Q3,Q5_2,Q5_3,Q5_4,Q6,Q8,Q9,Q10,Q11,Q12,Q13,Q14,Q15,q6
saron_pictus,50,70,60,publishable with major revision.,"Phonetic: can describe more about the inclusion of word boundaries, e.g., was the silence closure period of VOT included? That can influence the word duration. Speech rate probably also has some influence on the word duration across different individuals. Controlling for speech rate should be considered as part of the normalization. For example, word duration can be normalized wrt speaker’s speech rate: word duration / (no. syl / second), etc. The idea is to capture the fact that for a word produced with the same duration by two different speakers, for the speaker with a higher speech rate, this word is effectively longer than the speaker with a lower speech rate. One more thing, the authors created a notes tier – what in particular was coded there? How did the authors detect errors in the tokens?
Statistical: lognormal distribution of duration is probably fine, but what about other probable prior distributions? It'd be better to check the empirical distribution before fitting a model.
Overall: Our biggest concern is, how valid it is to measure the duration of adjectives in a NF condition? Maybe the authors wanted to control the variability in different syllables and words, and restricted the dependent variables to a subset of five adjectives. But the *big* assumption here is that, atypical word combination will affect adjectives particularly in a noun-focused condition.","Using Bayesian with weakly-informative priors sounds like a standard practice especially for a limited amount of data. Again, from the reports, it is not clear if the authors did exploratory data analysis before moving on to employ specific distributions for priors. This could weaken the motivation for using the selected modeling method.","The authors have some expectations about how medium and atypical words may not get reduced, so they used duration as the dependent variable. This sounds reasonable, but they could have established the assumptions about the duration more explicitly and cited evidence or support from previous studies. Not sure if restricting the dependent variable to word duration is adequate to answer the research question. In other words, the research question is reduced to ""Do speakers modify the duration of part of the utterances to signal atypical word combinations in referring expressions?"" Also, there's an apparent lack of explanation of the model structure.
They also included the order of the trials to control for any fatigue and speed-up during the entire experiment as a covariate. Random structures include how variations across different speakers and words in realizing different typicality categories and a certain trial will affect the word duration. Why not include repetition as a random effect?
Moreover, the authors did not discuss the possibility of unobserved heterogeneity in their model specification. In other words, is it possible that derived features from other information available in the data can explain the variation in word duration? For example, variation of adjectives can be conditioned on the following noun, but the nouns were not included in the model. Therefore it is likely that the variation of adjective duration is confounded with the properties of the following noun, and it is not reflected in the model specification.","Probably OK, however, as mentioned above, the authors didn’t consider all the possible covariates, thus the model is likely under-specified. The authors could examine the possibility of including other direct or derived variables in the model and discuss the potential effect these variables may have.","Not too sure about the covariate trial_minmax, especially the interpretation of its HDI. Why is this included as a covariate rather than a random effect?","We didn’t understand why the authors looked at adjectives within the subset of NF condition. They also excluded tokens according to their notes tier in the textgrid, what are some examples that they counted as ""error""?","The existing transformations seem to be OK. We wonder about the choice behind scaling the trial numbers to 0-1, instead of using the original scale. More explanation is needed here.","Overall, it feels that the authors were trying to fit the data with a particular statistical method, rather than motivating the use of a model based on the understanding of the data. More clarification and explanation on choosing the variables and models will improved the analysis substantially.",1
saron_pictus,90,90,90,publishable with minor revision.,They selected one dependent variable a priori and the models tested whether it differed across typicality conditions. Analysis was clear.,"Models were appropriate for testing the dv, though additional justification for hierarchical components of model structure would have been nice.",Predictors were appropriately chosen for the dv and research question.,Variables included in model were appropriate.,Would have liked to have some additional prose justification for hierarchical components of the model structure.,"trials that had ""some sort of hesitation or error"" were excluded. We think this is appropriate, however, cannot evaluate it as these criteria are not defined. What counts as hesitation? What counts as an error? Where these equally distributed across conditions? etc.","The models was fit using log normal likelihood, which better fit the data. However, the pattern of results did not change based on this transformation.",NA,2
saron_pictus,90,80,85,publishable with minor revision.,The phonetic analysis seems very relevant and well-conducted (but I am not an expert) and the statistical modelling is also well-conducted.,"The statistical modelling strategy is relevant and the rationale is explained nicely in the summary provided by the team. If I were to suggest a minor revision, I would suggest complementing the estimates and credible interval with hypothesis tests, as the HDI alone (and/or comparing it to some value) does not allow for testing hypotheses.","The structure of the statistical model is sound, I think including trial as a predictor to control for drift in word duration throughout the experiment is a good idea.","All included variables are relevant. Maybe the authors could have analysed other acoustic indexes as well (e.g., F0, intensity).",The structure of the statistical model is sound.,"The authors excluded trials that had any sort of issue denoted in the notes column, which sounds a bit crude.","The authors used a Lognormal distribution for the response, which is equivalent to using a Gaussian distribution on the log-transformed raw data, which I think is reasonable given the prior and posterior predictive checks presented by the authors.",NA,2
