Q3,Q5_2,Q5_3,Q5_4,Q6,Q8,Q9,Q10,Q11,Q12,Q13,Q14,Q15,q6
epinephelus_aztecus,85,80,83,publishable with minor revision.,"My ratings were based on replicability, motivation of the study from previous research, appropriateness of the analysis given the data and hypotheses, and interpretation of results. I did not realize that I would not be able to revise my ratings once I click the arrow button; had I known, the ratings would be lower than they are.","SEM is a good choice for exploratory analysis, but it is prone to overfitting. Indeed, the results of both SEM models (particularly, RMSEA, CFI, and SMSR) indicate that it’s too tightly fit to the data and likely not generalizable. Mixed effects regression is an appropriate alternative, but the implementation is not statistically sound.","The process of choosing variables was appropriate, but the structure of the models is not. The structure of the SEM is not indicated in the writeup; typically, path-based models have a visual representation of the posited structure to help the reader understand the many different connections being assessed. The major offender is the mixed effects regression, where separate models were run for each factor with only a random intercept by word. These models, being vastly underspecified, have a high risk of type 1 error (seeing something that isn’t there).",Variables selected seemed appropriate and justified by the hypotheses.,"The SEM models are likely overfitted to the data, and the mixed effects models are likely underfitting the data. In particular, the structure of the mixed effects regression is problematic.","Discarding errors makes sense, but there are other comments in the “Notes” section (e.g., “hesitation break”) that should warrant consideration for exclusion as well.",N/A,"The Rmd document is not anonymized, so the author can be identified.",2
epinephelus_aztecus,90,60,75,publishable with minor revision.,"We find that concerning the phonetic analysis and the resulting F0 values, one is commonly well-advised to use semitones instead of Hz values – especially when working on data of multiple speakers. However, this is the only minor comment we have on the phonetic analysis part.
Concerning the statistical analysis, we have little experience with running path models ourselves. Considering relevant sources, we find that the statistical analysis appears to be conducted in a meaningful manner. We wish to note that the description of modelling the fit indices including the modification of the same could (and likely should) be formulated in a more straightforward way. That is, with the current version, for laypersons (such as us) the relevant paragraph sounds a lot like hacking your way towards a well-fit model, even though the procedure described is well-grounded in statistical theory.
In a similar vein, we find that the amount of post hoc testing appears to be excessive at first. After the initial path model is fitted, several other models are fitted to account for speaker-individual differences and data that is rather out-of-scope of the overall research question (as given by the MSA coordinators), among other things.
As to our understanding, in all their models the authors do not include any random effects (or random effect like) structures for item (= the word for which the adjective was (un)typical), nor for adjective, nor for a combination of the two. We find that different combinations of adjectives and nouns might all be rated (un)typical; however, certain combinations might be more (un)typical than others. This is also reflected in the typicality measures provided by the MSA coordinators – a variable which is disregarded in all present analyses.
We thus find that the technical part of the statistical analysis is overall well-done. However, considering the theoretical underpinnings, i.e. which variable structures and which variables to work with, we find room for improvement.
The overall rating is the mean of both other ratings. We chose ‘publishable with minor revisions’ as we do not find any insurmountable issues with the statistical analysis, but would advise for creating further models to see whether the aforementioned structures and variables bring about changes in the model estimates. It goes without saying that such results are to be presented as exploratory post hoc findings; they are not to be confused with confirmatory analyses.","As mentioned above, we cannot speak in detail towards the path model part. Yet, after consulting relevant sources, we find no issues with the statistical analysis type. Similarly, using mixed-effects regression, we find no issue with the choice of statistical technique.","The authors make use of several dependent variables: duration of the determiner and an adjective, intensity mean, intensity range, pitch mean, pitch range. These measures are motivated by previous research; thus, we have no issues to raise at this point.
As independent variables, typicality and focus are used. Typicality being the predictor variable of interest, including it is straightforward and requires no further motivation. Focus was included to investigate acoustics when the speaker is not faced with a need to facilitate disambiguation even in untypical adjective-noun combinations.
As briefly mentioned above, random effects are not considered in the main path model. Even though a random effect for speaker is explored in further analyses, we would have wished for an inclusion in the main model as well.","We find typicality and focus to be meaningful predictors to answer the present research question as these variables are directly related to the target items. However, we would have liked to see some sort of random effect variable for adjective and/or noun combinations, as well as the use of the continuous typicality variable.
Condition was used as variable as well, even though the authors missed mentioning it in the relevant part of the questionnaire. This is probably due to condition being used in a post hoc analysis. Nonetheless, it is used in a meaningful way as the aim was to compare the three different conditions (ANF, NF, AF).","We find the structure of the presented models to be overall suitable for answering the present research question. As mentioned before, a more sophisticated random effect structure is preferable.","Excluding any observations that had comments in the “Notes” tier of the TextGrids is a reasonable choice. If such observations were without any issues to begin with, there would be no comments. Additionally, trials with issues during the acoustic analyses were disregarded; this also is a meaningful choice.","Typicality and condition were treatment-coded; a straightforward choice we have no issues with.
One point we wish to make is that we assume that working with semitones instead of Hz is the better operationalisation for working with pitch data. Thus, we would have liked this team to work with semitones as unit instead of Hz.","We find the overall analysis well done. However, it feels as if only the first part, i.e. the main path model, was planned beforehand. All further analyses, i.e. which we call ‘post hoc’ in our review, appear to be highly explorative and results of chance/circumstances rather than prior planning. Of course, exploring data further in post hoc analyses is not to dismiss; however, we feel that it must be more clearly stated at which point the main analysis ends and the additional (post hoc) analyses begin. It might be the case that we got the wrong impression here and all presented analyses were indeed planned beforehand; if this is true, the presentation of analyses and results and its underlying structure should be phrased in a more comprehensible way.",2
epinephelus_aztecus,55,65,60,publishable with major revision.,"We have a few concerns about both the phonetic analysis and the statistical analysis. Regarding the phonetic analysis, we appreciate that the team carried out their acoustic analysis by hand. Their methods, however, could benefit from more clarification. For example, the authors wrote: “Boundaries were created at zero crossings using large acoustic/auditory cues.” What cues were these exactly and how were they defined given the onset/offsets of the target words? Since just one member of the group checked all difficult cases, the measurements are probably consistent, but the methods as described are not replicable.  Additionally, while trials marked as errors were removed, there was no mention of whether pitch tracker errors and/or creaky voice tokens were removed. We found creaky voice to be especially prevalent in vowel-initial adjectives, especially after vowel-final ""der"", as in ""der orangen"", but can also occur in ""den orangen"", and for some speakers creak is common in many of the articles and adjectives.  The pitch tracker is not likely to do well with creak and will often give an extremely low value for f0 during creak (pitch halving).  Since usually part of the adjective is in modal voice, this will give an extremely large f0 range for most tokens that contain creak. Related to this, the authors have set their  pitch analysis range in their Praat script to 70 Hz - 550 Hz. The pitch tracker is likely to have some pitch tracker errors that give very high ""pitch"" during voiceless aspiration noise or frication noise, where there is just enough of a repeating pattern for a brief bit for the pitch tracker to think there's voicing.  Restricting the determination of max pitch to voiced portions at least 30 ms from the onset or offset of voicing would help with this, or hand measurement of max and min would, or setting a narrower range for pitch analysis, perhaps with the max determined for each speaker's actual pitch range.  A process of checking outliers could also help.

Regarding the statistical analyses, we like the first SEM approach, and find it interesting and appropriate (we note the R code is excellent and we really appreciate the careful attention to detail here). We also appreciate the second analysis involving linear mixed-effects models and the concern here for by-participant effects. We think this approach is generally in line with the SEM results. The authors claim that there are significant differences in the lme models, however, we note that given the additional five models run, the authors should adjust their p-values for multiple comparisons, which would then result in similar null results.  Finally, while this criticism may be due to our group’s relative lack of familiarity with SEM approaches, we were unclear as to the decision making that led to duration being included as a covariate of some measures but not others.

In a similar vein, we are unconvinced by the general approach; if we are wrong about our interpretation of the method, then this requires the motivations to be made much more explicit in the write up.  To take an uncharitable interpretation, it seems as though the authors used the SEM analysis and when they found that nothing was significant simply looked at which non-significant effects might be interesting anyway to run additional statistics (regressions) to back up the interesting non-significant ones from the SEM analysis.  Finding three significant effects, only one matches the interesting but non-significant SEM effect, and so they focussed exclusively on that one.  We are generally in favour of using multiple statistical approaches, and we appreciate that the authors are not bound to p-values, but the results as they stand are (or perhaps as they are presented) are unconvincing.  Moreover, given the extremely subtle distinctions found, we question whether the distinctions putatively found would be perceptible.

Furthermore, to the extent that the results can be trusted, we found some of them puzzling and there was insufficient discussion to assuage our concerns.  In particular, the authors found that intensity mean and intensity range are lower for Medium than for Typical, but do not go lower yet for Atypical; Intensity Range goes the opposite way for Atypical.  If the significant effect is reliable, one would expect that the results for Medium would be in the middle of the other two conditions, and the fact that they’re not merits some discussion.  

The third analysis involving the AF and ANF conditions alongside the NF condition is very interesting, however, we are unsure whether these are truly comparable in the way the authors have set them up. In the AF condition–as the authors note–there was no typicality condition. In the ANF, there was but there was no ambiguity. We think this is problematic in terms of testing  “how acoustics are modulated in comparison to items that are lacking typicality”. Because Typicality is not manipulated in the AF and ANF conditions but is in the NF condition, there is an inherent confound between Typicality and Focus Position that we believe makes it impossible to test the effect of Focus Position accurately within this design.  If Typicality has any effect, it cannot be having the same effect in all three of AF, ANF, and NF, and therefore the effect of Focus Position could be skewed by any effect of Typicality. Furthermore, it is unclear whether the speakers were producing the utterances in AF/ANF conditions without problems. As far as we know, there were no comments in the AF/ANF tiers, meaning many of these trials may have been problematic in terms of errors/hesitations/etc. It is unclear whether this affected the authors’ results.",The statistical analysis is fine other than the need to adjust for multiple comparisons and the issue with the AN/ANF conditions.,"We only have a limited knowledge of structural equation models, but based on our understanding, the model seems appropriate.","The dependent variables were fine, though we note that pitch tracker errors were prevalent in the data that we analyzed. A method of automatically taking max - min over the span of a whole word is almost sure to get quite a few of the pitch maxima falling in these pitch tracker errors. Pitch tracker errors and creaky voice could also throw average f0 off by inconsistent amounts.",The SEM model is fine. The linear models should adjust for multiple comparisons. The third model involving AF/ANF conditions does not seem to be as straightforward as the authors claim.,"We agree with the decision to exclude errors. However, we would like to note that we don’t think that information about errors/hesitation breaks/etc. were annotated in the AF and ANF conditions. For example, in JW_3, who had 9/30 NF trials marked as an error/hesitation break, none of the AF or ANF trials for JW_3 were so marked.  It seems unlikely to us that JW_3 only produced errors on the NF trials.  This introduces an inconsistency in how the different conditions were treated with respect to errors and points to the problems with including the AF and ANF conditions.

One might also want to exclude speaker JW_3 entirely, as this speaker had a very high proportion of stimuli marked as errors and seems to have struggled with the task.  However, since the actual error tokens were excluded, this seems like more a matter of preference, it could be fine either way.

We would also look for some method of excluding creaky voice from the f0 range measurements.  Hand-placement of measurement points could avoid this, or one could use a measure other than range, to avoid including f0 minima that reflect creak.",None,N/A,1
epinephelus_aztecus,60,70,80,publishable with minor revision.,"Overall, this write-up was well-written, well-explained, and left only a few questions unanswered. In terms of the phonetic analysis, we were left wondering precisely what acoustic and auditory cues the authors used to segment the determiner+adjective combination (i.e. waveform? spectrogram? periodicity? differences in intensity? formant information?). Though the textgrids were provided, including this information in the write-up improves the likelihood of faithful replicability.",The motivation for using the path models was well motivated and well-explained.,"Though the path models seem well motivated, we were unsure as to whether the DVs (duration, F0 mean, etc.) were standardized. It appeared so since the authors were comparing effect sizes/coefficients, but we were not totally clear on this. 
Overall (and we may be a bit biased due to our own usage of linear mixed-effects models), it seems that 5 separate linear mixed-effects models (that the authors included in addition) might have sufficed.","Additionally, we expected to see a few other independent variables included in the analysis such as vowel (or color) and perhaps a variable representing a possible order effect. 
","We are not experts in path models, so to our knowledge, this seems fine. Again, it was well-motivated.","The researchers excluded any errors in the ""notes"" tier of the textgrids. However, they do not mention exclusions based on hesitations or other types of annotations in the notes tier. No mention was made of any other exclusions, though we might wonder if there were any outliers or undefined pitch regions. We also observed many instances of creaky voice in the data, but no mention was made of this in this writeup. 
","No transformations were made for F0. Though later the authors fit individual-level models (and ran linear mixed-effects regression with participant as a random effect) to account for individual-level differences in vocal tract size, we might have expected to see these values normalized (via z-scores or semitones) for broader comparison.","On page 3, the authors focus in on the effects of pitch, saying that it ""stands out the most"", but we were not clear as to why. Its p-values were not the closest to 0.05, its effect sizes were not the largest, so we were left a bit confused. We appreciate the authors' justification of discussing nonsignificant results (since the model was well-fit), but we might have expected to see those described as ""trends"".",2
