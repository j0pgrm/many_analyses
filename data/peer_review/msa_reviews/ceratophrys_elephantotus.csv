Q3,Q5_2,Q5_3,Q5_4,Q6,Q8,Q9,Q10,Q11,Q12,Q13,Q14,Q15,q6
ceratophrys_elephantotus,80,80,80,publishable with minor revision.,The choice to run the sound files through another forced aligner and then not manually correct it due to time constraints is questionable.,"Its rated as 80/100 because we were unfamiliar with the analysis and are unsure of how best it suits the data. If author(s) provided rationale as to why this analysis best fits the data set, then we would rate it higher.","The factors/variables focused on were ""typicality"", ""word category"", duration, and F0. These variables are appropriate for answering the research question that was presented for the data set.","The variable of typicality was left as a three-factor choice, when there was a continuous scale for typicality that included a more precise measure of typicality. But, we are unfamiliar with the statistical analysis used, so it could be that a continuous scale isn't suitable for this model.",We are not familiar with the structure of the statistical model so we cannot evaluate if it is the best fit for the data set.,N/A,N/A,"The author(s) points out that a limitation of the data set is that it is unbalanced because there are only 5 males. However, they don't target that issue in the analysis (i.e., exclusion or transformation).",2
ceratophrys_elephantotus,25,55,40,publishable with major revision.,"The idea of using machine learning for classification is certainly interesting and is the main asset of this study. The main issues with the analysis are (a) data processing/selection and (b) a general lack of information that would have provided the necessary insights in order to understand the author’s intentions.
Regarding (a): 
- ASR introduced more errors than the original orthographic transcription of the sentences and the clean-up of the errors was probably incomplete
- Since MAUS is based on the ASR-computed orthography, many of the segment boundaries placed by MAUS are probably also wrong
- The selection of “phones” contains unstressed vowels even though these were supposed to be excluded according to the author (e.g. the second /a/ in “Paprika”)
- Why was /i/ amongst the phonemes selected as a phone in “Möhre”?
- The data selection included both the colours and fruits, i.e. both adjective and noun, even though only the noun was focused (NF condition)
- What exactly was difficult about extracting f0 automatically? Why are there (according to the first point on page 4 of the result) so many missing f0 values? If f0 was extracted as a signal for the whole phone, which part of the signal was a variable in the analysis?
Regarding (b):
- The hypotheses specify the way in which acoustic parameters indicate stress in German. However, no connection is made between 'focalisation' and 'typicality' (e.g. is the atypical or the typical condition considered focalised?)
- Which effects of typicality on the three acoustic variables (F0, formants, duration) are expected/hypothesised? That is, are atypical or typical colour+fruit combinations marked by “longer duration, higher f0, and higher loudness” (from section 3)? Also, loudness is not measured and there are no predictions at all for the formants that were measured.
- It remains unclear whether the results reported in section 7 go in the expected direction for each of the typicality categories. It is only reported which variables seem to improve (or bias) the classification algorithm.
- In the conclusion (section 8), the influence of the unbalanced dataset (section 2) is no longer mentioned.
- Parts of the report mismatch the R script, e.g. the conclusion sounds like the measurements referred only to the adjectives, not the nouns (but both were used according to the script).
","The idea is indeed good and to some extent original, but more detailed analyses and explanations would have been necessary (see answer 9)","There is no real „structuring“ of a statistical model, since a classification algorithm decided which variables from a given list were good predictors for typicality. In this respect, the  author chose a series of acoustic parametres like f0, formants, vowel duration, but this choice was only poorly justified by the report (sometimes also admittedly by the author, see page 3 of the report, last paragraph). In the method, formants are extracted that are not mentioned in the hypotheses.","The variables are suitable, although a longer explanation of why the variables “target_name” and “phone” introduce a bias into the classification would have been necessary, i.e. why was the classification rate 100% with these factors, but without only 56.7%?","Internally, all machine learning algorithms do a lot on their own; the external structure (i.e. the choice of variables, which was discussed before) was instead (and had to be) provided by the author. 

However, the members of this team are not very familiar classification trees and cannot really judge on this. For the rest of the evaluation, please see previous answers.","The author excluded utterances carrying annotated errors. This can be considered as a good quick choice in order to avoid noise in the data. 
It is understandable that missing values in F0 could not be manually excluded  because of matters of time, although the analysis (as the same author admits) would have benefitted from it.
It was a good choice to only examine NF, but it is unclear why both adjective and noun were included, and not just the focused noun. The analysis also included unstressed vowels even though these were supposed to be excluded (see answer to Q9 for further points on data selection).
","A sort of normalisation of F0 would have probably be useful in order to avoid possible biases due to differences between women and men.
Similarly, phone duration could be biased by overall speech rate (although this effect might be negligible).","Just our opinion: I’d suggest the author, if needed, to re-write the report, since there are so many sentences which we found ambiguous. In particular, many parts were not described in any depth, so that the procedure, which could be also interesting to a reader who’s not familiar with it (like us), is not that clear (even when looking at the script, too, some parts were missing or not enough described in the comments).
In 2 it is stated that the data is not balanced in terms of speaker sex. In the given dataset, however, there was no information about speaker sex: Where does that classification come from? Literature references would be helpful when formulating the hypotheses.",1
ceratophrys_elephantotus,48,24,36,publishable with major revision.,"As the authors point out, the data was extracted automatically and in many cases automatic extraction produced unreliable results.
Typicality measurements were somehow transferred to individual nouns and adjectives, which does not seem reasonable: typicality defines combinations of adjective+noun.
The analysis is based on intensity and pitch of stressed vowels, but gender and vowel minimal pairs are not considered. Since gender and vowel quality affects both intensity and pitch, including all vowels into the data set distorts the results.
The authors should have considered mixed effects models since observations in the analysis should be independent, but in the provided analysis hidden grouping of observations into speakers is ignored.
There is a problem with independence of observations in the analysis, since each speaker produced more than one utterance with the same values of variables under analysis (e. g. Der rote Paprika was produced twice by every speaker), this should be considered in the statistical analysis. 

","Decision tree analysis is applicable here, but you’d need to control for speakers, gender and repetition of words as random effects.","The authors classified nouns and adjectives into categories of typicality which is not reasonable: only combinations of Adjective+Noun can be classified as typical or atypical.
Vowel quality was not considered when structuring the model, as well as gender differences and repetition.
","The choice of variables is generally reasonable, but:
- Automatic extraction of data wasn’t always reliable
- Vowel quality wasn’t taken into account
",It would be better to use mixed-effects models for this type of data.,The authors did not exclude the data points where they had doubts about the quality of parameters extracted automatically. The authors should have excluded unreliable formant and fundamental frequency data.,NA,NA,1
ceratophrys_elephantotus,20,1,9,deeply flawed and unpublishable.,"No statistical analysis was provided, only the classification of phonemes produced based on the matrices created. There was also very little information provided to evaluate the report.",No statistical analysis was provided.,No statistical analysis was provided.,No statistical analysis was provided.,No statistical analysis was provided.,Unclear what the authors left out and why.,The authors implemented the classification based on the matrices whereby the data points were transformed into lists. It was a well-motivated choice given that they decided for this approach.,"Very little information.
No statistical analysis. 
Not a lot was given to us to be able to evaluate their analysis.",0
