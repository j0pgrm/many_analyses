Q3,Q5_2,Q5_3,Q5_4,Q6,Q8,Q9,Q10,Q11,Q12,Q13,Q14,Q15,q6
gnathosaurus_canadensis,20,1,10,deeply flawed and unpublishable.,"I am not convinced of the approach to analysing the data and there are serious issues in the statistical approach. The author computed the average f0 per syllable in the adjective and the noun and computed the difference. This is fine by me at this stage. However, the computed mean difference was then transformed to be in an absolute value; this is a serious issue (see below) as the assumption then is that there will always be the “same” direction of difference; that the noun will always have a higher f0 than the adjective. 
Then, the median was chosen as a dependent variable, but this was computed based on the three mean values of f0 per participant and typicality. The SD is obtained, but no mention as to how this was computed. Why haven’t the author obtained the medial and SD of each syllable? The statistical approach used the “friedman test” which is a non-parametric alternative to an ANOVA with repeated measures. However, they had to obtain one observation per participant and typicality for the test to run, which is already an issue as within speaker variation is lost!","This is motivated by the researcher to fit the data, but choosing this test restricts the author(s) in how they dealt with the data. The median used here is the median of the three repetitions per participant in a one of the three typicality contexts, rather than being the actual median for each syllable. I don’t believe this is the right tool, even if well-motivated. No pairwise comparison was proposed (you can use either a “wilcox test” or a “sign test” to do the pairwise comparison with corrections for multiple comparisons! Also, you have used R to compute your statistical analyses; Rstudio is an integrated development environment (IDE) for R (and Python, etc..). Make sure to cite the R version and the version of the package(s) used.","This is misleading as not described properly in the text. The difference in mean between the syllables in adjective and noun is computed initially correctly, but then for some reason, the author(s) decided to compute the absolute difference removing the sign; the sign is important here as this should correlate with differences in typicality (see dataset “MSA_extracteddata.xlsx” for original data). Then they used the median, which was obtained as the median of the three repetitions per typicality per speaker; this should have been obtained directly from the speech samples. 
We are told that the data from two speakers were considered as outliers and these were removed. It is not clear if there were already errors in data extraction that led to this. The analysis was done with and without these two speakers and the reported results 
","Variables included are not appropriate at all as the sign of the difference is lost; this needs to be retained. A clear justification for why only the mean value was obtained in the first instance is needed. 
The data from two participants were removed, with no clear justifications. You should have kept these. The author(s) decided to remove the data labelled with “errors”, which should be fine, though not clear at this stage why these were judged initially as “errors”
","Not entirely appropriate. There is no clear structure. I would have liked to see the following order:
1)	Data summary and description of the dataset
2)	Data visualisation to evaluate the patterns (simple box plots, or any other type of visualisation)
3)	Statistical modelling. 
a.	The author explains that the data are non-normally distributed; where are the analyses for that? 
b.	Normally, with this type of data, it is expected to have deviations from normality, and we are concerned with the normality of distribution for the residuals; were there any checks after the data analyses?
c.	Because you have three dependent variables, look at whether there are clear differences emerging from the three.
d.	Run a pairwise comparison
",The data from two speakers were excluded (though the results were presented with and without). The data were removed due to them being outliers; not clear if the author(s) chose a specific threshold (2.5 above/below the mean?).,"The author(s) use semitones instead of Hertz, which is fine. 
They did not use any specific transformations of the dependent variable, although they decided to compute the absolute difference rather than the true difference. This shouldn’t be done.
","Make sure your R script has all the steps of data analyses, e.g., importing the data set, visualisation (if any) method used to check outliers, etc..
I only spotted the error of using the absolute mean difference by opening the second excel sheet. When running the statistical analyses on the median based on the original mean differences, there are clear differences emerging in the data. 
Friedman rank sum test

data:  test$median, test$typicality and test$speaker
Friedman chi-squared = 9.2667, df = 2, p-value = 0.009722
I still do not believe that the test used here is appropriate (run linear mixed effects modelling and check the residuals or a Bayesian approach).
",0
gnathosaurus_canadensis,20,1,10,deeply flawed and unpublishable.,"We are not convinced of the approach to analysing the data and there are serious issues in the statistical approach. The author computed the average f0 per syllable in the adjective and the noun and computed the difference. This is fine at this stage. However, the computed mean difference was then transformed to be in an absolute value; this is a serious issue (see below) as the assumption then is that there will always be the “same” direction of difference; that the noun will always have a higher f0 than the adjective. 
Then, the median was chosen as a dependent variable, but this was computed based on the three mean values of f0 per participant and typicality. The SD is obtained, but no mention as to how this was computed. Why haven’t the author(s) compute the median and SD for each syllable directly from within Praat? The statistical approach used the “friedman test” which is a non-parametric alternative to an ANOVA with repeated measures. However, they had to obtain one observation per participant and typicality for the test to run; they don't make the most of the available variability which, in turn, might lead to oversimplified conclusions.
","This is motivated by the researcher to fit the data, but choosing this test restricts the author(s) in how they dealt with the data. The median used here is the median of the three repetitions per participant in a one of the three typicality contexts, rather than being the actual median for each syllable. We don’t believe this is the right tool, even if well-motivated. No pairwise comparison was proposed (the author(s) can use either a “wilcox test” or a “sign test” to do the pairwise comparison with corrections for multiple comparisons). In addition, you have used R to compute your statistical analyses; Rstudio is an integrated development environment (IDE) for R (and Python, etc..). Make sure to cite the R version and the version of the package(s) used.","This is misleading as not described properly in the text. The difference in mean between the syllables in adjective and noun is computed initially correctly, but then for some reason, the author(s) decided to compute the absolute difference removing the sign; the sign is important here as this should correlate with differences in typicality (see dataset “MSA_extracteddata.xlsx” for original data). Then they used the median, which was obtained as the median of the three repetitions per typicality per speaker; this should have been obtained directly from the speech samples. 
We are told that the data from two speakers were considered as outliers and these were removed. It is not clear if there were already errors in data extraction that led to this. The analysis was done with and without these two speakers and the results were reported with and without these two speakers.","Variables included are not appropriate at all as the sign of the difference is lost; this needs to be retained. A clear justification for why only the mean value was obtained in the first instance is needed. 
The data from two participants were removed, with no clear justifications. You should have kept these. The author(s) decided to remove the data labelled with “errors”, which should be fine, though not clear at this stage why these were judged initially as “errors”","Not entirely appropriate. There is no clear structure. I would have liked to see the following order:
1)	Full data wrangling in the main R script: add details of how the median was computed.
2)	Data summary and description of the dataset
3)	Data visualisation to evaluate the patterns (simple box plots, or any other type of visualisation)
4)	Statistical modelling. 
a.	The author explains that the data are non-normally distributed; where are the analyses for that? 
b.	Normally, with this type of data, it is expected to have deviations from normality, and we are concerned with the normality of distribution for the residuals; were there any checks after the data analyses?
c.	Because you have three dependent variables, look at whether there are clear differences emerging from the three.
d.	Run a pairwise comparison
",The data from two speakers were excluded (though the results were presented with and without). The data were removed due to them being outliers; not clear if the author(s) chose a specific threshold (2.5 above/below the mean?).,"The author(s) use semitones instead of Hertz, which is fine. 
They did not use any specific transformations of the dependent variable, although they decided to compute the absolute difference rather than the true difference. This shouldn’t be done.
","Make sure your R script has all the steps of data analyses, e.g., importing the data set, visualisation (if any) method used to check outliers, etc..
We only spotted the error of using the absolute mean difference by opening the second excel sheet. When running the statistical analyses on the median based on the original mean differences, there are clear differences emerging in the data. 
Friedman rank sum test
data:  test$median, test$typicality and test$speaker
Friedman chi-squared = 9.2667, df = 2, p-value = 0.009722
However, we still do not believe that the test used is appropriate (run linear mixed effects modelling and check the residuals or a Bayesian approach).
",0
gnathosaurus_canadensis,80,55,66,publishable with major revision.,"For phonetic analysis, the author measured the f0 of the stressed syllables only and analysed the f0 difference between the target adjective and noun, produced by the same speaker. The use of the semitone scale is appropriate for comparing results from different speakers. The methods were appropriate for controlling between-speaker variation and they are justifiable given the experimental design. 

However, we believe that it is a drawback that only one variable was examined, as this approach has ruled out the potential use of other phonetic cues. Further, we did not find evidence of exploratory analysis. We would have given a higher overall score if plots showing speaker- and item-related variation were created. 

We think we can conceive of this one-man approach (as it seems) as the first step in a larger team effort. As such, it’s very respectable — a good start and clearly written up. However, in-depth exploration and/or statistical modelling and/or the inclusion of more measurements would be required to appropriately address the research question.

The combination of a quite simple analysis with frequentist statistical analysis is unfortunate. Pure exploration would be preferable in this situation (the results from the statistical analysis are likely to be misleading in such cases, even though there is only a null effect. 

","For statistical analysis, the author used a Friedman test and the choice was well-justified. However, the data reduction process (the f0 difference between the adjective and the noun was averaged across items to allow each speaker to contribute one data point for each ‘typicality’ condition) may have averaged out variations worth reporting. In the reduced data used in the present analysis, the author found two speakers being outliers but in the present form, it is not clear what caused them to be outliers (e.g., particular items or particular ‘typicality’ condition). It would have been helpful if the author presented some figures showing the distribution of the raw data.   

While the statistical approach is justified, it is not up to commonly used current standards. Speakers (and items) are not included as random factors in this rather simple analysis. Multi-level/mixed models, of the frequentist or Bayesian flavour, would have been really helpful here, and indeed, might be expected from such an analysis in our field at this point.

A purely descriptive/exploratory approach might have been completely justified too, but then we would have wanted to see lots of plots and in-depth analysis by speaker, item etc. 
","
The choice of the variables (dependent variable as the f0 difference between the adjective and the noun in the NF condition; independent variable as ‘typicality’) is appropriate. 

Please see our comments about the statistical analysis. The methodological choice was justifiable, but now speech researchers are reluctant to opt for the data reduction as used in the present study. 
","The choice of the variable was justified, and therefore it is not unsuitable, but taking only a single dependent variable rules out the possibility to examine other phonetic effects (e.g., duration). If the author wished to examine only the f0, then still a few more dimensions could have been added (e.g., pitch range).
","
The Friedman test is an acceptable choice for simple analysis, but definitely, it is not of the state-of-the-art techniques and it is potentially misleading.
","Only data for the NF condition were analysed, excluding the tokens with an error. This is a simple but appropriate approach. For the given analysis this choice was fine.
",N/A,NA,1
gnathosaurus_canadensis,70,75,70,publishable with major revision.,"This is, overall, an acceptable analysis. Simple yet effective. I wish authors had introduced their analysis and explained their rationale a little better, though. 

My main concern has to do the the phonetic analysis. Why focus on the stressed syllable only to extract pitch peaks? We know that in many languages (e.g., Spanish), peaks associated with stressed syllables in certain positions (e.g., prenuclear) tend to appear outside the segmental boundaries of the stressed syllables. What if German, or in some cases or for some speakers, a similar process occurs? This analysis would not capture that. 

A couple of more details regarding the phonetic analysis:
-How was classification for participants' gender done? Information on gender was not provided. Also, 250Hz for male speakers (or any speaker) is too low. Especially when doing analysis of pitch maxima, it’s important to have a generous upper limit, to be safe.

- Why extract pitch means? What is the rationale for this? Also, why were these extracted manually? Not only is it unnecessary work, but the likelihood of errors also increases when doing this work manually.","It seems appropriate. Producing one single mean per condition and per speaker is not ideal, though, as variability is lost.","The dependent variable is correct, and it is the expected variable to choose to answer the research question. 

The independent variable is, in principle, intuitively appealing. However, I wish authors had explained at more length why they chose it. For example, why did they produce a difference between F0 mean in nouns and F0 mean in adjectives? Why not simply measure the noun, or the adjective, for example?","Authors decided to focus on one very specific phonetic cue, and thus excluded other potential acoustic analyses. I do not have an issue with this, but I just wonder why authors thought it was the best predictor variable to answer the research question.","It seems appropriate, except that, as explained above, producing one single score per participant per condition disregards  the variability in the data.","Why exclude trials labeled as ""errors"" but not trials with ""break"" or ""hesitation"" labels?

It is not clear what criteria authors used to determine which cases were outliers.",N/A,NA,1
