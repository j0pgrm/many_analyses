Q3,Q5_2,Q5_3,Q5_4,Q6,Q8,Q9,Q10,Q11,Q12,Q13,Q14,Q15,q6
hoplostethus_macrosteus,65,25,45,publishable with major revision.,"We found the segmentation criteria referenced to be generally rigorous, and spot checks of TextGrids did not reveal major concerns with regard to segmentation, but there were minor issues with annotation. We also did not have concerns with the Praat script used to extract acoustic measurements. However, given the challenges in segmenting liquids as mentioned in the authors’ response, some more in-depth discussion of how inter-rater reliability checks were conducted, as well as reporting of the results of such checks, would have been appropriate. There could also be more clarify as to what “coarticulated” referred to in relation to the segmentation of /Vl/, whether as opposed to deletion or assimilation or not, since that would presumably have a systematic effect on duration. In combination with the above, our rating for the phonetic analysis further reflects our concerns for the specific features chosen for analysis, which we elaborate below. While many of these analyst decisions could certainly be justifiable, we were often not provided with such justifications.

While the statistical analysis followed a generally accepted framework, there were issues with how models were formed and evaluated, meaning that one of the models in question could not adequately address the research question posed. Our rating for this part is thus a reflection of what we consider a flawed and somewhat misleading analysis that is likely to produce an unreliable estimate of the relationship between the variables.",We consider the use of linear mixed-effects modelling to be appropriate.,"We found the process of model selection to be problematic. The various models fitted in the Rmd for duration and intensity indicate the lack of a principled approach in deciding whether each factor should be included as a fixed effect or a random one. More generally, we do not consider the decision to include ‘color’ as a fixed effect to be sufficiently justified in this case. We also do not consider it appropriate to model the full datasets for comparison, when it has already been decided that outliers should be removed. Furthermore, when comparing model fit using AIC, models should be fit with ML rather than REML for the comparison to be meaningful. In this case, m3.5 would not have been considered an improved fit over m2.5 (the difference in AIC being less than 2).","Duration and maximum intensity of the stressed vowel are certainly relevant variables to include, although we remain curious as to the exclusion of other related features extracted from the Praat script. While the exclusion of f0 and formants is not problematic per se, the authors’ concerns could have been addressed by means of by-speaker normalization, and we believe that stronger justification could have been offered for their exclusion.

Other independent variables were suitably included in the model, but, as above, we question the choice of including ‘color’ as a fixed predictor.","We are of the opinion that the final model for duration was not appropriately structured. The way the interaction was included and subsequently tested (via Anova) does not in fact permit the significance of the specific typicality x color interaction term to be tested, or indeed the main effects of each fixed predictor. If, instead, a “typicality * color” term were included in the model formula, the p-value for the typicality:color term would come out as approximately 0.025, which would have to be more cautiously interpreted, since Wald z-test is known to be anti-conservative (thus reinforcing our concern above in Q11 that including the interaction would not seem to improve model fit by AIC). The model for intensity did not suffer from the same issue. The use of treatment/dummy coding here, as opposed to sum coding, would have an impact on the interpretation of intercepts and effect sizes, especially where interactions were concerned.","We consider excluding trials marked with “error” or “hesitation break” when the target is affected to be an appropriate choice. However, the blanket exclusion of values beyond 2SD from the mean is typically considered to be a heavy-handed approach, and we do not consider it to be sufficiently justified in the present case.","Contrary to the authors’ response, they did not in fact center and scale the dependent variables for modelling. This was only done as an intermediate step to exclude outliers.","We encountered a number of challenges navigating the Rmd when attempting to reproduce the results. The principal difficulty arose from the fact that Results_clean.csv was not provided, but the way it was used in the Rmd also indicates that it was not the direct output from the Praat Script and that much additional manipulation was required to arrive at a suitable form. Relatedly, there were inconsistencies in how tokens were labelled in the TextGrids, some of which resulted in ambiguity that required additional checking (in particular, ‘g’ referred to both ‘gelb’ and ‘gruen’ depending on the speaker). We were unable to reproduce the step excluding outliers for intensity, as the code excluded 36 instead of 33 observations for us. Reproduction would also have been aided by a tidier Rmd with more user-friendly comments and with redundancies removed (e.g. all the packages that were in fact not used), as well as the HTML output knitted from the Rmd.",1
hoplostethus_macrosteus,90,100,95,publishable as is.,"They chose two relevant acoustic measures, they labelled and measured them accurately and presented the results clearly.","Linear regressions were run on each acoustic measure, after comparing models. This is a sound approach to using this type of analysis.","The dependent variables were duration and intensity - the only issue here is that the instructions were to only include one in the writeup. The independent variables were typicality, color and observation number. Including color is useful because all of the colors were repeated in each typicality condition.","They used model comparison based on AIC values and also included participant as a random effect. Also including ""observation"" (i.e., experiment order) as a possible effect is interesting to see if where the utterance came in the experiment may have an effect.",Using a linear regression model for each of the acoustic variables is a valid approach to answer this research question.,"They examined the NF condition, only the adjectives. For the sentences that were marked as errors, the authors only excluded them if they affected the target adjective or noun. They also excluded any tokens whos measurements were excluded any values that were +/- 2 standard deviations from the mean, which is logical.","The authors note that they ""normalized the duration and the intensity measures"" but they do not provide any detail on how they actually did this.","This analysis is well done - the only drawbacks being that they reported on two instead of just one, and also that they did not provide any detail on how they normalised duration and intensity.",3
hoplostethus_macrosteus,90,20,40,publishable with major revision.,"Unsure about why ±2 std were removed. Seemed like color and observation should have been random effects rather than fixed effects, noun could also have been entered as a random effect, observation could have been removed once it became clear it wasn't significant. Would have used emmeans package rather than Tukey test for pairwise comparisons. Would have been nice to see the AIC values for each of the fitted models to understand why they chose the ones they did. F0 and other measures could have been taken and analyzed regardless of gender given that participant was entered as random effect.",LMER works fine for this question (as long as you define the fixed and random effects appropriately).,Fixed and random effects did not seem to be chosen appropriately (see above). Could have used other phonetic variables given that their rationale for excluding F0 doesn't take into account that a random effect of speaker would allow for comparison.,See above,See above,"Fine to exclude observations with notes, but didn't seem like they justified their exclusion of ±2 std of data","Data seemed fine as it was, but should have noted how normalization was carried out (z-score?)",NA,1
hoplostethus_macrosteus,85,50,60,deeply flawed and unpublishable.,"We were impressed with the manual coding of the segment and they did a fantastic job articulating their phonetic analysis. Furthermore, we believe the validity of the coding would be much higher as they were segmented by hand. However, removing the pitch and formant information wasn't justified just because gender information was not available as gender isn't a perfect correlate of vocal tract length. The statistical analysis was adequate with a few methodological quirks. Furthermore, the analysis is not reproducible even with the code provided as there were files missing for the script to run..",We believe the the statistical model selection was suitable for the analysis.,It would've been good to include Local measures of speech rate for the duration variable.,We noted that f0 and formants of the vowels were excluded from the outset. We don't think reasoning to exclude these variables were justified.,"Selected model for duration includes interaction terms without main effects included.
not clear on criteria of establishing significance (pvalues of what?)
post hoc analyses are conducted on interaction term but disregards main effects.
should have included local controls for speech rate / amplitude.","They only included observations from the noun-focussed condition as this was the only balanced dataset. They also removed observations 2 SD (which is different from the usual 2.5 SD) for the whole dataset, but not per speaker per adjective.",The authors centred and scaled the duration and intensity variables per speaker. We believe this is suitable.,"They didn't consider co-articulatory effects of the following word, though the following effect wouldn've been less apparent. There wasn't enough information about the modelling for us to evaluate the statistical model. There were no fixed effects listed. There were no controls for duration (i.e., speech rate) and amplitude. However, they did clearly outline their methods. It is hard for us to evaluate how effective their statistical model as they didn't test for interactions.",0
