Q3,Q5_2,Q5_3,Q5_4,Q6,Q8,Q9,Q10,Q11,Q12,Q13,Q14,Q15,q6
anthracoceros_coronata,50,40,45,publishable with major revision.,"Phonetic analysis:  

The segmentation between vowel-final words and ablegen was somewhat inconsistent, in that the presence or absence of a clear break between the words could plausibly be a cue to typicality. When this clear break was not present, the boundary was placed at the midpoint of the entire vocalic portion. Given German prosodic patterns, it is likely that (all else being equal) the /a/ of ablegen is longer in duration than the adjacent word-final vowel; consequently, segmenting the boundary at the midpoint of the vocalic portion thereby serves to artificially lengthen the duration of the noun. This could introduce a small bias into the results. 

Three measures were taken: duration, f0, and intensity. All of these are subject to word- and vowel-level effects: for example, all else being equal, Kartoffeln has a longer duration than Socken; Kirsche has a higher f0 than Banane; and braunen has a higher intensity than gruenen. This is not a problem if this is taken into account in the statistical modelling, but this was not addressed.  

Additionally, the acoustic measurements themselves may not be accurate. Fundamental frequency was estimated using Praat’s simplest pitch tracking method, which is relatively inaccurate especially when applied in an unsupervised manner. As for intensity, it is not clear from the methods document how precisely the recordings were made, but based on auditory inspection of the recordings it appears that the participants did not necessarily have the microphone a constant distance from their mouths. This makes any estimation of intensity inherently unreliable. 

Statistical analysis: the analysis did not include a random effect of word. This is critical, especially due to the potential confounds in the phonetic analysis, and the fact that word type is not evenly distributed among the conditions. Even if this were to be controlled for, the nouns in particular are not well-distributed among the typicality conditions – the word Kartoffeln, for example, only ever appears as orangen (medium typicality), meaning we cannot easily see what Kartoffeln would be like in the other typicality conditions. 

The fact that the LMER models did not converge due to singularity raises the possibility that there was some unusual structure in the data or model specification. This could have been investigated more carefully. 

The use of Bonferonni-adjusted p-values is a good step.","The use of LMERs was sensible. Switching to a plain LM when the random effects were not needed was in principle a reasonable step, although it’s possible that if word were included as a random effect then this would not been necessary.",The lack of inclusion of word as a random effect is a glaring flaw in the analysis. The exclusion or inclusion of the focus condition in some models was not justified.,"The variables included were suitable. Again, the lack of word as a random effect is inexplicable.",See above.,"The analysis included data from all focus conditions – i.e. NF, ANF, and AF. However, the typicality values are not evenly distributed throughout these conditions. Notably, only the NF condition features the full range of typicality (“atypical” through “typical”), the ANF condition only has phrases of high and medium typicality, while the AF condition only has phrases of low and medium typicality. This confound between focus condition and typicality makes interpretation of the results challenging.",Duration data were log-transformed. All numerical data were subsequently z-transformed. These are appropriate transformations.,"It was not clear from the report whether this was the work of one person or a team, and if the latter, how the work was shared and if any measures of inter-rater reliability were made.",1
anthracoceros_coronata,50,60,55,publishable with major revision.,"This analysis reported test results on a combination of three metrics, duration, maximum intensity and maximum pitch, and two words within each sentence, the adjective and the noun. This resulted in six different variables. Each dependent variable was tested separately per 3 conditions of typicality, resulting in 36 models. There were 6 lm models without the condition, 18 lm models for each condition, 6 with the condition as a fixed effect, and 6 with the condition as a fixed effect plus the interaction.
The choice for separating noun and adjective was not explained. The hypothesis behind this rationale is not explicitly provided. The choice for duration, intensity and pitch was also not discussed. Moreover, the analyses on intensity and pitch were based on the maximum point within the word, and did not take the within-word variation into account. In addition, random factors had to be removed from the analyses due to convergence / singularity issues, and some aspects such as speech rate (which directly affects duration measures) and inter-speaker variation (as random effects in the lm statistical model) were not controlled for.","The originally planned statistical analysis type (LMER) seems correctly selected, but it was changed to (LM) later. Without further normalization, LMs do not seem appropriate (e.g. because the models do not take inter-speaker variation into account).","The metrics chosen could be relevant to the dataset, but the analysis seems to be carried out with elimination in mind, rather than choosing a specific metric. Specifically, the motivation behind using  a maximum intensity point and a maximum pitch point is not strong enough. Many nonlinear models could be used to account for intensity and pitch variations within the word. Thus, fine-grained changes in intensity and pitch within the word could be discerned. 
The number of tests, 36, makes  the analysis feel a bit like a “fishing expedition”, with multiple selected metrics and multiple testings of them. Bonferroni correction is applied to establish the alpha level, but it is calculated with the number of response variables (6) as a basis instead of the performed tests (36), although I do not think the results would have been too different with the alpha set at 0.001.","The authors chose to report duration, intensity and pitch as response variables. Mean and maximum intensity and pitch were extracted, but mean values were discarded afterwards. Choosing the maximum intensity within the word as the dependent variable can be problematic, as the maximum peak can be achieved in different positions within the word, and this would cause variation that would either obfuscate results or create patterns that do not reflect the real effect of the typicality predictor. Especially in the case of F0, modeling curves (e.g. with GAMMs, DCT transformation or fPCAs) would be more appropriate as much information is lost when using single data points as a dependent variable.
Lot of focus is put on the predictor “condition”, but the focus condition is not part of the research question. In addition, only one of the focus condition levels (NF) covers the whole typ_mean spectrum: ANF lacks values below 25 and AF lacks values over 70 (both having only two typ_mean clusters, as opposed to NF, which has three). Thus, the three levels of typicality (or typ_mean value clusters) are only represented in the NF level of “condition”.","The models are structured as lm(value ~ independent variable, data = .), where value represents the dependent variable. The authors explain previously, 6 lmer models were carried out with a random intercept for speaker, but that models had singularity issues, so speaker was removed and lm models were carried out. 
For the independent variable, the authors explain that they had 3 conditions, that resulted in 36 models: 
Separate models (with combined) condition: value ~ typ_mean (6 models)
Separate models per condition: value ~ typ_mean (6 models)
Condition as a factor but not interaction: value ~ typ_mean + condition (18 models)
Condition as a factor, with interaction: value ~ typ_mean * condition (6 models)
The rationale behind the inclusion of the variable condition or the interaction is not provided, and this choice is not explicitly justified by the research question.","Outliers from each metric were removed following a 2-standard deviation cutout. Mean and maximum intensity and pitch were extracted, but mean values were discarded due to their distribution not fitting gaussian. Aside from these and the sentences including notes in the original textgrids, there is no mention of further exclusions. This may not be enough. Our team had to mark extra sentences as errors or hesitation breaks in addition to the ones already marked as such in the provided textgrids. Errors and hesitation breaks likely affected the measurements (e.g. duration) in these sentences.","Duration values were log-transformed. All variables were z-transformed and centered. There were no further transformations and thus speech rate, inter-speaker and inter-utterance variation were not controlled for.",The script “data_cleaning.R” was mentioned in the report but not included in the data files.,1
anthracoceros_coronata,59,55,57,publishable with major revision.,"We had some issues with the way word boundaries were marked (who did this? did they receive training? how reliable was the marking?). Additionally, the report contained no predictions and no motivation for the variables that were selected. This makes it somewhat difficult to evaluate the results - the authors find some effects, but state they are unlikely to be of linguistic significance. We were wondering what standard is used for determining this. Also the visual representation of the results could have been a bit more intuitive.","The choice for linear mixed effect modelling is a good one. However, we did not fully understand why the models did not converge, and also wondered about the fallback to standard linear regression.","The focus on pitch, duration and intensity makes intuitive sense. However, why only mean and maximum are measured for each could have been motivated better.",No additional comments,No additional comments.,The way outliers were handles appears to be fine.,N.a.,"It was sometimes difficult to follow what the authors are doing exactly, and why they are doing it, also because the explanation is sometimes written down in a way that is a little confusing (e.g., ""Similarly, for pitch, the maximum pitch and the maximum intensity [should be “mean pitch” we assume] of the word were measured"")",1
anthracoceros_coronata,66,76,70,publishable as is.,"Segmentation was carried out at the word level and the team justifies this by pointing out difficulties in segmenting at the level of individual phones. Some of these difficulties also impact the segmentation at the word level, although this issue was not addressed in the report.

Acoustic correlates were measured at the word level and that probably affected the results, given the fact that the correlates the team chose to measure, duration, pitch and intensity are known to vary from syllable to syllable in a given word as a function of the degree of stress. So, measuring the correlates at the word level turns out no to be very informative and essentially limits the chance of observing a significant effect.

Three acoustic correlates were selected as dependent variables, despite the instruction given by the organizers to report just one numerical value in the final report.","The statistical analysis is very simple and straightforward, a simple linear model having the mean typicality index as dependent variable and the acoustic correlates as dependent variables. Separate models were run for what the team called ""condition"", that is, the three types of focus conditions (focus on Noun, Adjective or broad focus). The analysis seems appropriate in itself, although, as said before, the fact that the dependent variables were measured at the word level may have compromised the chance of detecting a significant effect.","As said before, the statistical analysis seems appropriate in itself, although the fact that the dependent variables were measured at the word level may have compromised the chance of detecting a significant effect.",The fact that the dependent variables were measured at the word level may have compromised the chance of detecting a significant effect.,The statistical model and the way it was structured is essentially correct and appropriate. A more sophisticated model would not make it more likely that an effect was going to be found.,The choices are very reasonable. Only trials that were labeled as containing error in the Notes field of the TextGrids were excluded. These corresponded to a small fraction of the total of trials.,"Raw duration values were log-transformed, which is a common practice. Log-transformed duration, intensity and f0 data was transformed to z-scores prior to the statistical analysis, which is also a common and reasonable choice, given the fact that the sample contained data from different speakers of both sexes and some form of data normalization is recommended in that case.",NA,3
