StartDate,EndDate,Status,IPAddress,Progress,Duration (in seconds),Finished,RecordedDate,ResponseId,RecipientLastName,RecipientFirstName,RecipientEmail,ExternalReference,LocationLatitude,LocationLongitude,DistributionChannel,UserLanguage,Q2,Q3,Q5_2,Q5_3,Q5_4,Q6,Q8,Q9,Q10,Q11,Q12,Q13,Q14,Q15
Start Date,End Date,Response Type,IP Address,Progress,Duration (in seconds),Finished,Recorded Date,Response ID,Recipient Last Name,Recipient First Name,Recipient Email,External Data Reference,Location Latitude,Location Longitude,Distribution Channel,User Language,"Your team name (i.e., the fantasy animal)",The team name (fantasy animal) for the analysis you are reviewing.,"Please rate the following aspects of the study under review with regard to how well they answer the research question (""Do speakers acoustically modify utterances to signal atypical word combinations in referring expressions?"") with the available data. - Rate the phonetic analysis","Please rate the following aspects of the study under review with regard to how well they answer the research question (""Do speakers acoustically modify utterances to signal atypical word combinations in referring expressions?"") with the available data. - Rate the statistical analysis","Please rate the following aspects of the study under review with regard to how well they answer the research question (""Do speakers acoustically modify utterances to signal atypical word combinations in referring expressions?"") with the available data. - Provide an overall rating",Would the analytical methods presented produce an analysis that is:,Please explain your ratings of this analysis.,Please evaluate the choice of statistical analysis type.,Please evaluate the process of choosing variables for and structuring the statistical model.,Please evaluate the suitability of the variables included in (or excluded from) the statistical model.,Please evaluate the suitability of the structure of the statistical model.,Please evaluate choices to exclude or not exclude subsets of the data.,"Please evaluate any choices to transform data (or, if there were no transformations, but you think there should have been, please discuss that choice).",Please use this space for any additional comment you may have at this stage.
"{""ImportId"":""startDate"",""timeZone"":""America/Denver""}","{""ImportId"":""endDate"",""timeZone"":""America/Denver""}","{""ImportId"":""status""}","{""ImportId"":""ipAddress""}","{""ImportId"":""progress""}","{""ImportId"":""duration""}","{""ImportId"":""finished""}","{""ImportId"":""recordedDate"",""timeZone"":""America/Denver""}","{""ImportId"":""_recordId""}","{""ImportId"":""recipientLastName""}","{""ImportId"":""recipientFirstName""}","{""ImportId"":""recipientEmail""}","{""ImportId"":""externalDataReference""}","{""ImportId"":""locationLatitude""}","{""ImportId"":""locationLongitude""}","{""ImportId"":""distributionChannel""}","{""ImportId"":""userLanguage""}","{""ImportId"":""QID2""}","{""ImportId"":""QID4""}","{""ImportId"":""QID6_2""}","{""ImportId"":""QID6_3""}","{""ImportId"":""QID6_4""}","{""ImportId"":""QID7""}","{""ImportId"":""QID9_TEXT""}","{""ImportId"":""QID10_TEXT""}","{""ImportId"":""QID11_TEXT""}","{""ImportId"":""QID12_TEXT""}","{""ImportId"":""QID13_TEXT""}","{""ImportId"":""QID14_TEXT""}","{""ImportId"":""QID15_TEXT""}","{""ImportId"":""QID16_TEXT""}"
2022-04-21 11:15:27,2022-04-21 11:31:29,IP Address,128.189.135.43,100,961,True,2022-04-21 11:31:30,R_3dYNhYGufMdfKUS,,,,,49.245,-123.1337,anonymous,EN,cromileptes_saxatilis,eosipterus_pytyopsittacus,55,30,20,publishable with major revision.,"I'd like to preface this by saying that overall, the analysis looks competently done, and clearly a lot of work has gone into it. I gave low ratings for the following reasons: (i) no scripts or other materials were shared, which compromises the replicability of the analysis; (ii) many analysis details are not reported transparently, and may only be replicable to those who are intimately familiar with the methods employed by the authors (and perhaps not even by those, given the lack of details); (iii) the project does not answer the MSA research question, which is clearly highlighted on the website, i.e. ""Your task will be to investigate whether typicality affects the phonetics of the utterances."". I gave the phonetic analysis a higher rating mainly to reflect the fact that what was done seems to be competently carried out, though it is very difficult to evaluate given the lack of details / scripts. I gave the statistical analysis a lower rating since – while clustering and random forests are great exploratory techniques – it did not address the main research question in any form. The overall score is the lowest as this project does not speak to the research question in any substantive way.","K-means clustering and random forests are great exploratory techniques, but they are not suitable for hypothesis testing. Although the research question here could probably be couched in exploratory terms, these techniques do not produce the kind of estimates (e.g. effect sizes, confidence intervals, etc.) that can easily be compared across analyses.","This process seemed largely appropriate, though it's not clear to me why the random forest was refitted with a smaller set of variables – isn't it clear from the full model that certain variables contribute less to the results than others?",The variables seem appropriate for (i) clustering accent types and (ii) predicting focus type – but not for answering the main research question.,"Both the K-means clustering and random forest models look OK, though, importantly, the models ignore dependencies within speakers and items, which is an issue here.",The exclusions reported in the survey responses seem reasonable & theoretically motivated.,"There were various derived measures that went into the models fitted by the authors, but there was not transformation per se. The calculation of these derived measures seemed fine, though it was hard to evaluate this process given the lack of details.",
2022-04-22 11:15:03,2022-04-22 11:24:08,IP Address,128.187.116.12,100,545,True,2022-04-22 11:24:09,R_2VNMgBcGq6LjaNC,,,,,40.2584,-111.6591,anonymous,EN,trapezia_cantonensis,comanthina_maculatus,95,90,92,publishable with major revision.,"The phonetic analysis seemed straightforward. Perhaps Praat is known to be not the best tool for F0 though and there didn't appear to be any sort of data verification/checking, etc. ","I appreciate that the author was aware of the assumptions of an ANOVA and chose to run non-parametric tests instead. However, as far as I know, a two-tailed unpaired t-test is parametric. ","Variable selection seemed fine, although there wasn't much discussion of what independent variables were included in the model. A more robust analysis would have perhaps logged the durations and added speaker and/or word as random effects. ","The dependent variables make sense. The independent variables could have been augmented with word and speaker as random effects. ","Again, a more robust analysis would have added speaker and/or word as random effects. ","There didn't appear to be any discussion of exclusions. ",A more robust analysis would have perhaps logged the durations.,
2022-04-22 12:43:30,2022-04-22 13:10:39,IP Address,71.178.216.156,100,1628,True,2022-04-22 13:10:40,R_2afzkhSr3wjNhz9,,,,,38.9208,-77.036,anonymous,EN,eosipterus_pytyopsittacus,psittacula_scabriculus,50,50,50,publishable with major revision.,,,,,,,,
2022-04-25 00:48:19,2022-04-25 00:50:12,IP Address,83.135.242.78,100,113,True,2022-04-25 00:50:13,R_2EmXjznKVeuNTRt,,,,,50.973,7.1754,anonymous,EN,petauroides_fistulator,polymetme_brevirostrum,90,70,80,publishable as is.,"We find that concerning the phonetic analysis and the resulting F0 values, one is commonly well-advised to use semitones instead of Hz values. However, this is the only minor comment we have on the phonetic analysis part.
Concerning the statistical analysis, we have little experience with running Bayesian models ourselves. However, having a look at relevant literature we find that the statistical analysis appears to be conducted in a meaningful manner without any issues that come to our (laypersons’) minds. Concerning the linear-mixed effects regression, we find that using rather complex effect structures as done in the present case, one should not neglect potential issues of collinearity. The authors of the present analysis do not check for such issues (or they do not mention doing so). As collinearity can lead to several problems regarding the model estimates, we find this point worth mentioning. 
The overall rating is the mean of both other ratings.","As mentioned above, we cannot speak in detail towards the Bayesian statistics part. However, regarding the mixed-effects regression part, we find no issue with the choice of model. Whether one applies such regression in a frequentist or Bayesian framework is a ‘matter of faith’, we believe. Thus, we have no negative points to raise. ","Using pitch range as dependent variable is motivated by other research; in fact, we used a rather similar approach to the question in our own analysis. 
The choice of independent variables is very straightforward; Condition, Typicality, and Category are meaningful predictors to answer the research question. However, the team does not provide a rational for their choice, i.e. they choice is not motivated by previous research or theoretical approaches.
The operationalising of all variables appears to be sophisticated as well. Using treatment coding for Condition and custom contrasts for Typicality seems reasonable to us. Fitting a maximal model to begin the modelling process with is one of the two prominent model building approaches (top-down/backwards vs. bottom-up/forwards) and aligns with our choice as well. Using rather elaborate random effect structures to begin modelling with, the present analysis tries to account for all potential inter-variable influences.","We find Condition, Typicality, and Category to be meaningful predictors to answer the present research question as these variables are directly related to the target items.","We find the structure of the linear mixed-effects regression model to be suitable for answering the present research question. Citing from Q11: Fitting a maximal model to begin the modelling process with is one of the two prominent model building approaches (top-down/backwards vs. bottom-up/forwards) and aligns with our choice as well. Using rather elaborate random effect structures to begin with, the present analysis tries to account for all potential inter-variable influences.","Excluding any observations that had comments in the “Notes” tier of the TextGrids is a reasonable choice. If such observations were without any issues to begin with, there would be no comments.","As mentioned in Q9, we assume that working with semitones instead of Hz is the better operationalisation for working with pitch data. Thus, we would have liked this team to work with semitones as dependent variable instead of Hz values.","We would like to stress again that, regarding the Bayesian part of the statistical analysis, we are laypersons. One group member has basic theoretical knowledge of Bayesian statistics from a linguistics perspective, another member as theoretical knowledge of Bayesian statistics from a mathematical perspective. However, no group member has ever worked with Bayesian methods from a practical point of view."
2022-04-25 02:57:44,2022-04-25 03:04:21,IP Address,91.169.106.116,100,397,True,2022-04-25 03:04:22,R_1HpM1jWH7K4mC7b,,,,,48.8138,2.3873,anonymous,EN,linckia_nattereri,gnathosaurus_canadensis,20,1,10,deeply flawed and unpublishable.,"I am not convinced of the approach to analysing the data and there are serious issues in the statistical approach. The author computed the average f0 per syllable in the adjective and the noun and computed the difference. This is fine by me at this stage. However, the computed mean difference was then transformed to be in an absolute value; this is a serious issue (see below) as the assumption then is that there will always be the “same” direction of difference; that the noun will always have a higher f0 than the adjective. 
Then, the median was chosen as a dependent variable, but this was computed based on the three mean values of f0 per participant and typicality. The SD is obtained, but no mention as to how this was computed. Why haven’t the author obtained the medial and SD of each syllable? The statistical approach used the “friedman test” which is a non-parametric alternative to an ANOVA with repeated measures. However, they had to obtain one observation per participant and typicality for the test to run, which is already an issue as within speaker variation is lost! ","This is motivated by the researcher to fit the data, but choosing this test restricts the author(s) in how they dealt with the data. The median used here is the median of the three repetitions per participant in a one of the three typicality contexts, rather than being the actual median for each syllable. I don’t believe this is the right tool, even if well-motivated. No pairwise comparison was proposed (you can use either a “wilcox test” or a “sign test” to do the pairwise comparison with corrections for multiple comparisons! Also, you have used R to compute your statistical analyses; Rstudio is an integrated development environment (IDE) for R (and Python, etc..). Make sure to cite the R version and the version of the package(s) used.","This is misleading as not described properly in the text. The difference in mean between the syllables in adjective and noun is computed initially correctly, but then for some reason, the author(s) decided to compute the absolute difference removing the sign; the sign is important here as this should correlate with differences in typicality (see dataset “MSA_extracteddata.xlsx” for original data). Then they used the median, which was obtained as the median of the three repetitions per typicality per speaker; this should have been obtained directly from the speech samples. 
We are told that the data from two speakers were considered as outliers and these were removed. It is not clear if there were already errors in data extraction that led to this. The analysis was done with and without these two speakers and the reported results 
","Variables included are not appropriate at all as the sign of the difference is lost; this needs to be retained. A clear justification for why only the mean value was obtained in the first instance is needed. 
The data from two participants were removed, with no clear justifications. You should have kept these. The author(s) decided to remove the data labelled with “errors”, which should be fine, though not clear at this stage why these were judged initially as “errors”
","Not entirely appropriate. There is no clear structure. I would have liked to see the following order:
1)	Data summary and description of the dataset
2)	Data visualisation to evaluate the patterns (simple box plots, or any other type of visualisation)
3)	Statistical modelling. 
a.	The author explains that the data are non-normally distributed; where are the analyses for that? 
b.	Normally, with this type of data, it is expected to have deviations from normality, and we are concerned with the normality of distribution for the residuals; were there any checks after the data analyses?
c.	Because you have three dependent variables, look at whether there are clear differences emerging from the three.
d.	Run a pairwise comparison
","The data from two speakers were excluded (though the results were presented with and without). The data were removed due to them being outliers; not clear if the author(s) chose a specific threshold (2.5 above/below the mean?). ","The author(s) use semitones instead of Hertz, which is fine. 
They did not use any specific transformations of the dependent variable, although they decided to compute the absolute difference rather than the true difference. This shouldn’t be done.
","Make sure your R script has all the steps of data analyses, e.g., importing the data set, visualisation (if any) method used to check outliers, etc..
I only spotted the error of using the absolute mean difference by opening the second excel sheet. When running the statistical analyses on the median based on the original mean differences, there are clear differences emerging in the data. 
Friedman rank sum test

data:  test$median, test$typicality and test$speaker
Friedman chi-squared = 9.2667, df = 2, p-value = 0.009722
I still do not believe that the test used here is appropriate (run linear mixed effects modelling and check the residuals or a Bayesian approach).
"
2022-04-25 04:14:17,2022-04-25 04:45:50,IP Address,141.201.219.162,100,1893,True,2022-04-25 04:45:51,R_31bdgtoomOtHQqt,,,,,47.8008,13.0443,anonymous,EN,anomalocaris_ornata,trapezia_cantonensis,86,86,86,publishable with minor revision.,"We really enjoyed reading this analysis, it was very well presented and the graphics were very clear and informative. We believe there are only some minor issues in the report.

There are some confusing typos in the report, for example, the introduction talks about three measurements, 1.1 talks about 4. Under 3.4 non-food treatments are significantly longer than non-food treatments? In places, information is missing for example on how vowel formants were normalised. ","GAMMs are appropriate for the dynamic F0 and intensity data. Likewise, the mixed model is appropriate for the static vowel duration data.",The process seems fine and to make sense with what is in the published literature.,"It is unclear why only the adjective was chosen for analysis over other possible variables such as the noun. It is also not completely clear what typicality measure was used in the models. ",The process seems fine and to make sense with what is in the published literature.,"The author focuses exclusively on the adjective of the NP. Considering the noun is in focus position, it would make sense to explore the adjective and noun in tandem. Any increases in intensity, F0, etc. could in principle be accompanied by a similar increase in the noun – or not. Looking at adjective and nouns gives us a fuller picture of what is happening. 

The author focuses exclusively on the stressed vowel. While other options are possible, this strikes us as a justified choice as any typicality-based modulation should be captured by looking at the vowel only.
","F0 data are notoriously often non-normal, it would be good to have an idea of what the distribution looked like. The author is not terribly specific about how normal these data were. It is also unclear how higher and lower voice types (which might differ significantly between speakers) was considered in the analysis.",Thanks for an interesting read!
2022-04-25 06:05:43,2022-04-25 06:12:09,IP Address,91.169.106.116,100,386,True,2022-04-25 06:12:10,R_2B8WgXMbPdw8ncI,,,,,48.8138,2.3873,anonymous,EN,linckia_nattereri,gnathosaurus_canadensis,20,1,10,deeply flawed and unpublishable.,"We are not convinced of the approach to analysing the data and there are serious issues in the statistical approach. The author computed the average f0 per syllable in the adjective and the noun and computed the difference. This is fine at this stage. However, the computed mean difference was then transformed to be in an absolute value; this is a serious issue (see below) as the assumption then is that there will always be the “same” direction of difference; that the noun will always have a higher f0 than the adjective. 
Then, the median was chosen as a dependent variable, but this was computed based on the three mean values of f0 per participant and typicality. The SD is obtained, but no mention as to how this was computed. Why haven’t the author(s) compute the median and SD for each syllable directly from within Praat? The statistical approach used the “friedman test” which is a non-parametric alternative to an ANOVA with repeated measures. However, they had to obtain one observation per participant and typicality for the test to run; they don't make the most of the available variability which, in turn, might lead to oversimplified conclusions.
","This is motivated by the researcher to fit the data, but choosing this test restricts the author(s) in how they dealt with the data. The median used here is the median of the three repetitions per participant in a one of the three typicality contexts, rather than being the actual median for each syllable. We don’t believe this is the right tool, even if well-motivated. No pairwise comparison was proposed (the author(s) can use either a “wilcox test” or a “sign test” to do the pairwise comparison with corrections for multiple comparisons). In addition, you have used R to compute your statistical analyses; Rstudio is an integrated development environment (IDE) for R (and Python, etc..). Make sure to cite the R version and the version of the package(s) used.","This is misleading as not described properly in the text. The difference in mean between the syllables in adjective and noun is computed initially correctly, but then for some reason, the author(s) decided to compute the absolute difference removing the sign; the sign is important here as this should correlate with differences in typicality (see dataset “MSA_extracteddata.xlsx” for original data). Then they used the median, which was obtained as the median of the three repetitions per typicality per speaker; this should have been obtained directly from the speech samples. 
We are told that the data from two speakers were considered as outliers and these were removed. It is not clear if there were already errors in data extraction that led to this. The analysis was done with and without these two speakers and the results were reported with and without these two speakers.","Variables included are not appropriate at all as the sign of the difference is lost; this needs to be retained. A clear justification for why only the mean value was obtained in the first instance is needed. 
The data from two participants were removed, with no clear justifications. You should have kept these. The author(s) decided to remove the data labelled with “errors”, which should be fine, though not clear at this stage why these were judged initially as “errors”","Not entirely appropriate. There is no clear structure. I would have liked to see the following order:
1)	Full data wrangling in the main R script: add details of how the median was computed.
2)	Data summary and description of the dataset
3)	Data visualisation to evaluate the patterns (simple box plots, or any other type of visualisation)
4)	Statistical modelling. 
a.	The author explains that the data are non-normally distributed; where are the analyses for that? 
b.	Normally, with this type of data, it is expected to have deviations from normality, and we are concerned with the normality of distribution for the residuals; were there any checks after the data analyses?
c.	Because you have three dependent variables, look at whether there are clear differences emerging from the three.
d.	Run a pairwise comparison
","The data from two speakers were excluded (though the results were presented with and without). The data were removed due to them being outliers; not clear if the author(s) chose a specific threshold (2.5 above/below the mean?). ","The author(s) use semitones instead of Hertz, which is fine. 
They did not use any specific transformations of the dependent variable, although they decided to compute the absolute difference rather than the true difference. This shouldn’t be done.
","Make sure your R script has all the steps of data analyses, e.g., importing the data set, visualisation (if any) method used to check outliers, etc..
We only spotted the error of using the absolute mean difference by opening the second excel sheet. When running the statistical analyses on the median based on the original mean differences, there are clear differences emerging in the data. 
Friedman rank sum test
data:  test$median, test$typicality and test$speaker
Friedman chi-squared = 9.2667, df = 2, p-value = 0.009722
However, we still do not believe that the test used is appropriate (run linear mixed effects modelling and check the residuals or a Bayesian approach).
"
2022-04-25 07:19:30,2022-04-25 07:21:48,IP Address,128.91.19.21,100,138,True,2022-04-25 07:21:48,R_2wNaoi7Cuoh8JSr,,,,,39.9597,-75.1995,anonymous,EN,eosipterus_pytyopsittacus,psittacula_scabriculus,50,50,50,publishable with major revision.,"We have a few major concerns with both the phonetic and statistical analysis presented here. On the phonetic side, the main issues are with the fact that the vowels were hand-measured, and given that the analysis relies on precise measurements of duration. The authors should’ve used one of the many available forced aligners to have a consistent method for measuring duration. Additionally, the fact that they took an average of all vowels in each word does not account for the fact that the data included tokens of varying syllable length, which could impact their results (and no hypothesis was given to justify this measure of length effects). Finally, they did not differentiate between stressed and unstressed vowels, which naturally have different durations and could significantly impact their results, given the aforementioned differences in number of syllables between target words. 
","On the statistical side, see below for more details, but the chief concern is that vowel duration should have been normalized in some way, and they should have accounted for vowel stress. The model is simple and straightforward and is logical given the data structure, but it does not include all necessary variables, and is based on flawed data. ","The process for choosing the variable of vowel duration seemed appropriate. One limitation is that the team used default priors from bmrs, which may be suitable but they should’ve motivated this choice and also discussed it as a possible limitation. ","While the choice of duration is appropriate, it does seem that the values of the variables should have differed, however, in at least two ways. Vowel duration should be normalized (to control for effects of variable speech rate). Also, the vowel duration should not have been an average, for one of at least two reasons. As a first possibility: If the stressed vowel is changing in duration differently than other vowels (e.g., possibly as the only vowel changing in duration), then using an average of all vowels will lead to different effect sizes in words with different numbers of syllables (because the effect of change in a stressed vowel will be less in a 4 syllable word than in a 2 syllable word). As a second possibility: since stressed and unstressed vowels naturally have different durations, differential proportions of stressed-to-unstressed vowels could significantly impact their results.","The model structure is suitable, and we appreciate the authors’ attempts to use Bayesian models.","The only data excluded was from speech errors (as determined by the researchers) and vowels that they claim were “unrealized”. This is fine, but more detail about what counted as “unrealized” would have been helpful. ","The vowel durations should have been normalized, so as to make comparisons across individuals / contexts (because of what’s known about speech rate variability).","As a minor detail: the .xlsx file is included, but not the .csv file that the .Rmd alludes to.

As a more important detail: the .docx writeup alludes to the mean vowel duration for the atypicality condition as either .08 (in table 1) or as .09 (in the prose). After running the included R file, it seems the prose is correct.

Finally, because there were the earlier-mentioned methodological problems, and because the results go in the opposite direction of expectation (no hypothesis we can think of would expect medium typicality to have the shortest duration; the null hypothesis should be atypical > medium > typical), the model (and especially the data-prep for the model) ought to be given much more scrutiny (in ways described above).
"
2022-04-25 06:44:03,2022-04-25 07:40:11,IP Address,138.246.3.41,100,3368,True,2022-04-25 07:40:12,R_2EgWYqa9K1rIrP3,,,,,48.1336,11.5658,anonymous,EN,gnathosaurus_canadensis,ctenosaura_limax,100,100,95,publishable as is.,The way the analysis was done is well explained and replicable with the provided ressources,Multinominal logistic regression is definitely a suitable model for the research questions.,"Three groups of models were used, the first used a subset of features, the second all extracted features and the last was a random baseline. Why and how the specific features were chosen for model 1 is kept rather vage, and it is not explained why these variables are more interpretable than others though I do agree that the variables are well-known and that these three groups of models make a lot of sense for being able to interpret the results.","The variables chosen for model version 1 are well-known and well-studied features in prosody, so they are suitable to investigate the research question. However, the reason for excluding the other variables is not well-explained. Especially how the original 20 features from the list 88 features is not explained. This likely will not alter the results, so I did not deduct any point for this, I just personally would have found it interesting. Especially with regards to the variables that are highly correlated, I would have found it interesting 1) which variables those are and 2) which variables were excluded based on this criterion and why these specific variables were excluded.","For the research question, I find the three models well-suited.","The analysis did not exclude any tokens from the critical condition, i.e., incorrectly produced sentences were included in the analysis. I personally would have excluded incorrectly produced sentences, however, since there were not a lot of them in the data set, it likely does not make a large difference not to exclude them.","I have not used the tools myself but based on the explanations in the report, the transformations seem fine to me.","It is hard for me to evaluate this analysis since I have not personally used most of the tools, e.g., the openSMILE tool, and models described. Because of this, I cannot really judge how accurate the results are, only that I find the choice of methods well-explained."
2022-04-25 13:08:23,2022-04-25 13:28:18,IP Address,67.1.148.177,100,1195,True,2022-04-25 13:28:19,R_1PdQ49t7rNPDNVu,,,,,32.1943,-110.9767,anonymous,EN,dermatolepis_aculeatus,swiftia_ruber,95,100,95,publishable with minor revision.,The analysis was very good.,The choice was very good.,"One thing they don't address is the (very frequent) reduced speech, which altered the syllable count. This will change their sw#sw pattern and must be addressed. Did they exclude these tokens? Did they get parsed as if they were sw#sw patterns when they were s#sw (or something else) instead? Also there was no discussion of how they treated hesitation breaks/pauses, which may disrupt the sw#sw pattern. Ultimately we don't think it will change the analysis, but it is an issue.","They excluded (or they're missing) speaker PS for unknown reasons. They didn't mention what they did with ""error""-marked trials.",Very good.,Very good.,Scaling of pitch f0 was very good.,Minor typos (totalling 348 typical and 348 typical phrases).
2022-04-18 07:11:11,2022-04-18 13:41:12,IP Address,92.10.240.239,25,23400,False,2022-04-25 13:41:13,R_2whFClan6tUWgjM,,,,,,,anonymous,EN,,,,,,,,,,,,,,
2022-04-18 13:49:34,2022-04-18 14:05:14,IP Address,129.107.80.47,20,939,False,2022-04-25 14:07:27,R_vfvyDCv0HnXFxzX,,,,,,,anonymous,EN,epinephelus_aztecus,haematopus_fossor,,,,,,,,,,,,
2022-04-26 01:48:54,2022-04-26 02:11:11,IP Address,139.124.248.164,100,1337,True,2022-04-26 02:11:12,R_YYO2BGSOpcwCrqV,,,,,43.5312,5.4554,anonymous,EN,eriphia_laterispinis,varanus_eulophotes,90,60,80,publishable with minor revision.,"The phonetic analysis seems sound, and the statistical analysis conforms to standards in the field, which is both a good and a bad point (see details below).","The authors report that the residuals of the LMM was not normally distributed. Then, they report that log- or inverse-transforming the dependant variables also lead to non-normally distributed residuals. From there, they chose to use a Gaussian model without transformation, ignoring the failure of their assumption checks. A better option would have been to try other transformations and/or other likely functions for the model.",The choice of variables seems sensible.,The choice of variables seems sensible.,"The structure of the model seems OK (although it could be improved, see the assumptions check issue explained above).","No data were excluded, which seems OK.",I think the data do not necessarily to be transformed but different distribution assumptions should have been tried within the statistical models (see my previous point).,I have no additional comments at this point. Congrats to the authors for a (overall) very sound and well conducted analysis.
2022-04-26 07:51:07,2022-04-26 08:16:29,IP Address,87.169.109.146,100,1521,True,2022-04-26 08:16:29,R_UA6uDUUCzjUuSnD,,,,,48.1355,11.5911,anonymous,EN,procambarus_maculosus,procambarus_mahogoni,20,30,25,deeply flawed and unpublishable.,"Both analysis script and written summary are not sufficiently comprehensive. A short report is totally okay, but content descriptions and explanations regarding dataset, extraction of studied parameter and statistical method are missing. The choice of mixed models is appropriate as are the dependent variables and fixed factor; however, repeating the fixed factor (typ_median) in the random factor structure is a highly irregular practice and, in this case, leads to estimation errors for the random effects. Two of the three statistical models resulted in singularities which makes the results unreliable and unpublishable. The selection of the analysed data subset is described inaccurately. The measurement methods and further standardization procedures are not discussed or derivable from the given information. Only the vowels in the colours were analysed but not the target words. There are no expectations as to the direction in which typicality could influence the three parameters studied.",Suitable. Mixed models allow for the integration of fixed and random factors. This makes it possible to comprehensively cover influences on the variation of the dependent variable. They are insensitive to an unbalanced number of values in the data set and therefore fit the given speech data.,"Not evaluable, as the process is not described and the selection of variables is not explained.","Overall, the used variables seem reasonable. However, more variables (especially, but not only,  more random factors and slopes) could have been integrated to improve the model. E.g.: word/vowel, possibly other speaker characteristics that could influence the F0 height or intensity (e.g. F0 is generally higher for women). It is unknown which variables were intentionally excluded from the model and it is not described why typ_median was used instead of the ternary typicality groups.","Dependent and independent variables are appropriate according to the research question. In each of the three statistical models, the fixed factor referring to the typicality score is at the same time integrated as a random factor within the same model, which is questionable.","Focus on NF is appropriate. The colours are compared, but not the target words. The advantage of using the colours is that there is a balanced set of words in relation to the typicality groups. It is unclear, however, why a typicality effect should show in the colour instead of the target words. The choice of which vowels to analyse is neither described nor evident from the script. From the attached data set, it can be assumed that the stressed vowel (V1) from the colour was analysed. The colour words in NF were: “gelb, grün, rot, orange, braun“. The stressed vowel in ""orange"" is the second and is in the csv coded as V1 and thus in the analysis. However, it looks like the first vowel /ɔ/ of “orange” was also analysed (the vowel /ɔ/ is also noted as V1 and is thus included in the analysis), although this is not the stressed vowel in the word.","These are difficult to understand. Were the speech signals opened in Praat and the analysed parameters determined manually and transferred to the table? Or were there any Praat-Scripts used for this? To which words do these vowel segments listed in the csv table belong, and which position do they occupy in the word (especially as regards the word “orange”, /ɔ/ und /a/ segments)? There is no explanation as to why the dependent variables were converted into a general standardised measure and not normalised in a speaker-specific way. A normalisation of vowel duration with regard to speaking rate instead of using the pure duration prior to standardisation would have been useful. Considering the intensity of the vowel not absolutely, but relatively - i.e. in comparison to other segments/vowels of the same speaker - could be worthwhile.
How exactly was F0 measured? Which algorithm was used to extract the F0 signal?",Calculation of the effect size (“Cohen D”) is neither described in detail nor is the method of computation shown.
2022-04-26 10:15:41,2022-04-26 11:08:03,IP Address,73.14.34.31,100,3142,True,2022-04-26 11:08:04,R_1qVO2H7FZxFNC2s,,,,,40.0373,-105.279,anonymous,EN,clione_dorsalis,nestor_idahoensis,55,75,65,publishable with minor revision.,"Rating of phonetic analysis: no interpretation of F1 and F2 data is provided in the analysis, and isn't easily interpreted. Because different directions of effect (i.e., F1 should decrease with vowel space dispersion for high vowels and increase with vowel space dispersion for low vowels) are expected by vowel it's unclear how to interpret a main effect of typicality on F1 or F2. 
Rating of statistical analysis: The statistical analysis is largely sufficient; the authors wrote a clear analysis and description of their statistical methods. We're not sure whether including words (which is effectively vowel) as random slopes was appropriate, because the directions for the F1 and F2 variables vary predictably by vowel. We would have appreciated more justification for the choice of using random slopes for word effects rather than a fixed effect, and the implications for interpretation of the main effect of typicality on F1 and F2. ","The Bayesian analysis was well-motivated. ","The independent variable addressed the research question. 
The dependent variables duration and F0 were appropriate. F1 and F2 were relevant, but required further interpretation as described above. ","The variables were suitable to include in a model investigating the effect of typicality on prosodic realization.  ","Given that word and vowel are identical features, including word as a random effect rather than a fixed effect made the results of the model difficult to interpret because of the different predictions for F1 and F2 by vowel. ","The researchers made appropriate choices to exclude unlikely measurements from their analysis. ","The researchers made appropriate choices to log transform data. ","We acknowledge that our expertise is limited in evaluating the technical aspects of a Bayesian statistical model. "
2022-04-26 10:12:57,2022-04-26 11:29:17,IP Address,188.210.214.2,100,4580,True,2022-04-26 11:29:18,R_3CBYPaJFZBssrXa,,,,,55.867,-4.2621,anonymous,EN,psittacula_scabriculus,clione_dorsalis,90,80,85,publishable with minor revision.,"The analysis is very good. However, at some points a bit more explanation or supporting sources could be added as to why these predictors were chosen (f.e., gender). Also, the factors were releveled but it doesn't become clear from the code whether the presented statistics were based on the default dummy coding, or some sum coding, for instance. That won't change the results bit might slightly change the values, particularly the estimate. ",The chosen of statistical analysis is good and appropriate for the type of data.,"As mentioned before, it might be good to add some brief notes of why the authors had decided upon controlling for gender (maybe some past literature). ",The variables seem all very suitably chosen for the model.,The statistical models are structured well.,NA,"As per my note above, possibly consider changing the contrast type, for the sake of presentation of the final statistics numbers.",NA
2022-04-19 10:41:22,2022-04-19 13:01:41,IP Address,5.132.95.23,40,8419,False,2022-04-26 13:01:42,R_30racGKw6LQ9nkB,,,,,,,anonymous,EN,ctenosaura_limax,cromileptes_saxatilis,10,55,3,publishable as is.,,,,,,,,
2022-04-26 18:24:27,2022-04-26 18:32:14,IP Address,73.235.22.233,100,466,True,2022-04-26 18:32:14,R_1FDtmuKCgiUMtJO,,,,,38.5559,-121.7391,anonymous,EN,pervagor_meeki,trachyphyllia_lappa,75,70,75,publishable with major revision.,"The analyses reported by this team are overall appropriate for this data and design. In particular, we agree with the team’s choice to analyze word-level acoustic features (pitch, duration) that correlate with focus using linear mixed effects models, which allows the team to control for individual differences across speakers. We also agree with the choice to only analyze NF trials, as trials in other conditions did not present a well-balanced typicality manipulation.
However, we have questions regarding some of the choices made by the team, which could have been justified more thoroughly in the report. These include the choice to only analyze half of the data rather than including “repetition” as a covariate in the models; the choice to include “phrase” as a random effect, and to include “color” as a fixed effect even for the models on the nouns; the choice to ignore singular fit in the lmer model; the difference between min/max f0 and f0 range and the parameters used to extract f0. We elaborate on these and other issues in response to the following questions.",Linear mixed effects models are an appropriate choice of analysis.,"In response to this question, we address concerns with the selection of independent variables and random effects. 

1. The choice to include “phrase” as a random effect was not well justified. First, it was unclear what was meant by “phrase” in the report; by looking at the R script provided, we found that “phrase” referred to the specific color-noun combination. However, that is equivalent to using the target noun as a random effect, since each noun was only paired with a single color in the NF condition. A potential issue with including noun/phrase as a random effect is that nouns were not crossed with typicality (each noun only occurrent in one typicality condition); this may lead the models to attribute variance due to typicality to word specific effects, which may have contributed to the generally null effects of typicality in these models. Therefore, we would recommend that the team provides a more thorough justification for why the noun/phrase random effect should be included. 

2. While looking at the R code, we also detected a minor issue with the generation of the phrase variable: in two cases (“braunen-Paprika” and “orangen-Trauben”) an extra space was added at the end of the color in some trials (“braunen -Paprika” and “orangen -Trauben”) leading to two spurious extra phrases with just 2 observations each. If the team keeps phrase as a random effect, they should address this minor issue so that phrase is coded correctly.

3. There could also be more justification for the choice to include color as a fixed effect in all models, including the models on the nouns.

4. We appreciated that the team raised the issue of repetition in shaping typicality effects. We suggest that the team could have added “repetition” (first or second time each noun was uttered in the NF condition) as a covariate in the models to address any potential repetition effects. 
","In response to this question, we address concerns with the selection of dependent variables.

1. Pitch and duration, measured at the word-level, are relevant measures of prosodic prominence. The team could also have measured intensity, a similarly relevant measure that has consistently been associated with focus, or explained whether there were any reasons why they did not think this measure was appropriate.

2. The report should have included more details about the parameters used in the Praat script to extract f0. In particular, we have the following questions: given that pitch range is usually measured as the difference between min and max f0, why was range used as a separate variable in addition to min and max f0? What parameters were used to determine plausible f0 measurements, and were they the same across speaker genders? While looking at the f0 data collected by the team, we found that a large percentage of words led to “undefined” f0 measurements (presumably outside the preselected bounds); a different set of parameters may have led to fewer data exclusions and, therefore, greater statistical power.
","1. When looking at the R code provided, we noticed that the team suppressed the “singular fit” warnings produced by lme4 by default. By running the models without this suppression, we found that all models led to a singular fit, indicating that the random effects structure may have been too complex for the small dataset used in these analyses. While there is some debate as to whether random effects should be simplified to avoid singular fit or not, the developers of lme4 (the package used in these analyses) recommend avoiding singular fit (see the lme4 documentation, https://search.r-project.org/CRAN/refmans/lme4/html/isSingular.html). In particular, they warn that Wald statistics (e.g. chi square) and likelihood ratio tests may be inappropriate when applied to models with singular fit. As the team relied on these types of tests to assess significance, we recommend that they simplify the random effects structure to avoid singular fit; alternatively, if they wish to retain the maximal structure even with singular fit, we suggest that they reconsider the type of significance test being used. More generally, we recommend that the team address and justify their reasons for ignoring the singular fit warning.

2. In both the R code and the report, the team did not specify what type of contrasts were being applied to the fixed effects in the models. As the contrasts were not defined in R, the models presumably used the default dummy coding, with “atypical” as the default baseline for typicality (being first alphabetically). Contrasts may not have been relevant to this team, as they did not report any of the model estimates but rather tested significance using chi-squared, likelihood ratio tests, and eta squared effect sizes. However, we would recommend that the team still define the fixed effects contrasts in order to produce interpretable estimates relevant to the hypothesis (for a review on the importance of setting and reporting contrasts, see Brehm & Alday 2022, JML, https://osf.io/9648f/). Reporting individual contrasts (e.g., atypical vs typical, atypical vs medium, etc…) may also reveal more nuanced effects of typicality that may not have been captured by the effect size for the overall effect of typicality across all levels.","1. We agree with the team’s choice to exclude error trials, including the additional errors identified by the team and not by the study coordinators.

2. We do not agree with the choice to only analyze the first mention of each color-noun phrase for each speaker, which is equivalent to only analyzing half of the data. This undoubtedly led to lower power in the models, which were already too complex for this small dataset. The team raised a valid issue by noting that each color-noun phrase was repeated twice for each speaker, and that this repetition may have influenced prosodic prominence; however, rather than eliminating half of the data, we suggest that the team could have added repetition as a covariate in the models (which we would find more justified than adding color as a fixed effect).
","It is debatable whether linear models are appropriate to analyze non-transformed pitch in Hz, which is not normally distributed. We would recommend performing a transformation on Hz to render it more linear (e.g., log or semitones), or to justify the choice not to transform Hz.
","The team used an overall solid approach for data originating from a limited dataset with some design flaws. We agree with the major steps taken by the team in the analysis, including the choice of DV and the type of models used. We raise some concerns regarding some of the team’s choices, which we believe could be addressed by modifying some aspects of the data analysis and/or by further justifying those choices in the report.

Another minor comment: the report and figures did not specify which units were used to measure duration (e.g., seconds or milliseconds). This could be inferred by the unit size on the Fig. 1 y-axis, but we recommend that the team include the units more explicitly.
"
2022-04-27 03:00:47,2022-04-27 03:18:23,IP Address,144.32.240.17,100,1055,True,2022-04-27 03:18:23,R_VXaobjXzPIPuFVf,,,,,53.9573,-1.0837,anonymous,EN,pervagor_adscensionis,paralichthys_undulatus,90,90,90,publishable with minor revision.,Solid statistical analysis,Mixed effects fairly standard in the field,Appropriate,Appropriate,Suitable for the data and the question,Only used NF as this was the only condition that directly answered the research question,f0 transformed to semitones which should normalise across sex (but some justification needed for the specific setting chosen),
2022-04-27 04:46:09,2022-04-27 06:41:38,IP Address,92.5.242.235,100,6929,True,2022-04-27 06:41:39,R_3sM0cVnxHNxUcZr,,,,,53.4606,-2.2572,anonymous,EN,naso_cassivellaunos,linckia_nattereri,66,70,23,publishable with major revision.,,,,,,,,
2022-04-26 03:10:02,2022-04-27 07:07:01,IP Address,88.10.224.231,100,100619,True,2022-04-27 07:07:02,R_1LBBX8gnuyDmgfY,,,,,43.3126,-1.9745,anonymous,EN,gymnothorax_spinulosus,trigonias_lachneri,80,35,50,publishable with major revision.,"The phonetic analysis methodology is justified with literature, and I appreciate that the composite measure makes it possible to avoid the problem of choosing which of F0, duration or intensity should be the dependent variable after starting the statistical analysis. But the measure that was used came from a paper that had nothing to do with phrasal prominence or typicality and might not have been sensitive enough for the purpose of this analysis. 
The biggest problem I see with the statistical analysis is the choice to simply ignore the AF and ANF conditions, and keep only data from NF condition. This choice is hard to understand for two reasons: (1) Phrasal prominence is bound to have a big impact on the stress pattern of the sentence, and it is possible or even likely that typicality, if it has an effect on prosodic prominence, would not have the exact same effect in different phrasal prominence conditions. And (2) this choice ignores the explicit design of the experiment. 
","The choice of mixed models is a good one for this type of dataset, in order to control for variability coming from the participants and the stimuli. "," As explained above, it is hard for me to understand the choice of ignoring 2 experimental conditions in the statistical model and therefore not using condition as a variable in the model. It might also have made sense to include some effects usually included in phonetic analysis, for example a fixed effect of gender. It is possible however that the type of composite variable used makes adding a gender effect unnecessary. Also there is nothing about comparing the model with simpler models (or more complex models) to see if the model is the right one.
Besides, the choice of using the mean typicality (rather than the median, or the categorical values) is not explained. But I feel that justifying this choice (at least between mean and median) is a hard problem that we did not solve in our group either.","Typ_mean sounds good to us. The composite variable as well.
Random effects are ok. Condition variable is missing as we already explained.","Given the data that they have selected the model is suitable. But if they had kept data from all 3 conditions (AF,NF,ANF) they should have included the condition as a fixed factor in the model as well as the interaction condition:typ_mean
They could include all the random effects in the model , which is fine (but would probably not have been possible with a more complex model including condition). Also, they should have checked the normality of their residuals to verify that the model is suitable.","They excluded all data from NF and ANF condition.  They say they did so because in these conditions the typicality was not balanced. But to us this reason would only make sense if they used the typicality categories. Since they used the mean_typicality this should not be a problem. 
The data with errors was rightly excluded. I believe that it would have been necessary to further check the automatically extracted acoustic analyses to make sure they did not contain nonsensical values. For instance they could have excluded outliers in intensity /duration.
They excluded all data from NF and ANF condition.  They say they did so because in these conditions the typicality was not balanced. But to us this reason would only make sense if they used the typicality categories. Since they used the mean_typicality this should not be a problem. 
The data with errors was rightly excluded. I believe that it would have been necessary to further check the automatically extracted acoustic analyses to make sure they did not contain nonsensical values. For instance they could have excluded outliers in intensity /duration.
","Not knowing the measurement used very well, it is hard to judge if it is a priori reasonable to log-transform it. That being said if I understand correctly the model assumptions for mixed-effects models, it is the residuals of the model that should be normally distributed, not the data itself, so the justification provided for log-transforming data is not correct.",no further comment
2022-04-27 08:18:09,2022-04-27 08:30:59,IP Address,144.82.60.13,100,769,True,2022-04-27 08:31:00,R_1jlxb4biV5eVFWl,,,,,51.6115,-0.2496,anonymous,EN,stygobromus_tyraica,hoplostethus_macrosteus,65,25,45,publishable with major revision.,"We found the segmentation criteria referenced to be generally rigorous, and spot checks of TextGrids did not reveal major concerns with regard to segmentation, but there were minor issues with annotation. We also did not have concerns with the Praat script used to extract acoustic measurements. However, given the challenges in segmenting liquids as mentioned in the authors’ response, some more in-depth discussion of how inter-rater reliability checks were conducted, as well as reporting of the results of such checks, would have been appropriate. There could also be more clarify as to what “coarticulated” referred to in relation to the segmentation of /Vl/, whether as opposed to deletion or assimilation or not, since that would presumably have a systematic effect on duration. In combination with the above, our rating for the phonetic analysis further reflects our concerns for the specific features chosen for analysis, which we elaborate below. While many of these analyst decisions could certainly be justifiable, we were often not provided with such justifications.

While the statistical analysis followed a generally accepted framework, there were issues with how models were formed and evaluated, meaning that one of the models in question could not adequately address the research question posed. Our rating for this part is thus a reflection of what we consider a flawed and somewhat misleading analysis that is likely to produce an unreliable estimate of the relationship between the variables.",We consider the use of linear mixed-effects modelling to be appropriate.,"We found the process of model selection to be problematic. The various models fitted in the Rmd for duration and intensity indicate the lack of a principled approach in deciding whether each factor should be included as a fixed effect or a random one. More generally, we do not consider the decision to include ‘color’ as a fixed effect to be sufficiently justified in this case. We also do not consider it appropriate to model the full datasets for comparison, when it has already been decided that outliers should be removed. Furthermore, when comparing model fit using AIC, models should be fit with ML rather than REML for the comparison to be meaningful. In this case, m3.5 would not have been considered an improved fit over m2.5 (the difference in AIC being less than 2).","Duration and maximum intensity of the stressed vowel are certainly relevant variables to include, although we remain curious as to the exclusion of other related features extracted from the Praat script. While the exclusion of f0 and formants is not problematic per se, the authors’ concerns could have been addressed by means of by-speaker normalization, and we believe that stronger justification could have been offered for their exclusion.

Other independent variables were suitably included in the model, but, as above, we question the choice of including ‘color’ as a fixed predictor. ","We are of the opinion that the final model for duration was not appropriately structured. The way the interaction was included and subsequently tested (via Anova) does not in fact permit the significance of the specific typicality x color interaction term to be tested, or indeed the main effects of each fixed predictor. If, instead, a “typicality * color” term were included in the model formula, the p-value for the typicality:color term would come out as approximately 0.025, which would have to be more cautiously interpreted, since Wald z-test is known to be anti-conservative (thus reinforcing our concern above in Q11 that including the interaction would not seem to improve model fit by AIC). The model for intensity did not suffer from the same issue. The use of treatment/dummy coding here, as opposed to sum coding, would have an impact on the interpretation of intercepts and effect sizes, especially where interactions were concerned.","We consider excluding trials marked with “error” or “hesitation break” when the target is affected to be an appropriate choice. However, the blanket exclusion of values beyond 2SD from the mean is typically considered to be a heavy-handed approach, and we do not consider it to be sufficiently justified in the present case.","Contrary to the authors’ response, they did not in fact center and scale the dependent variables for modelling. This was only done as an intermediate step to exclude outliers.","We encountered a number of challenges navigating the Rmd when attempting to reproduce the results. The principal difficulty arose from the fact that Results_clean.csv was not provided, but the way it was used in the Rmd also indicates that it was not the direct output from the Praat Script and that much additional manipulation was required to arrive at a suitable form. Relatedly, there were inconsistencies in how tokens were labelled in the TextGrids, some of which resulted in ambiguity that required additional checking (in particular, ‘g’ referred to both ‘gelb’ and ‘gruen’ depending on the speaker). We were unable to reproduce the step excluding outliers for intensity, as the code excluded 36 instead of 33 observations for us. Reproduction would also have been aided by a tidier Rmd with more user-friendly comments and with redundancies removed (e.g. all the packages that were in fact not used), as well as the HTML output knitted from the Rmd."
2022-04-27 12:06:39,2022-04-27 12:16:46,IP Address,67.218.235.188,100,606,True,2022-04-27 12:16:47,R_phg2ZETCJTPHKHD,,,,,43.3126,-1.9745,anonymous,EN,pseudodax_euryzona,haematopus_fossor,65,70,70,publishable with minor revision.,"This analysis reports multiple tests of three different phonetic metrics without providing a convincing rationale for this decision. In addition, some factors potentially affecting the outcome of the analysis were not appropriately controlled for, including speech rate (which directly affects duration measures) and inter-speaker variation (especially, given that random slopes were not included in the statistical model).",The statistical analysis type (LMER) seems correctly selected to me.,"The metrics selected for the response variables are potentially interesting, but the authors reported a bunch of them, and no motivation was provided for the big quantity of tests. This makes the analysis feel a bit like a “fishing expedition”, with multiple selected metrics and multiple testings of them, and no correction of the resulting p-values. The tests include frame duration, adjective duration, noun duration, adj V duration, noun V duration, adj V intensity, noun V intensity, adj V centralisation, and noun V centralisation, for a total of 9 tests.","The authors chose to report duration, but they did not normalize/control for speech rate, so that the variable duration, as is, might not be adequate.","The models are structured as METRIC.c ~ trial * typicality + (1 | word) + (1 | speaker), but the reasoning behind choosing to add an interaction over non-interacting predictors is not provided. Random intercepts for “speaker” and “word” were appropriately added. I assume that the inclusion of random slopes prevented the model from converging and that they were discarded because of that.",I feel that not enough subsets of the data were excluded. Our team needed to mark extra sentences as errors or hesitation breaks in addition to the ones already marked as such in the provided textgrids. Errors and hesitation stops likely affected the measurements (e.g. duration) in these sentences.,"All measurements were centered around the mean of the population. Given that “speaker” was only introduced as a random intercept in the statistical analysis, I would have opted for a by-speaker normalization to account for inter-speaker variation to a greater extent.",-
2022-04-21 16:52:48,2022-04-27 12:56:04,IP Address,96.242.236.104,100,504196,True,2022-04-27 12:56:04,R_AdgL6HTEuvu0mvD,,,,,40.5921,-74.6238,anonymous,EN,procambarus_mahogoni,ceratophrys_elephantotus,80,80,80,publishable with minor revision.,"The choice to run the sound files through another forced aligner and then not manually correct it due to time constraints is questionable. ","Its rated as 80/100 because we were unfamiliar with the analysis and are unsure of how best it suits the data. If author(s) provided rationale as to why this analysis best fits the data set, then we would rate it higher. ","The factors/variables focused on were ""typicality"", ""word category"", duration, and F0. These variables are appropriate for answering the research question that was presented for the data set.","The variable of typicality was left as a three-factor choice, when there was a continuous scale for typicality that included a more precise measure of typicality. But, we are unfamiliar with the statistical analysis used, so it could be that a continuous scale isn't suitable for this model. ","We are not familiar with the structure of the statistical model so we cannot evaluate if it is the best fit for the data set. ",N/A,N/A,"The author(s) points out that a limitation of the data set is that it is unbalanced because there are only 5 males. However, they don't target that issue in the analysis (i.e., exclusion or transformation)."
2022-04-20 10:07:42,2022-04-20 13:51:16,IP Address,71.182.176.168,40,13413,False,2022-04-27 15:31:48,R_71YCCaSbrDtOIKd,,,,,,,anonymous,EN,hoplostethus_macrosteus,trachurus_riukiuensis,13,11,14,deeply flawed and unpublishable.,,,,,,,,
2022-04-27 18:00:57,2022-04-27 18:05:26,IP Address,71.104.44.228,100,269,True,2022-04-27 18:05:27,R_2dj4OKeeX0mWtI1,,,,,40.4992,-74.4996,anonymous,EN,lasionycteris_altavela,lycodes_bradfieldi,90,35,65,publishable with major revision.,"The full analysis write-up was not presented nor was the aggregate data used in the model made available. The team just presented a table with results. ","The authors choose to analyze the data with a RM ANOVA. The authors could have considered using analyses that do not aggregate across trials and assume that all trails are equal. Additionally, nonlinear model would are also an option (e.g., generalized additive models). 
","I have no issues with their choice of variables (they seem reasonable given the research question) and are supported by prior literature. 

The model itself, however, is fairly basic and does not take into account all sources of random variability which makes inferences biased. 
","Typicality and frequency band  are  suitable variables to include in the model. I would have probably included the frequency band variable as a continuous variable.

","The model does not account for all sources of variability (i.e., at the item and typicality levels). ","They analyzed all the data. While there were not many
error trials I wonder if excluding them would have made a difference in  this analysis. 
","No transformations. It is not clear if the data met the assumptions for ANOVA (looks like they did not), and if not, what they did about it. 
","I found the document hard to follow. It would have been nice if they wrote up an actual results section as there is lots of data to follow. 

Aggregate data not included.

Regardless of “smallness” of effect size, the AM interaction was significant and should have been explored based on their answers in the questionnaire (significance will be determined by p < .05). 

Small was not defined by the authors nor which effect size they were using. 
"
2022-04-27 19:26:25,2022-04-27 19:27:37,IP Address,222.154.100.210,100,72,True,2022-04-27 19:27:38,R_pxw6REc24TExteh,,,,,-43.5379,172.6151,anonymous,EN,alosa_atun,pervagor_adscensionis,70,85,80,publishable with minor revision.,,,,,,,,
2022-04-20 19:42:27,2022-04-20 19:43:03,IP Address,132.181.235.171,20,35,False,2022-04-27 19:43:06,R_1ikC4LhBfOOZxuH,,,,,,,anonymous,EN,alosa_atun,pervagor_adscensionis,,,,,,,,,,,,
2022-04-20 19:56:32,2022-04-20 19:56:53,IP Address,222.154.101.247,20,20,False,2022-04-27 19:57:02,R_3MKyvaWY1tqUGMN,,,,,,,anonymous,EN,alosa_atun,varanus_eulophotes,,,,,,,,,,,,
2022-04-27 17:15:11,2022-04-27 22:21:35,IP Address,70.166.93.81,100,18383,True,2022-04-27 22:21:35,R_2B2wMolXYWoBdVC,,,,,32.7449,-117.165,anonymous,EN,genyonemus_evotis,saron_pictus,50,70,60,publishable with major revision.,"Phonetic: can describe more about the inclusion of word boundaries, e.g., was the silence closure period of VOT included? That can influence the word duration. Speech rate probably also has some influence on the word duration across different individuals. Controlling for speech rate should be considered as part of the normalization. For example, word duration can be normalized wrt speaker’s speech rate: word duration / (no. syl / second), etc. The idea is to capture the fact that for a word produced with the same duration by two different speakers, for the speaker with a higher speech rate, this word is effectively longer than the speaker with a lower speech rate. One more thing, the authors created a notes tier – what in particular was coded there? How did the authors detect errors in the tokens?
Statistical: lognormal distribution of duration is probably fine, but what about other probable prior distributions? It'd be better to check the empirical distribution before fitting a model.
Overall: Our biggest concern is, how valid it is to measure the duration of adjectives in a NF condition? Maybe the authors wanted to control the variability in different syllables and words, and restricted the dependent variables to a subset of five adjectives. But the *big* assumption here is that, atypical word combination will affect adjectives particularly in a noun-focused condition.","Using Bayesian with weakly-informative priors sounds like a standard practice especially for a limited amount of data. Again, from the reports, it is not clear if the authors did exploratory data analysis before moving on to employ specific distributions for priors. This could weaken the motivation for using the selected modeling method.","The authors have some expectations about how medium and atypical words may not get reduced, so they used duration as the dependent variable. This sounds reasonable, but they could have established the assumptions about the duration more explicitly and cited evidence or support from previous studies. Not sure if restricting the dependent variable to word duration is adequate to answer the research question. In other words, the research question is reduced to ""Do speakers modify the duration of part of the utterances to signal atypical word combinations in referring expressions?"" Also, there's an apparent lack of explanation of the model structure.
They also included the order of the trials to control for any fatigue and speed-up during the entire experiment as a covariate. Random structures include how variations across different speakers and words in realizing different typicality categories and a certain trial will affect the word duration. Why not include repetition as a random effect?
Moreover, the authors did not discuss the possibility of unobserved heterogeneity in their model specification. In other words, is it possible that derived features from other information available in the data can explain the variation in word duration? For example, variation of adjectives can be conditioned on the following noun, but the nouns were not included in the model. Therefore it is likely that the variation of adjective duration is confounded with the properties of the following noun, and it is not reflected in the model specification.","Probably OK, however, as mentioned above, the authors didn’t consider all the possible covariates, thus the model is likely under-specified. The authors could examine the possibility of including other direct or derived variables in the model and discuss the potential effect these variables may have.","Not too sure about the covariate trial_minmax, especially the interpretation of its HDI. Why is this included as a covariate rather than a random effect?","We didn’t understand why the authors looked at adjectives within the subset of NF condition. They also excluded tokens according to their notes tier in the textgrid, what are some examples that they counted as ""error""?","The existing transformations seem to be OK. We wonder about the choice behind scaling the trial numbers to 0-1, instead of using the original scale. More explanation is needed here.","Overall, it feels that the authors were trying to fit the data with a particular statistical method, rather than motivating the use of a model based on the understanding of the data. More clarification and explanation on choosing the variables and models will improved the analysis substantially."
2022-04-27 18:27:07,2022-04-28 03:52:57,IP Address,141.5.2.21,100,33950,True,2022-04-28 03:52:58,R_Xtu19d5gPI5tWkp,,,,,50.1376,8.6776,anonymous,EN,lycodes_bradfieldi,gymnothorax_spinulosus,81,75,78,publishable with minor revision.,"The analysis focuses on a specific, quantifiable aspect, i.e. intensity on the vowel of the accented syllable, as a general correlate of accentuation on the adjective component in the Adjective-Noun combinations with Adjective Focus (AF, pragmatically driven to distinguish two referents with different color). The group’s main hypothesis that in AF trials intensity should be larger for atypical than typical trials is clear and straightforwardly testable with a simple statistical model. The group’s second hypothesis, however, that the difference in accentuation on the adjective between the typical and atypical conditions would be maximal when the focus is instead on the Noun, is more problematic. It should have been reformulated as a follow-up hypothesis on whether typicality alone is sufficient to drive significant intensity differences in the absence of focus on adjectives.","The choice of a linear mixed model is appropriate as the authors considered speaker and target color as random factors, while the three accentuation modalities (LF, ANF and NF), and typicality were considered fixed factors. ","The authors included typicality not as a categorical but as a continuous variable, which is an appropriate choice to account for the fact that there are different N of trials per condition.","The variables included have been appropriately chosen ","While backward deletion can be problematic, the statistical structure is appropriate. ","The use of a Linear Mixed Model allows for the suitable inclusion of all conditions. ","Individual intensity data were normalized by subtracting the mean intensity in decibels over the entire stimulus sentence. This choice does not consider (nor did the authors test) the possibility of a trend in intensity across the entire sentence, positive or negative. If such a trend exists, the mean intensity would not represent a stable baseline. ",There was no report or comment on the effect size of the results.
2022-04-28 06:31:42,2022-04-28 06:44:39,IP Address,115.129.148.244,100,777,True,2022-04-28 06:44:39,R_yPdEjGYeFUe5GEN,,,,,-33.8715,151.2006,anonymous,EN,dunkleosteus_inscriptus,alosa_atun,70,90,79,publishable with major revision.,"The statistical modeling used in this analysis is carefully considered, well-motivated, comprehensive - taking into account all variables of interest to the research question, systematically deployed and generally well interpreted.","Linear Mixed Effects models are an appropriate choice of statistic to examine the effects of interests in these data. ","The models used are well desgined and systematically refined following a standard process. The authors clearly motivate each version of the model, the tests used to evaluate them, and the process by which they have been refined.",The variables included in the models are appropriate to the data and research question. It is not clear whether the use of mean typicality ratings as a continuous variable is appropriate in place of the 3-level categorical typicality variable that informed the study design.,"The final models chosen are appropriately structured with respect to the phenomena being examined, the nature of the dataset, and the metrics dervied from it. The authors clearly motivated all elements of the models, and the process by which they have been refined.","The primary concern with this team's approach is the decision to restrict the analysis to the subset of phrases with the singular dative article. This decision appear to be necessary for aspects of their analysis that wouldn't extend to 'den' phrases, but this unfortunately means that approximately 25% of the data is not analyzed, including five entire noun phrases (""den gelben Erbsen"", ""den gruenen Bohnen"", ""den gruenen Socken"", ""den orangen Kartoffeln"", ""den orangen Trauben"") that were carefully included in the balanced study design (Coretta et al. 2021 ""Methodological Details of the norming and production studies"": Sec. 2.3). This is a substantial and possibly critical subset of the experimental data that has been omitted and which has skewed the balance of the data unevenly across typicality categories. All analysis presented therefore either assumes that the phenomena reported extend across plural NPs, or that any phonetic differences can be neglected, but the authors might wish to better motivate the decision and address this issue in more detail.","No data transformations have been directly applied to the modeled data, but given the large findings reported for speech rate differences and the lack of difference in local duration effects, some kind of temporal transformation/normalization might have been applied to examine duration effects more closely.
","This team have planned, executed and presented a comprehensive analysis of the data that thoughtfully addresses the research question and offers some insights into the phonetic properties of these utterances and how they might differ with typicality.

Some key metrics which are central to the analysis are not adequately explained. In particular, 'DiphDur', and 'DurRat' -- ""the ratio of the duration between the nucleus and the offglide"" -- will depend critically on the accuracy and consistency with which the segment boundary is located between the /e/ vowel and the coda of the article, yet the details by which this was measured and validated are not properly explained. (In the first place, this also assumes that all speakers produce a comparable vocalized 'rhotic' in the definite article, but this is not addressed either - do all participants speak a sufficiently comparable variety of German in this important respect, and how was this acertained?). Vowel-approximant transitions of this nature do not typically contain a clear segment boundary, so how robustly was this boundary located in this data by the automatic segmentation tools used, and how was this checked and validated?

The segmentation of the vowel-coda sequence in the definite article is tied up with another methodological issue about which there is insufficient detail: formant tracking across the rime. No details are provided about how LaBB-CAT tracks formants (window size/type/overlap), max. number of formants, etc., yet this is also a key metric: the first variable claimed to differ significantly with typicality in the article. While the statistical analysis is compelling, and appears to be robust, it is difficult to assess without having a better idea of the data. A couple of illustrative spectrograms aligned with waveforms showing how formants track over the course of a determiner, where the segment boundries lie, and how the nuclear vowel is delineated from the coda schwa would greatly aid interpretability here, especially since no significant differences are reported for either vowel duration or F2: it is perhaps surprising that typicality is flagged through vowel height with no commensurate change in fronting or duration, and some phonetically detailed illustrations of this phenomenon would help to understand the effect reported.

Other key variables which require more explanation are: 'maxIntensity', 'meanPitch', and 'ED' - few details are given to properly understand how these were measured, calculated and validated.

>> ""The alosa_atun_data.rds file contains 10,913 observations"".
What is the breakdown of this dataset (by type/condition/speaker)? 70*30 test trials were provided, and this team has also analyzed the additional trigger trials, but that should result in no more than 4,200 observations?

The finding that ""(AF) typical trials have a significantly faster speech rate"" is not adequately unpacked. Since no significant durational effects were reported at the segment, rime, or lexical level in the determiner, utterance-level duration/speech rate differences cannot arise from local lengthening, so this is inconsistent with the claim that ""This may be an effect of the overall trial, or may be carried by local duration effects, such as in the adjective itself)"". If this were thought to be the case, duration should have been examined in other constituents in the target NP. If these differences are global, as the data suggest, what drives this phenomenon? 
"
2022-04-28 08:14:19,2022-04-28 08:47:36,IP Address,5.147.48.245,100,1997,True,2022-04-28 08:47:37,R_30jdJKrkJDvjjMj,,,,,51.4489,7.0383,anonymous,EN,aracana_bitatawa,dunkleosteus_inscriptus,80,70,90,publishable with minor revision.,"The analysis is done with an R script that is available on OSF and contains helpful comments throughout the script. The authors chose Linear Mixed-Effects models with NHST and Bayesian Mixed-Effects models with ROPE analysis for analysing the data. 

Being unfamiliar to Bayesian Mixed Effects modelling and especially to the given ROPE plots in the paper, we cannot comment on the usefulness of these analyses","As we are not familiar with the Bayesian Mixed Effects models we cannot say if the choice of these models is a good one for the given data, however, the Linear Mixed-Effects Models are a valid choice for working with duration data. ","We will, again, comment on the Linear Mixed-Effects Models only:

Separate models for focus condition and typicality were fitted to answer the research question “Does the acoustic profile of an utterance with an atypical referent like blue banana differ from one with a typical referent such as yellow banana in German utterances containing focused noun phrases?”.  Since the models are run separately, we are dealing with a relatively simple fixed effect structure: condition (first model) vs. typicality (second and following models). The authors opted for random intercepts instead of random slopes. We think that this is a valid choice. ","The authors ran several Linear Mixed-Effect Models. The focus condition model is used to validate the duration measurements since the authors assume an effect for focused elements of an utterance. The authors opted for the measurement of relative noun/adjective durations instead of absolute durations as a dependent variable and find an effect, namely that nouns are longer in focused condition. Their explanation for this choice is valid and comprehensible.  

However, for the typicality models the authors seem to have changed the modelling approach and decided to test relative AND absolute noun durations. As the authors say themselves “absolute durations are influenced by speech rate, number of syllables in the noun length, number of syllables in the adjective and other factors”. Since these factors might influence the results and are not included as covariates, it is questionable if we can trust the results of the absolute duration models. Unfortunately from the report it is not clear to us what the results of the absolute and what the results of the relative duration models are and if there was any difference between these two.","For the Linear Mixed-Effects models the structure seemed to be suitable with an exception for the absolute duration typicality models that would need more explanation and a clear report of the results, since they go somewhat against what the authors said themselves about the suitability of absolute durations for the analysis in the focus condition model (see above).","Based on the research question, typicality is only relevant for focused nouns and the authors built a subset (Condition: NF) to run their models on. However, they say later that modelling was then done on the subset AND on the full data set. Why was the modelling done on the full data set if only the focused noun condition is relevant for the RQ? Which of the models correspond to the full data set and what is the result compared to the subset? This remains unclear in the report and needs to be answered in the text. ","The authors opted for relative durations to avoid problems related to possible effects of other factors on absolute duration. This is a valid choice to us, however, see above for comments on absolute durations (since the authors also included them in another set of models that would need a more detailed explanation in the report as to why this was done and what the results were).","While most scripts, data, and codes seem to be available on OSF and is well described in the text, the only thing that seems to be missing is  the output of the BAS pipeline, the <XX i.pipeline.TextGrid> files that are mentioned in the text. These output files are fed into a second Matlab function, that is also present in the OSF project and well explained, which then calculates the durations for the given output files and saves it to spreadsheets. The spreadsheets are saved in the OSF project. Since both functions are given and the second one needs the <XX i.pipeline.TextGrid> files as input, the authors might want to add the files to the OSF project for reproducability. 
"
2022-04-28 08:54:34,2022-04-28 09:22:38,IP Address,104.28.50.169,100,1683,True,2022-04-28 09:22:38,R_7O4A1qhEUhiXjoZ,,,,,33.5716,-101.8545,anonymous,EN,anthracoceros_coronata,lasionycteris_altavela,85,90,88,publishable as is.,"The analysis is clear and reasonable, with valid statistical choices.

Some additional explanation of choices made would be helpful.  For example, the code creates Formant and Pitch objects, but only uses intensity in the analysis.  This is not at all unreasonable, but a comment on the reasoning would be useful.

Similarly, only NF trials are considered, excluding AF and ANF trials.  Again there may be valid reasons for doing so, but some discussion is warranted.

The choice to find the maximum intensity of the utterance rather than of individual words is again reasonable, but some discussion would be appropriate.",The use of a linear mixed model is in line with norms in the field.,"Variables: as mentioned above, some reasoning behind the focus on only intensity, when other measures were collected, would be helpful.

Model: The only question about the model is that in the comment in the code above the model definition, it says that a random slope of typicality is included, but I don't see any random slopes at all in the model definition, and typicality is included as a fixed effect.

While not strictly necessary, some model comparison or discussion thereof would be useful to see if the random effects are justified.","The use of maximum intensity makes sense, but some discussion of why that variable was chosen over other measures of focus/stress would be appropriate, especially since Praat Pitch and Formant objects were created.",The model structure is suitable.,"The only items excluded were those with text in the ""notes"" tier of the TextGrids.  There are a few outliers in Intensity if defining outlier as ±2sd from the mean, but there are none at ±3sd from the mean, so it is reasonable to not exclude any of these data.","No transformations were done to the data.  The only consideration here is that typ_mean has a strange distribution—many values of 100% and 0%, with values in the middle skewing right, but it is reasonable to not apply a transformation.",
2022-04-28 09:36:38,2022-04-28 10:12:05,IP Address,134.69.55.186,100,2126,True,2022-04-28 10:12:06,R_2xJKgT4T9v4VISE,,,,,34.1325,-118.2076,anonymous,EN,hoplostethus_macrosteus,trachurus_riukiuensis,50,95,70,publishable with major revision.,"The authors should consider measuring only specific portions of the adjective (for instance, only the stressed vowel), instead of including the flanking consonants and any unstressed vowels (e.g. the plural morpheme -en) in the segmentation, as there is variation inherent in segmental duration that was not accounted for here. Re: peak F0 measure: Section 1.3 was confusing; we are not clear on the ""word"" from which the pitch measurements were derived (i.e. the adjective or the noun), complicating our critiques of the analysis of this acoustic measure. ","This seems reasonable to us. ","The variable selection seems mostly on point. Our only critique was that ""color"" was not considered as a fixed effect, given that the vowels in each of the adjectives (and nouns) were different, and would likely contribute to variation in the duration measure.",See above,Suitable,We are concerned with the high number of exclusions for the F0 article model; 20% of the data excluded seems quite high.,"We were surprised that the F0 data were not transformed based on speaker sex (which, while albeit an imperfect strategy, is common in the field). Speaker sex was not provided with the data, so it would perhaps have been wiser to not include this measure at all (since arbitrarily determining speaker sex is also problematic). ","While we are mostly satisfied with the segmentation criteria discussed, motivating those decisions via citations of other scholars' work would have strengthened their decisions and our confidence in their methods. We were also surprised to not see any discussion or summary of the analysis as a whole, nor a section specifically targeting the limitations of the analysis."
2022-04-28 14:16:05,2022-04-28 15:24:06,IP Address,129.107.80.47,100,4081,True,2022-04-28 15:24:07,R_3JzbnDbPJC7jXQO,,,,,32.7185,-97.1432,anonymous,EN,varanus_eulophotes,genyonemus_evotis,85,70,73,publishable with minor revision.,"While the techniques for dimensionality reduction and analysis of acoustic features seem solid to us, we are not so sure about the overall approach. This team took an exploratory approach that included many acoustic dimensions (increasing the chances of a significant result somewhere). It was difficult for us to evaluate the conclusions and think it must be framed as exploratory rather than confirmatory. ","See comments above on the overall approach, otherwise the use of the GLMM as the final analysis seems appropriate. ","Selection of the variable is appropriate given the overall approach. ","This analysis used a holistic meta-variable instead of a single acoustic measure as dv, but then attempt to make conclusions about the individual acoustic features in the end. Our main concern is that it's unclear how the authors chose which acoustic measurements to initially extract, and there were so many acoustic measurements used in the acoustic feature analysis that something was bound to be significant in the model. ",Structure is appropriate given the approach,"The authors chose not to exclude data without typicality ratings and instead manually coded typicality for those items. They discuss how they did this, but don't provide a justification as to why. This also causes them to change the structure of the model to be binomial because some of the conditions only have (as they manually assigned) ""typical"" or ""atypical"" levels. We found the inclusion of these data unnecessary because (as far as we can tell) the items for which typicality was not coded were not designed to bear on this question. ","z-score was used during feature selection to make graphs to compare across participants, which we found appropriate.  However, it was unclear whether this transform was used on the data included in the GLMMs (which includes random intercepts for speaker, so z-scores are potentially unnecessary there). ","We don't see any space to comment on data processing. The authors don't mention any attempt to check the accuracy of the force aligned measurements, which could greatly affect the results. "
2022-04-28 17:07:16,2022-04-28 17:23:50,IP Address,129.108.202.181,100,993,True,2022-04-28 17:23:51,R_10BC9RKXBzT6YnW,,,,,31.7703,-106.3006,anonymous,EN,paralichthys_undulatus,stygobromus_tyraica,60,70,70,publishable with minor revision.,Please see next comment,"To be honest I could not follow what statistical test they used. They produced confidence intervals, etc, but this writeup is too computational for me to really understand it enough to be able to evaluate it in detail.",They used supervised machine learning for the whole analysis.,"It looks like their predictor was Typicality, which is valid for the research question.","I do not have enough understanding of their approach to answer this effectively. ","They excluded all errors and hesitations, which is reasonable. They also only examined the adjectives, which I think is also reasonable based on the fact that the adjectives are repeated in each typicality condition. ",discrete cosine transform,"As noted above, I do apologise but I don't have enough knowledge of computational approaches to evaluate this submission effectively. However, I did note that they did not choose one acoustic measure, as we were instructed to do, but instead trained a model to pick out the most relevant acoustic features. However, even in the results, which shows a barplot with the most important features, many of the terms are opaque to me."
2022-04-28 12:00:18,2022-04-28 20:41:49,IP Address,174.18.72.234,100,31291,True,2022-04-28 20:41:50,R_PXqsmWPRRdsksbD,,,,,32.246,-110.9177,anonymous,EN,trachurus_riukiuensis,petauroides_fistulator,35,30,30,publishable with major revision.,"Based on our findings about this analysis explained in several of the questions below, we do not believe the finding that Atypical has lower f0 than other conditions is reliable.  Our concerns that led to this judgment are based both in the phonetics and the statistics of the analysis.  At a very general level, this analysis seems to use entirely automated procedures to extract the data for analysis, with no requirement that the researcher ever listen to the recordings or look at spectrograms.  We understand that an entirely automated method is both more expedient and more replicable than one that involves human judgments based on the spectrogram, but we do wonder if the avoidance of hands-on phonetic methods led to some of the concerns we note below about creaky voice, inclusion of hesitations, and inclusion of production errors.","We feel the choice of statistical analysis type could be a very good method, if implemented differently on several points. The approach as it stands uses a GAMM fitted to the f0 curve over the duration of the noun, which includes several random smoothing factors in the GAMM as well as the fixed factor of interest (Typicality), and assesses significance of the coefficients for the Typicality effects in the resulting model.  The points we feel would need to be implemented differently to give reliable results are explained below.","Dependent variable: Most of our concerns about this model stem from choice and implementation of the dependent variable, f0 track over the duration of the noun, automatically extracted after automatic labeling of the noun.
•	Noun vs. adjective measurements: This analysis analyzed only f0 during the noun, not the adjective.  Nouns are not matched across conditions in this experimental design; adjectives are.  (That is, Typicality is a between-items factor if the dependent variable is in the noun but a within-items factor if the dependent variable is within the adjective.)  Even if one predicts that the effect is most likely to be realized on the noun, it's a shame to waste the power and lower error variability offered by the item-matching of the adjectives.  Reasoning for this choice was not addressed in the write-up.  The unmatched nouns may also introduce some confounds because of how the GAMM was fit across the duration of the nouns, addressed below.
•	Creaky voice: This analysis used Praat's automatic f0 measurements at 10 ms intervals throughout the noun.  This has the advantage of being able to capture differences anywhere in the f0 curve over the noun, as opposed to measuring the peak f0, for example.  However, it is unclear how creaky voice may have affected this dependent variable.  We expect that the GAMM could probably fit to an f0 track that shifts suddenly from creak to modal voice or vice versa (e.g. halving or doubling) with a very steep slope to one part of the “wiggly” curve.  However, this would treat creak as simply very low pitch on a continuous scale, not a categorically different kind of voicing.  We believe there is substantial creak at the end of the nouns for most speakers (between noun-final schwa and vowel-initial “ablegen”), and in other parts of the noun for a few speakers.  Any measure that includes creaky voice as simply very low pitch on a continuous scale, as this one does, is likely to have the outcome strongly influenced by how much creak each token happens to have where in the noun, which is relatively unlikely to be a linguistically meaningful realization of a Typicality difference.  Even if the creak were a realization of a Typicality effect, it would be misleading to present it as a difference on a continuous f0 variable.

Time variable: Because the ID variable (time) is set to 10 ms windows throughout the duration of the noun, number of IDs (number of 10 ms windows) varies widely across tokens.  Of necessity, there is very little data left at the later IDs (nouns that happen to have been pronounced with the longest duration), and that data is not well distributed across Typicality conditions.  We used the authors’ R script to analyze the distribution of data somewhat further, and found that there is very little data past about ID 50, bringing any effect toward the end of the IDs into doubt.  We would prefer the time factor for the GAMM fitting to use frames at each 5% of duration of the noun, or something comparable, to spread the presumed intonation curves to the same range.  (We have a histogram by ID, but it won't paste in here.) 
 
Lack of a stress placement factor:  No factor seems to have been tried in the model for which syllable of the noun stress falls on.  Since the nouns are not matched across Typicality conditions and stress placement would be expected to have a large effect on f0, this could introduce a substantial confound.  Noun stress placement varies from first syllable (e.g. Gurke) to third syllable (e.g. Mandarine).  It is possible, however, that using the noun (item) as a random smoothing factor helps with this.
","We take this question to be about the final choice of model, as opposed to the model selection process (previous question).  

Large number of random smooth terms: This analysis includes competitor name, competitor color, distractor 1 name, distractor 1 color, distractor 2 name, and distractor 2 color as random factors, in addition to identity of the noun, identity of the adjective, trial number, and the obvious random factor of speaker.  Our understanding of this method is that if having one of the distractors be red, or be a clothespin, happens to make a difference in how people say the target phrase, including random smooth terms for everything on the screen gives the model a place to appropriately put that source of variability.  We can see the potential advantage of allowing random terms for all of these potential sources of variability, but since the distractors and competitors are carefully distributed across items in the experimental design, we suspect that not including these random smooth terms would make a much simpler model with little loss in what can be interpreted.  This is a very high number of random factors, and we were surprised that there apparently were no problems with failure to converge.  Furthermore, since the target adjective is predictable from the target noun (each noun occurs only with a single adjective), we were unsure about the benefit of including random smooth terms for both separately.

Stress placement: As discussed above, given the over-time approach of the GAMM and the importance of intonation for this method, we were surprised not to have a factor for which syllable of the noun the stress falls on.",Covered by answers to the previous two questions.,"Errors and speaker JW_3: We were surprised to see that this analysis does not exclude the productions that were marked in the Textgrid as containing errors.  While some productions labeled as errors contained errors only in some other part of the sentence and may have been usable, others contained mispronunciations or large pauses or self-corrections during the adjective and noun, influencing the f0 and duration of the target word(s).  In particular, we noticed on further examination of this analysis that only one token has ID data above ID 92: a token of Zitrone by speaker JW_3 that was labeled as an error.  This particular token has a large hesitation at the start of the noun, which the automatic labeling process probably included as part of the duration of the noun, pushing the entire actual intonation contour into higher ID numbers.  Furthermore, we noticed that speaker JW_3 has an extremely high proportion of their tokens labeled as errors, suggesting this speaker had difficulty with the task and should perhaps be excluded entirely.  Since there is so little data at high ID numbers, any effect toward the end of the GAMM curve could be unduly influenced by a few error tokens that include hesitations in the noun.

Creaky voice: We noticed large amounts of creak, especially at the ends of nouns (especially between schwa and vowel-initial ablegen), and for some speakers throughout large parts of the determiner, adjective, and noun.  We believe creak should have been either excluded from the GAMM analysis or analyzed as a separate dependent variable (presence/absence of creak).  So many productions end in creak that it would likely be impossible to exclude all productions that contain creak.  The automatically extracted pitch track is highly likely to have problems with creak.","This analysis transformed f0 to semitones.  We think this is fine, although with the Speaker random effect included, we’re not completely sure it’s necessary.","Visual presentation of results:  As we worked to understand what the GAMM coefficient results meant, we wished for some graphs, for example of fitted the GAMM over ID for each Typicality condition, and perhaps also a graph of average semitones over ID for each Typicality condition as well, to see how the GAMM fit the raw data.  Because of the way the GAMM fits the entire curve over the span of the nouns, it was difficult to interpret the overall finding that Medium and Typical both have significantly positive coefficients relative to Atypical across the time span of the GAMM, at some time.  To explore this, we did some additional graphing using the authors’ uploaded materials, and obtained this estimate of the difference between the fitted GAMM for Atypical vs. Medium, the larger of the two differences:
(Graph will not paste in)
Interpretation of final result: The graph suggests that the difference is based almost entirely on very high ID numbers, which as discussed above come from only a few tokens that are not well distributed across conditions and at least sometimes represent errors.  Furthermore, high ID numbers are the most likely to fall during creak."
2022-04-24 20:28:32,2022-04-28 21:45:41,IP Address,184.64.221.169,100,350229,True,2022-04-28 21:45:41,R_1lyoiVyOhFYDIvn,,,,,51.0406,-114.0764,anonymous,EN,pseudopleuronectes_assasi,aratinga_lugubris,10,35,25,deeply flawed and unpublishable.,"In their analysis, there are major critical points to be considered. We go through these critical issues in this questionnaire. First, the authors state: 

“…since there are no minimal pairs, it is impossible to answer this question with the data provided by the organizers, so we decided to formulate the question differently:
Is there any difference in the speakers’ production, when they produce atypical/medium/typical word combinations with the same color adjective? (e. g. green carrots vs. green tomato vs. green beans)” (p.17).

 Because the experiment is set up in such a way so as to avoid minimal colour pairs in the testing phase (e.g. yellow banana vs. blue banana), the authors choose to re-formulate the research question and develop their own research question. This research question again asks about the differences in productions, but these differences are non-acoustic ones. This is unfortunately not the topic of the study and so the entire analysis is considerably removed from the primary research question and the goal of the project.

Our argument is supported on page 6, where the authors state the following.
“We listened to utterances of a particular color by all speakers in order to find out whether there were any differences between typical and atypical utterances. We did not manage to find any consistent acoustic differences, so we decided to drop this search and focus on non-acoustic cues” (p.6). 

The authors offer an impressionistic perception account of whether the acoustic differences exist or do not exist without even specifying whether they have any German language background. As such, their analysis not only overlooks the importance of the acoustic cues, but it is also flawed in that it does not offer specific parameters through which the acoustic differences do or do not exist.  ","The choice of the statistical analysis was the Bayesian mixed effects ordinal 
regression. Given the outcome variable (typicality), which has three factors that have natural ordering: typical, medium, atypical, we believe that the choice of the statistical analysis is on target. Still, because of the way the Bayesian analysis has been conducted, i.e. with default priors and without posterior checks, the results of the simple ordinal regression would be, if not the same, similar. ","The outcome variable was the typicality. The first predictor variable was the speech error, which had two factors: speech errors and no speech errors. 

Another variable was the adjective emphasization, which was broken down into 2 factors: non-emphasized and emphasized. 

The authors developed 2 models with each predictor variable separately, and each model consisted of random and fixed effects (by-participant and by-colour, respectively)
Considering the choice of analysis and the authors’ hypotheses, the statistical models were on target.  ","All the variables included in the statistical analyses were  suitable for testing the postulated hypotheses. ","The Bayesian statistical models were not thoroughly developed.  First, the authors could have developed the prior distribution based on the previous research on speech errors and accentedness. We understand that building the priors is most certainly not an easy task, but priors can largely affect the model output and the posterior checks. The brm model itself was well structured as the model converged and the authors presumably checked the Rhat values. However, there were no posterior predictive checks to show the probability distributions of plausible values of the parameters, given the data and the model. In addition to credible intervals, the posterior checks would indicate whether the models fitted the given data. Lastly, the authors justifiably selected the cumulative link logit family type for their models which automatically transformed the estimates into log odds. While log odds are useful, it would have been more useful to interpret the results with the transformation of log odds into simple odds. ","The authors did not analyze the ANF and AF items. They only used the NF condition 
in their analysis, which was an understandable choice given the structure of the original study.

For the error analysis, the authors did not exclude any items in the NF condition, which was understandable given their analysis, however, they should have excluded items with errors when they were analyzing accentedness (emphasis vs. non-emphasis) because the items with errors could have affected their results.","The typicality variable was transformed. Initially, it consisted of 3 categories: hesitations, errors, pauses. 
However, when developing the models, the authors decided to include two factors in this variable: errors and no errors. This choice strengthens the model’s fit and its convergence. ","We believe that the statistical modelling is somewhat suitable given the hypotheses and the choices authors made, but that the overal analysis is flawed because:

1) it does not deal with the question the study asks
2) the impressionistic way the stimuli are analyzed
3) terms like accentedness and speech errors are not well defined
4) there is too much code in the report which is a problem because it is not accessible to people who are not used to R programming language
5) no language background of the raters is provided
6) visualization of the norming part of the study was redundant
"
2022-04-29 01:30:35,2022-04-29 01:33:15,IP Address,222.154.100.210,100,159,True,2022-04-29 01:33:15,R_2dEF3iZ37qXsg9u,,,,,-43.5379,172.6151,anonymous,EN,alosa_atun,pervagor_adscensionis,70,85,80,publishable with major revision.,"The acoustic analysis was robust; however, there was minimal phonetic analysis. It is clear from the data provided that a lot of work went into preparation and analysis, but it's difficult to evaluate without any guidance from the authors. For example, they say they didn't have time for feature selection, but still included a /Features subfolder with multiple scripts inside. Some information in the scripts didn't appear in the report (e.g., that the speaker utterances were chunked into 5 per utterance for the GMMs). We concluded the statistical analysis was robust based on the comments and the final report; however, we can't replicate the analysis in its current format.",The team used Linear mixed effects models (lmers) for their statistical analysis. Their choice of statistical analysis is suitable for the current study.,"The team derived the Kullback-Leibler divergence for Mel-frequency cepstrum coefficients (MFCC) and fundamental frequency (f0) between pairs of utterances and in adjective and z-scored within speaker. These MFCC and f0 distance measures were the dependent variables and a typicality score by subtracting the median typicality of A from the typicality of B from norming data. The team did not explain A or B. The derived median typicality score was the independent variable. However, we conclude their choice of variable selection was suitable for the current study. They noted they wanted to do more feature selection on other elements of the utterance, but were unable to due to time limitations.","The team did not justify their choice to use MFCC and f0 distance in their methodology. They did not justify their choice of using the derived median typicality score as opposed to the typicality categories; however, we concluded the use of the typicality score from the norming data was justified within the context of the statistical model.","The structure of the statistical models were suitable for the purposes of the current analysis. The adjective and the speaker were included as random effects. The initial lmer model had speaker by adjective as random slopes; however, this failed to converge. There were no interactions in their statistical models. Models with p-value > 0.05 were significant; however, residual plots were used to evaluate the interpretability of models. We note that the final models were not selected using a stepwise regression process and explanatory power between models were not evaluated.","The team filtered the analytical data set and removed observations with errors and included only observations in the noun-focused conditions and where the adjectives were the same across pairs (A and B). Their choice to remove observations with errors is justified; however, they did not provide summary statistics for the final analytical data set.","The team did not transform the final analytical dataset; however, they did mention in their questionnaire they would’ve removed outlier when they were putting together their analytical data set and they would've normalised the MFCC and f0 distance measures. There was some contradiction between what was reported (that no outliers were removed) and the statistical analysis (where outliers were removed in the final step) provided, but it did not have a major effect on the outcome.",The authors didn't relate the findings back to the original research question.
2022-04-29 03:19:13,2022-04-29 03:24:58,IP Address,94.211.244.41,100,345,True,2022-04-29 03:24:59,R_2Uh0myt5Ev3YU0h,,,,,52.1617,5.3711,anonymous,EN,neosilurus_omanensis,pseudodax_euryzona,75,60,70,publishable with minor revision.,"There is no information about the demographics of the annotators. Are these native speakers of German or not? And although the paper notes that one annotator went over all examples again, after the four annotators were done, it is unclear what this annotator checked exactly. Did they also look at the individual annotations, or just resolve issues that were flagged by the original annotators? Thus it is not clear how reliable the annotations are. The choice to test the hypothesis on s2 and not on the other possible components seems to be driven by the data itself, and thus needs to be corrected for multiple comparisons. It is not completely clear how many comparisons have been considered (but at least the other component and the intercept)._"," The analysis using a linear model is sound. ","Capturing pitch tracks with PCA analysis indeed allows for quantitative analysis of potentially qualitative effects. The choice for the variable has not been motivated, but such a motivation may easily be given (and was not required for the current analysis document)","Duration, or any other variable, has not been considered directly, but may have direct or indirect effects",A random effect for the effect of the adjective+noun  combination may have improved model fit (as some nouns are much longer than others).,"There is no explict choice to exclude data, though the dataset also contains many examples in other focus conditions, for which typicality can be derived. The exclusion of outliers (above or below 3 SD from the mean) is reasonable and sound.","The transformation using PCAs is appropriate and may allow to quantify interesting features that are not simple mean shifts in pitch. However, the decision to pick the best component of two is not clearly motivated (why not try mulitple components)? The effect size (and significances) may change with analyses of the other components.","One of the members of our group may know who (one of the) author(s) of this analysis is, due to a username still being present in the Praat script, and the unfortunate coincidence of this group member having seen the author's username when both were colleagues. However, we do not think this knowledge has affected our judgement and we have no conflict of interest."
2022-04-29 05:24:36,2022-04-29 05:35:24,IP Address,89.88.224.243,100,648,True,2022-04-29 05:35:25,R_OpPGZ2sHAGsmT5v,,,,,48.4289,0.0915,anonymous,EN,ceratophrys_elephantotus,pervagor_meeki,75,65,70,publishable with minor revision.,"f0 extraction could be more fine tuned, the team priviledged one measure per word, separate mixed effects models were run each having a different dependend variable: ANOVAS with repeated measures would have been sufficiant for this type of analyses. A more complex model combining the different measures would have been interesting. ","en vogue but the data was not complex enough to justify this type of analysis. ","ok, four dependend variables were analyzed according to typicality with random effects that differed between nouns and adjectives. A total of 8 models were run. ","fine, but leading to eight separate models",fine,portions of the signal containing comments in the TG were excluded: valid option,"f0 was transformed to semi-tones a LOGARITHMIC scale ",
2022-04-29 06:02:29,2022-04-29 06:35:13,IP Address,83.41.211.216,100,1964,True,2022-04-29 06:35:14,R_rj2mXhBdbwHQQut,,,,,41.4928,2.0403,anonymous,EN,saron_pictus,dermatolepis_aculeatus,75,85,80,publishable with major revision.,"In general, we found this analysis to be appropriate, although we have issues with the use of the word 'normalization' with respect to the transformation of the values of the fundamental frequency. We would have expected a transformation that improved the comparability between speakers with differing vocal tract lengths, as is typically done in studies of vowels.

Additionally, while the use of linear mixed models with a Gaussian likelihood would be the default for the field, checking the assumptions of these fitted models shows they were misspecified, and that a different model may have allowed us to be more confident in any conclusions drawn (or not drawn).","The choice of mixed-effect regression is appropriate for the structure of the data. However, checking the residuals of the fitted models shows that they depart strongly from normality, indicating that the model is misspecified and interpreting the model parameters may not be wise.

The authors should have transformed the data or employed a different likelihood distribution instead of centring the dependent variable and using the default Gaussian likelihood.","In general, the variable was selected that directly answered the research question, which was appropriate. ","The inclusion of typicality was important, given the research question.

It may also have been useful to account for the time course of the experiment by including Trial as a covariate along with a random slope for trial by participant.

Not including a random slope for typicality by speaker weakens confidence in the results of the model.","The model structure, in terms of the random and fixed effects that were included, seems appropriate. However, the authors describe random slopes that were fit that does not appear anywhere in the R code.",The criteria for exclusion were both reasonable and clearly delineated.,"Based on the code provided, the pitch was not scaled but only centred. This was also done for all observations together. While centring in this way can help with model interpretability, it is a linear transformation that should have no impact on the interpretation of the model or the findings.

The problem with this is that we are comparing speakers across a variable that is likely to differ from person to person, and because the data was not normalized within each speaker comparing pitch values across different participants may not be appropriate or meaningful. ",
2022-04-29 06:01:03,2022-04-29 07:39:21,IP Address,72.75.217.214,100,5897,True,2022-04-29 07:39:21,R_3f7RJAMw0hQAIwh,,,,,42.9767,-78.7959,anonymous,EN,sphyrna_ellioti,chelonia_brummeri,80,90,85,publishable as is.,"These analyses were carefully thought through and competently carried out. One comment I have on the phonetic analyses is that the floor and ceiling for the F0 measures were set to a constant value. This sometimes results in pitch doubling or pitch halving for some talkers, so it might be good to check if any talkers seem to show drastic pitch discontinuities that can be corrected by changing these values. 

I thought the statistical analyses were reasonable and appropriate for the question. I do wonder whether there's a potential problem in redundancy between the syllable structure fixed term and the adjective random effect term, since there aren't many adjectives included to begin with; but I don't think this would invalidate the conclusions.",The analyses types are very appropriate for the questions. I don't have any concerns about the statistical analysis types themselves.,The process of choosing the variables for the models seems appropriate. Some decisions were not explicitly explained but they still seem like reasonable decisions overall. I have no concerns about this part of the analyses.,"The included variables are overall well suited to answer the question. I do think there might be some redundancy between some terms, such as the random effect of adjective and the fixed effect of syllable structure. Otherwise, both the dependent and independent variables seem reasonable. ","The structures of the statistical models are very suitable to answer the question. I didn't have any concerns about this, although I am less familiar with the GAMMs than with the Bayesian linear mixed-effects models.","The decisions behind the exclusion of data were reasonable and appropriate. ","The transformations of the data were appropriate. One small worry is over whether the F0 values should be transformed to semitones. The transformation depends on the measure of a speaker's minimum F0, which might introduce problems given that estimation of pitch is not trivial and can sometimes introduce pitch-halving. In this case that could translate to it affecting all the pitch measurements for a speaker.","I am much less familiar with GAMMs than with Bayesian mixed effects models, and feel less confident about judging those. Still, the logic behind their inclusion seemed appropriate to me, and the execution resembled what I've seen in other studies analyzing similar types of data."
2022-04-29 07:28:26,2022-04-29 08:03:22,IP Address,95.153.169.87,100,2096,True,2022-04-29 08:03:23,R_31NMh8gTj7EHoIv,,,,,45.0452,38.9722,anonymous,EN,aratinga_lugubris,procambarus_maculosus,79,31,52,publishable with major revision.,"The team chose F0 of the stressed vowel in nouns as the basis for their statistical model. We’d like to point to the following issues of this approach:
- By analyzing nouns instead of adjectives the researchers seemed to do the opposite thing from what was supposed by the organizers.
- There are few minimal pairs with the same vowel qualities to compare: walnuss (typical) - paprika (atypical); bohnen, zitrone (typical) - aprikose (medium). However, all the data was inserted into the statistical model.
- Automatic F0 extraction did not always work well, but such tokens weren’t excluded or analyzed manually.
- It’s not clear why the team opted for making a FPCA and then plug its results as inputs of a mixed effects regression. They could’ve just made a regression which tries to predict F0 on the basis of independent variables.
- Trying to predict FPCA components instead of typicality makes the analysis obscure and makes it hard to get back to raw data.","The application of FPCA is not well reasoned. It’s not clear why the team opted for this type of analysis and then used its results as inputs of a mixed effects regression. ",The choice of mixed-effects is not clear. The model looks like this: component ∼ typicality ∗ gender + (gender | word) + (typicality | speaker). We can’t understand why related variables of speaker and gender can be both random intercepts and random slopes.,We wanted to note that analyzing Gender (even though the organizers did not provide this data) was reasonable.,Leaving aside the problems with certain variables in mixed effects the structure of the model is reasonable. However the choice of the predicted variable (FPCA components) does not correspond to the initial goal.,"F0 values were extracted automatically. In case F0 data was not available at some point within a vowel, the team decided to use the closest available F0 value. We don’t know how many tokens had this problem, but we think they should’ve been excluded or F0 values should have been extracted for them in a semi-automatic mode.
We agree that tokens with background noise or meaningful errors should have been excluded. The researchers did this.",We think that FPCA transformation of the data and making its result the main predicted variable in the statistical analysis is not justified by the researchers.,"It’s really strange that this peer review questionnaire does not pose any questions as to whether the analysis makes linguistic sense. What we are reviewing are, basically, the tools used, but not whether the results are reasonable."
2022-04-29 08:11:28,2022-04-29 08:15:22,IP Address,81.97.172.223,100,233,True,2022-04-29 08:15:23,R_1NCB1BBfWsbSOGP,,,,,55.0021,-1.6287,anonymous,EN,haematopus_fossor,anthracoceros_coronata,50,40,45,publishable with major revision.,"Phonetic analysis:  

The segmentation between vowel-final words and ablegen was somewhat inconsistent, in that the presence or absence of a clear break between the words could plausibly be a cue to typicality. When this clear break was not present, the boundary was placed at the midpoint of the entire vocalic portion. Given German prosodic patterns, it is likely that (all else being equal) the /a/ of ablegen is longer in duration than the adjacent word-final vowel; consequently, segmenting the boundary at the midpoint of the vocalic portion thereby serves to artificially lengthen the duration of the noun. This could introduce a small bias into the results. 

Three measures were taken: duration, f0, and intensity. All of these are subject to word- and vowel-level effects: for example, all else being equal, Kartoffeln has a longer duration than Socken; Kirsche has a higher f0 than Banane; and braunen has a higher intensity than gruenen. This is not a problem if this is taken into account in the statistical modelling, but this was not addressed.  

Additionally, the acoustic measurements themselves may not be accurate. Fundamental frequency was estimated using Praat’s simplest pitch tracking method, which is relatively inaccurate especially when applied in an unsupervised manner. As for intensity, it is not clear from the methods document how precisely the recordings were made, but based on auditory inspection of the recordings it appears that the participants did not necessarily have the microphone a constant distance from their mouths. This makes any estimation of intensity inherently unreliable. 

Statistical analysis: the analysis did not include a random effect of word. This is critical, especially due to the potential confounds in the phonetic analysis, and the fact that word type is not evenly distributed among the conditions. Even if this were to be controlled for, the nouns in particular are not well-distributed among the typicality conditions – the word Kartoffeln, for example, only ever appears as orangen (medium typicality), meaning we cannot easily see what Kartoffeln would be like in the other typicality conditions. 

The fact that the LMER models did not converge due to singularity raises the possibility that there was some unusual structure in the data or model specification. This could have been investigated more carefully. 

The use of Bonferonni-adjusted p-values is a good step. ","The use of LMERs was sensible. Switching to a plain LM when the random effects were not needed was in principle a reasonable step, although it’s possible that if word were included as a random effect then this would not been necessary. ","The lack of inclusion of word as a random effect is a glaring flaw in the analysis. The exclusion or inclusion of the focus condition in some models was not justified. ","The variables included were suitable. Again, the lack of word as a random effect is inexplicable. ",See above.,"The analysis included data from all focus conditions – i.e. NF, ANF, and AF. However, the typicality values are not evenly distributed throughout these conditions. Notably, only the NF condition features the full range of typicality (“atypical” through “typical”), the ANF condition only has phrases of high and medium typicality, while the AF condition only has phrases of low and medium typicality. This confound between focus condition and typicality makes interpretation of the results challenging.","Duration data were log-transformed. All numerical data were subsequently z-transformed. These are appropriate transformations. ","It was not clear from the report whether this was the work of one person or a team, and if the latter, how the work was shared and if any measures of inter-rater reliability were made."
2022-04-29 10:07:07,2022-04-29 10:11:36,IP Address,80.7.115.73,100,269,True,2022-04-29 10:11:36,R_AHRiCRbG0ZanT5D,,,,,53.9573,-1.0837,anonymous,EN,chelonia_brummeri,pseudopleuronectes_assasi,95,85,90,publishable with minor revision.,"We discussed a score of 90 for the statistical analysis itself, but reduced it to 85 because the presentation of the analysis techniques and results was not all that easy to follow in places, and would have been greatly enhanced by use of some plots (e.g. to illustrate the arguments about normality). ","The choice of test is appropriate (lmer) and the approach is reasonable i.e. comparison (using likelihood ratio tests) of a null model (with random effects only) to a model which includes the fixed factor of interest as well as random effects. A limitation of the choice to use lmer is that the data did not allow inclusion of random slopes, but only random intercepts for speakers/items. ","The report provides a good amount of information about the rationale for the choice of variables and for the structure of the models. ","The DVs (duration/F0/intensity/F1~F2) are appropriate choices for investigation of acoustic cues to prominence in German. ","The appropriate fixed factors were investigated (focus condition in Study 1; typicality in Study 2); it made sense to include sex as an additional fixed factor only for F0. They clearly acknowledge that the inability to include random slopes is a limitation of the analysis, and interpret the results with caution.","They identified appropriate subsets of the data to work in in which it was safe to compare within/across conditions (e.g. avoiding comparisons where nouns differ across conditions). 

The Study 1 analysis serves to show that there is meaningful variation in the chosen DVs in response to the condition focus (i.e. in the expected direction, except for F1~F2). Study 2 addresses the main RQ regarding typicality and yields a null result. One could argue that the null result cannot simply be set aside as a result of e.g. task failure, due to the observed effects of focus on the same DVs in Study 1 (the authors don’t make this argument but are appropriately cautious and just reject the hypothesis).","We did not quite grasp the arguments put forward about the lack of normality in the distribution of the DVs, and it was complicated by mixed results from normality tests. Some plots of the data might have helped clarify this argument. An alternative approach to normalisation (e.g. to a relevant local domain/baseline measure for each speaker and/or token) might avoid this issue and allow easier interpretation of the data.","For reproducibility, we would recommend saving an annotated R script instead of the R console history. In general, the argumentation in the results would have been enhanced by provision of descriptive statistics (e.g. plots) as well as the results of the statistical models. "
2022-04-29 09:57:55,2022-04-29 10:38:11,IP Address,92.5.242.235,100,2416,True,2022-04-29 10:38:12,R_1QfkpH4jHzBqvaJ,,,,,53.4606,-2.2572,anonymous,EN,naso_cassivellaunos,linckia_nattereri,66,70,23,publishable with major revision.,"Team 'linckia_nattereri' took a maximal approach, measuring various segmental, prosodic and voice quality acoustic markers. We rated 66 for the phonetic analysis for the team’s effort and thoroughness. See below for detailed comments on the problems that we have identified. 
 
For the statistical analysis, the ‘linckia_nattereri’ team provided a summary of their variables, correlations between the variables, and the outputs of a clustering analysis (Principal Component Analysis [PCA], Random Forest) and Bayesian modeling. The choice of the statistical analyses is appropriate, targeting a multidimensional approach in order to explore which variables would be of primary interest.

The overall rating reflects our concerns about how to link the research question, data analysis, and interpretations. As alluded to in our review of the suitability of the acoustic variables below, the choice to measure whole words has unfortunate implications. The problem is more general than the contested choice to analyze segmental variables, which affects a subset of the variables. This problem affects all the variables as it appears to blur distinctions across the board. This is so because we expect to find relevant effects within mostly syllable-size portions of speech but in this study, they were measured together with (i.e. they were affected by) all the other syllable(s) in the same word.

Perhaps not less problematic is the fact that in order to reduce scores to a single scale, Team 'linckia_nattereri' chose to present the values as the difference between the values for the noun and the adjective (Adjective minus Noun), essentially preventing the possibility to interpret any of the findings in terms of actual acoustic events. We believe that this interpretability problem at the heart of this study greatly undermines an otherwise worthy effort by Team 'linckia_nattereri’.
","All measurements (means, medians, standard deviations, etc.,) were transformed to a difference between the obtained value on the Noun minus the obtained value on the Adjective, providing a derived estimate of the amplitude of change of each estimate from the adjective to the noun. Correlations were used to identify co-modulated variables before running multidimensional classification analyses. Predictive modeling was performed by running a PCA and then a Random Forest classification in order to examine whether and how the dependent variables formed clusters depending on the typicality; the Bayesian modeling tested the predictive power of the ‘typicality’ factor for various measurements. The PCA was used both as a dimensional reduction technique and as a clustering one. Factor loadings from the PCA were used to identify main dimensions and their relation to corresponding variables. Following these results, the authors selected 6 main dimensions on the basis that each dimension accounted for more than 5% of the variance. The total variance explained for these 6 dimensions was 64%. According to the PCA results and based on these dimensions, the 3 typicality categories were clustered separately. The authors describe relations between each dimension and the separation between typicality levels. The random forest technique was applied to evaluate the contribution of each predictor to the clustering in terms of typicality after removing predictors with high correlation levels (R^2 > 0.9), reducing the total number of predictors from 44 to 33. A confusion matrix was used to estimate the goodness of the obtained model. 

The quantitative results seem fair, showing that there’s a relatively good classification performance on the basis of the 33 predictors. The confusion matrix seems to have been color-coded with various grey shades but we could not make sense of what different shades indicate. It is a serious issue for information transfer to the reader. The authors then focused on the 10 best predictors deduced from this clustering technique. Following this section, these 10 best predictors were entered into a Bayesian logistic mixed model in order to estimate both the posterior probability of each associated effect and the corresponding effect sizes. 

Overall the analysis is sound, with justifications concerning the relations between each step of the analysis.
","Team 'linckia_nattereri' do not provide an explanation as to why they chose to look at segmental markers. This is problematic given the design of the data, in which each noun is combined with a particular adjective. We therefore did not understand why segmental markers were chosen. However, as the modeled variables were always expressed in terms of a difference between the adjective and the noun, this issue may be partly attenuated, but not fully, as each typicality level was associated with different adjective-noun pairs. Each difference within a typicality level was associated with different word pairs with different segmental contents. It is therefore very likely that any pattern associated with the segmental measures would reflect segmental differences rather than typicality variations.

Under prosodic measures, Team 'linckia_nattereri' looked at intensity and F0 measurements. The procedure for the error reduction in F0 is sound. We also think that the choice of 'Rise' measurements makes good sense, but note that the F0 trajectory in the data seems to be mostly falling throughout the noun phrase for the vast majority of speakers, so in hindsight, it's not that clear what these measurements capture.

Team 'linckia_nattereri' also chose a set of ""voice quality measures"". They measured the ""Harmonics to noise ratio"" (HNR) in Praat, which they also present among other variables (they used HNR to also compute other related variables). Note that these measurements, which are very sensitive to physiological differences between different speakers, are also quite reflective of differences in the segmental makeup (e.g. voiceless vs. vocalic material), such that they may be quite problematic (especially raw HNR) in the context of this data which is not lexically balanced by design.


","The different variables that were analyzed could be justified under certain contexts, but we found the given contexts unsuitable. For example, we'd expect segmental measurements like formants and even HNR (see the previous answer) to make sense if the segmental materials were controlled for, or if the nouns and adjectives in the MSA data were counterbalanced. However, they are not and there does not seem to be an appropriate context to look at segmental markers in this case.

Furthermore, we expect prosodic and (for that matter also) voice quality differences to play a role at specific positions in prosodic structures. We would therefore expect that such measurements would at least pay attention to final positions and/or stressed positions of structures in their targets. Team 'linckia_nattereri' measured all the variables within entire word intervals, blurring links between potential post-lexical events and their position in prosodic word structures (e.g. word-final rise/fall would be diminished given the number of preceding syllables and their F0 trajectory).

We find the choice to measure whole words unsuitable in the context of this task and we believe that this choice has some problematic implications.
","The succession of phases in the analysis (correlational analysis, PCA, Random Forest, Bayesian modelling) is clearly argued. The two main issues in the analyses relate to (1) the color-coding scheme of the confusion matrix which does not make sense in relation to the model’s performance, and (2) more critically, the decision that the authors assume concerning the random-effects structure in the Bayesian modeling part: they state that ‘The model included speaker as random effect. No other random effects were included as this led to R crashing.‘ It is not satisfactory to make a choice based on software limitations, it should be argued in terms of data structure. Indeed, ‘item’ may clearly not be treated as a random factor in the Bayesian analysis as the same adjective was used in all typicality conditions (atypical, medium and typical) but different nouns appeared across the typicality conditions. Except for this limitation, the structure of the model is well-conceived. In line with this issue, The exact random structure of the model is not stated in the report, though it is accessible from the scripts provided. In the end, only a random-intercept by speaker was included in the model. After all other solutions failed in terms of computation.

Overall, the authors choose to model typicality as the outcome with each of the ten continuous variables as a predictor, fitting a logistic model. The results are compared with the random forest ones and seem to be mostly comparable. The main predictors, according to their analysis, would be F2 (it should be transcribed as ‘F2’, not ‘f2’), intensity, tilt, glottal excitation, and energy. Some are associated with only a small effect-size but these are not provided in the report. F1 does not stand out from the Bayes model though it is the best predictor in the Random Forest. The report lacks a perspective on the very different status of the outstanding predictors: indeed, at least some of them are clearly related to spectral content that will be associated with segments. Therefore, they would necessarily correspond to categorical associations that would imply a confusion between typicality and word sequence.

","Only NF tokens were analysed. This choice is justifiable given that we were interested in the ‘typicality’ as a predictor within the NF condition. ","We were not certain whether this question concerned treatments of the phonetic data (e.g., speaker normalisation) or those for the variables in data modelling. If the question concerned the latter, no transformation was done. It is justifiable in the given analysis, but see our comments about the selection and treatment of the variables.  ",
2022-04-29 13:07:47,2022-04-29 13:17:57,IP Address,73.217.118.234,100,609,True,2022-04-29 13:17:57,R_3qqA7SSbouxG2Uj,,,,,39.9834,-105.143,anonymous,EN,nestor_idahoensis,sphyrna_ellioti,85,95,93,publishable with minor revision.,"While this is generally an appropriate acoustic analysis, we have some concerns about the inclusion of intensity as a variable as well as need for more detail about measurement. For intensity, we don’t think it is an appropriate variable to include without more information about how the study was conducted and what the recording conditions were. We would also like a description of heuristics for flagging/manual measurement of implausible values generated during the automated analysis, such as inconceivably short aligned intervals, high/low F0 outliers, and a missingness analysis for files not surviving automatic analysis. Finally, how was the by-talker centering of F0 conducted?  ","The mixed effects models were appropriate for the analysis. Use of Bayesian models would have allowed for a greater ability to use maximal random effects structure. However, frequentist models are sufficient for the analysis.  ","While the analysis was thorough, it was more broad than the research question posed, mainly due to the inclusion of the focus condition. Rather, simply including typicality and part of speech would be sufficient to answer the research question. 
","The variables included were suitable, but other relevant variables may have been excluded, such as spectral tilt (Aronov & Schweitzer, 2016).
",The structure of the statistical model was appropriate for the analyses.,"The author included all of the data, including all conditions (NF, AF, ANF). This may have influenced the findings for the NF condition, since condition affected prosody in all of the analyses. It would be helpful to learn whether excluding the AF and ANF conditions lead to the same results.","Why were the transformations for duration/F0 used? A sentence explaining each would have been helpful here. ",
2022-04-23 13:31:33,2022-04-29 14:57:07,IP Address,153.104.35.64,100,523534,True,2022-04-29 14:57:07,R_stzffqSvIOeWLXH,,,,,40.0428,-75.3506,anonymous,EN,polymetme_brevirostrum,epinephelus_aztecus,85,80,83,publishable with minor revision.,"My ratings were based on replicability, motivation of the study from previous research, appropriateness of the analysis given the data and hypotheses, and interpretation of results. I did not realize that I would not be able to revise my ratings once I click the arrow button; had I known, the ratings would be lower than they are.","SEM is a good choice for exploratory analysis, but it is prone to overfitting. Indeed, the results of both SEM models (particularly, RMSEA, CFI, and SMSR) indicate that it’s too tightly fit to the data and likely not generalizable. Mixed effects regression is an appropriate alternative, but the implementation is not statistically sound.","The process of choosing variables was appropriate, but the structure of the models is not. The structure of the SEM is not indicated in the writeup; typically, path-based models have a visual representation of the posited structure to help the reader understand the many different connections being assessed. The major offender is the mixed effects regression, where separate models were run for each factor with only a random intercept by word. These models, being vastly underspecified, have a high risk of type 1 error (seeing something that isn’t there). ",Variables selected seemed appropriate and justified by the hypotheses.,"The SEM models are likely overfitted to the data, and the mixed effects models are likely underfitting the data. In particular, the structure of the mixed effects regression is problematic.","Discarding errors makes sense, but there are other comments in the “Notes” section (e.g., “hesitation break”) that should warrant consideration for exclusion as well. ",N/A,"The Rmd document is not anonymized, so the author can be identified."
2022-04-29 04:41:09,2022-04-29 16:57:28,IP Address,86.170.68.144,100,44178,True,2022-04-29 16:57:28,R_1I5GrkRgNqGo24W,,,,,57.5845,-6.3549,anonymous,EN,trigonias_lachneri,anomalocaris_ornata,80,53,60,publishable with major revision.,"Overall, appropriate models for analysed outcome variables were used, and an attempt was made to include the maximal random structure where possible, which is a strength of the analysis. In situations where convergence problems occurred, the researchers could have used optimisers and keep the maximal random structure.

There are some aspects of the analysis that require additional explanation in our view.  For example, in some of the models the researchers use the binary ‘col_obj’ variable in the random structure and in others they used ‘word’ but it does not become entirely clear why there are different approaches for different outcome models. I our view, ‘word’ might have generally been a more appropriate variable to include than ‘col_obj’, as it should capture more variation. 

Further, each model was checked for ‘best fit’, and it would have been interesting to check whether ‘colour’ and ‘object’ independently affected each model first before creating the combined variable ‘col_obj’.

Overall, appropriate models for analysed outcome variables were used, and an attempt was made to include the maximal random structure where possible, which is a strength of the analysis. In situations where convergence problems occurred, the researchers could have used optimisers and keep the maximal random structure.

There are some aspects of the analysis that require additional explanation in our view.  For example, in some of the models the researchers use the binary ‘col_obj’ variable in the random structure and in others they used ‘word’ but it does not become entirely clear why there are different approaches for different outcome models. I our view, ‘word’ might have generally been a more appropriate variable to include than ‘col_obj’, as it should capture more variation. 

Further, each model was checked for ‘best fit’, and it would have been interesting to check whether ‘color’ and ‘object’ independently affected each model first before creating the combined variable ‘col_obj’.

Our most serious concern with the analyses is the way in which the food items (nouns) were included in the analysis, as the nouns were not balanced across the three typicality conditions. In our view, their varying segmental and syllabic composition, stress pattern and length will confound the typicality condition. For example, all words in the 'typical' category have unchecked/long/tense vowels (with the possible exception of 'Erdbeere'), while three of the 'atypical' words have checked/short/lax vowels.

The statistical code provided might need updating, adding a list of packages and a clarification which specific dataset the models are based on. When we ran the model for dB^2, the resulting numbers were different from the reported ones. This is probably a minor issue as the statistical significance results remained the same. 

Lastly, in our interpretation, the task was to provide one overall answer to the research question about utterance modulation in response to information typicality, and this approach provides several answers from different outcome variables, and does not become clear which variable the authors want to prioritise over the others as the final answer.


The statistical code provided might need updating, adding a list of packages and a clarification which specific dataset the models are based on. When we ran the model for dB^2, the resulting numbers were different from the reported ones. This is probably a minor issue as the statistical significance results remained the same. 

Lastly, in our interpretation, the task was to provide one overall answer to the research question about utterance modulation in response to information typicality, and this approach provides several answers from different outcome variables, and does not become clear which variable the authors want to prioritise over the others as the final answer.
","Linear mixed models seem appropriate for the continuous outcome variables analysed, considering that multiple participants responded to the same stimuli and that the same words (for adjectives) occurred in different conditions.","More information is needed on how the cut-off levels for voice_type were chosen and how the variable adds to answering the question. If it is used as proxy for binary genders, could the authors provide a rationale for their assumption that the genders might differ in their approach to information marking with prosody? 
Also it might have been more appropriate to add voice_type in interactions with the remaining variables if the authors thought that gender could lead to different responses to changing typicality.

When analysing pitch, the researchers split the data into two using the already arbitrary cut-off points of voice_type. Why was that level chosen? Why was voice_type left in the model, considering that a semitone transformation would have normalised the data? The bimodal distribution is explained as having occurred due to an impact of voice_type on F0 (dependent variable), however splitting the data reduces the power of the model, and seems like an ad hoc rationale for fitting the model.
","As mentioned above, a clearer rationale is needed for the voice_type variable. Even if it improves AIC somewhat, without an additional theoretical rationale we are not convinced that it needs to be included, particularly in the split f0 models.

Including nouns (objects) is unlikely to be a reasonable decision considering they were not balanced across typicality levels and had different lengths and syllabic structures. 
Issues with the variables in the random slopes and intercepts were also pointed out above.

Considering that only one answer (effect size and CI) was required at the end, we are not sure why typicality was included as a categorical variable or which specific partial effect (level of the variable and its interactions) the researchers want to highlight as the main answer. 

","If inclusion of col_obj in the random structure of the intensity and f0 models was inappropriate (1+col_obj|Word) why weren’t just random intercepts per word included (1|Word) as in the vowel duration model? As mentioned before, this would not be a problem if only colour adjectives were included.

As mentioned before, it is unclear why voice_type was included, and why it was included as a separate predictor without adding it to any interactions or in the random structures of the models.

The vowel duration model would have been appropriate if nouns were excluded and optimisers were used to help preserve the maximal random structure.

","We have already commented on the problem of not excluding nouns.
It is potentially problematic that outliers were excluded only from the f0 data but not from the intensity and vowel duration data. While it is reasonable that measurement errors might have occurred in f0, this may also have happened for intensity or duration.

","Semitone transformation was explained and it appears reasonable. ","The figures were not clearly labelled and numbered. "
2022-04-29 16:03:41,2022-04-29 17:17:40,IP Address,179.0.56.75,100,4439,True,2022-04-29 17:17:41,R_W2s9L9ecm2QPrBT,,,,,-27.6027,-48.5541,anonymous,EN,arapaima_modularis,naso_cassivellaunos,60,90,80,publishable with minor revision.,"The analysis seems appropriate and well-motivated. The results are consistent with the descriptive statistics. I have no objections with the selection or execution of the analysis. My major concern has to do with the data the analysis was performed on. In particular, the authors excluded a massive amount of data points, beyond the ones labeled as ""errors"" by the MSA project. In total, this analysis examined 336 tokens (approximately 11 per participant) out of the possible total 900 tokens. This was due to the type of adjective+noun combination chosen for the analysis, namely tetrasyllabic noun phrases, which reduced the possible A+N combinations to 6 (out of 15). The motivation to choose only A+N with this particular syllabic structure is unclear to me.  ","The analysis is clear and well-motivated. I would not change any aspects of it. ","The three outcome variables are hardly motivated. The analysis would have been stronger and more convincing if authors had explained why they chose these particular acoustic cues (and not others). In principle, I think they are good choices, but it would have been good to see the explanation and rationale as provided by they authors. 
The independent variable is the obvious one (typicality). ","As explained in the previous point, it is not clear why the authors believed the three acoustic parameters would be good candidates to answer the research question. 
As for the independent variable (typicality), it is the expected variable to choose, so I have no issues here. However, the massive amount of data this analysis discarded meant that this variable was only viable with two levels (atypical vs typical), while the intermediate level the original data set contained (medium typicality) had to be excluded. The analysis could have been more informative if this third level had been included. ","It seems well-structured. ","By working with two-syllable adjectives and nouns only, this analysis excluded too many tokens, as explained above. So much so that, for example, the 'medium typicality' condition ended up with one noun phrase only, and was thus eliminated from the analysis altogether. The authors did not explain why they chose to work with four-syllable combinations of N+A only, so I am not sure this type of exclusion was warranted.   ","The data transformation seemed appropriate. However, the measures for the three acoustic parameters seemed particularly difficult to understand. In particular, it took me many readings and some background searchers to understand the concept of ""mass"" as computed by ProPer, and I am still not sure I understand it completely. This could be my own limitation, but I can usually follow an analysis or explanations for data transformation if enough information is provided. I would have liked to see more detailed, easier-to-understand steps regarding how the three acoustic parameters were calculated. ",
2022-04-29 17:32:46,2022-04-29 17:39:49,IP Address,177.18.234.107,100,422,True,2022-04-29 17:39:49,R_3EyaUfmQSOei7Ep,,,,,-15.7792,-47.9341,anonymous,EN,swiftia_ruber,neosilurus_omanensis,90,90,90,publishable as is.,"Audio and text-grids were automatically force-aligned using software for this purpose, and a part of this alignment was double-checked by human annotators. Automated force-alignment needed to be used anyway due to time and financial constraints. Human-annotated data was used when available, and the remaining data used came from the automatic force-alignment. Four pitch-related variables were used (pitch ratio of the adjective, pitch range ratio of the adjective, pitch variation ratio within the adjective, pitch change ratio within the adjective) as well as speech ratio. Using five acoustic cues certainly enriches the analysis, though we understood that only one dependent variable should have been used.","Linear regression models were appropriately used for the analysis. For each dependent variable (there were 5, see comment on previous and next questions) two models were fitted, one with 'typicality' as an independent variable, and another adding 'context' and an interaction between typicality and context. Models were compared and the more complex model was used only if it added significant information. Analysts included varying terms for participant and adjective when the model converged, and dropped them when convergion was an issue, but did not mention if only varying intercepts or also varying slopes were included. When varying terms were dropped, they did mention which one(s) ended up being dropped.
Statistical analysis was appropriate. Analysts made sensible adjustments to p-value interpretation (raising alpha for the one-tailed interpretation, but also correcting p-values for multiple comparisons). They also calculated effect sizes, which were in general very small (though analysts did not comment much about them). All information provided by the models (beta coefficients, p-values and effect sizes) led to the conclusion of no effect of typicality. ","A total of ten models were fitted, and five were reported, since five dependent variables were used for the analysis (4 related to pitch and 1 to speech rate). Correction for multiple comparisons was done. This is very informative for the analysis, though we understood that  each team should have selected only one dependent variable and therefore only one statistical model to be reported. The dependent variables were:
1) Pitch ratio of the adjective
2) Pitch range ratio of the adjective 
3) Pitch variation ratio within the adjective
4) Pitch change ratio within the adjective
5) Speech rate (articulation rate) of the adjective ","Procedures for including/excluding variables, which have already been commented on, were appropriate.","The structure of the statistical models was suitable, as already commented on.","Speech rate outliers of more than two standard deviations from the participant’s mean were deleted. Also, for both adjective and sentence, the pitch minimum and maximum and the pitch range of the first 10% and last 10% were deleted if they exceeded the range of the mean plus/minus two standard deviations. The amount of deleted values was considerable, especially for maxima and minima, which affected the analysis of pitch range and pitch rise, but since the remaining data were still balanced, they were used.",There was no data transformation.,
2022-04-29 15:54:38,2022-04-29 18:10:08,IP Address,174.18.46.221,100,8129,True,2022-04-29 18:10:09,R_1DoQyj6SypPMXeK,,,,,32.1453,-110.9456,anonymous,EN,comanthina_maculatus,arapaima_modularis,100,100,100,publishable as is.,"The report explains in detail their approach to the question, how they segmented the files, exclusion criteria, statistical analysis, descriptive and analyzed statistics, and conclusion.","Given the statistical setup, I find the choice of a repeated measure ANOVA fitting.","They decided to measure Pitch and determine if it is modulated by the three levels of typicality, which fits the research question as provided.","As the participant information given was that the group was homogeneous, there were no extralinguistic variables to include; pitch as a function of typicality, so to speak, is how they created the model, which is minimal but fully adequate given the approach.","Given the RQ and approach selected, it was suitable.",The exclusion of outliers and tokens with errors was adequately addressed.,,
2022-04-30 02:49:26,2022-04-30 15:15:19,IP Address,5.132.95.23,100,44753,True,2022-04-30 15:15:20,R_3kbQrrF1bHfjnzc,,,,,51.7285,5.8849,anonymous,EN,ctenosaura_limax,cromileptes_saxatilis,90,85,87,publishable with minor revision.,"Overall, the report is very well-written with clear documentation of all the steps and accompanying codes. 
The only information that I find a little hard to find is what exactly is included in the 'notes' tier. This report would benefit from making this clear since the data exclusion is dependent on this information. There are some descriptions of what 'error' is but not other types. 

The statistical models were also well presented. However, I would like to play devil's advocate and express the concerns for people who are not completely familiar with or convinced by bayesian methods, since it is still a relatively new statistical procedure for the field. My biggest concern is how the priors were chosen, and how different priors could lead to different results. For instance, the min, max, and mean duration were all taken from the current data. Is this the norm? Are the current data representative enough as 'average segment duration'? How to include previously published literature on segment duration? What would be the consequence if another person uses a different value, say setting the minimum as 0.1 and maximum as 1.2? I understand the authors have included references which may have the answers for all these questions. However, I think as for now, it is better to include explanations and interpretations in all reports which use Bayesian method until it is more widely understood in the field. I am by no means against using this method, but my suggestion is for the authors to include more explanations.",Good attempt but needs more explanation.,"To the best of my knowledge, the process is good. ",The variables selected were suitable for the research question the authors presented.,It is suitable.,"As I previously mentioned, the 'notes' tier needs a bit more detailed description. Having examined the codes and data frame, I think the data exclusion procedures in this report were justified.",n/a,
2022-04-25 02:14:14,2022-04-25 02:26:34,IP Address,46.242.13.125,20,740,False,2022-05-02 02:26:35,R_2sZwQRBrANAcRxx,,,,,,,anonymous,EN,pseudodax_euryzona,lycodes_bradfieldi,,,,,,,,,,,,
2022-05-02 02:43:10,2022-05-02 03:03:20,IP Address,141.5.2.21,100,1209,True,2022-05-02 03:03:20,R_1Ic4Pc9VHUAcBy1,,,,,50.1376,8.6776,anonymous,EN,lycodes_bradfieldi,gymnothorax_spinulosus,80,75,74,publishable with major revision.,"The statistical analysis seems sound. The SPI is defined as the cumulative sum of signal energy (En) multiplied by the logarithmic expression of the maximum F0 divided by the minimum F0. However, we wonder why the index was calculated over the whole word, rather than at the elongated/stressed phoneme (or syllable containing the vowel), as in the cited reference paper for SPI. Perhaps the choice of the duration of the entire word introduces noise, reducing the difference between typical and atypical. We were not familiar with the SPI – has it been shown to be relevant outside of Parkinsonian contexts?

We also have some statistical concerns, which we share below in Q15.
","The choice of a linear mixed model is appropriate as the authors considered speaker and target color as random factors.  Target color accounts for word-level effects, which may be a confounding factor (i.e., some words may be longer than others, and therefore have more data going into their SPI estimate).","The authors included typicality not as a categorical but as a continuous variable, which is an appropriate choice. They only analyzed the NF condition, which contains a balanced number of typicality trials. The dependent variable (SPI) was chosen based on previous clinical work and calculated for all color words. ","See before
",See before,"Given that typicality was only balanced for the NF condition, it seems appropriate to exclude the other conditions. The authors also excluded all data that contained comments in the text grid, such as “hesitation” or “noise.” A crucial information that is missing pertains to the number of trials this approach excluded. While LMMs handle missing data well, there was not so much data to begin with (30 participants with 10 trials per the three typicality conditions).","SPI was log-transformed as it was found to be non-normally distributed. Our understanding of LMMs is that the DV can be non-normal, as long as the residuals are normal. Perhaps this transformation is unnecessary and skewing results. It may be better to run the model with the non-transformed data and check the redisiduals for normality, before transforming (if necessary). Or perhaps switching to a GLMM is more appropriate to deal with non-normality.",
2022-04-25 03:53:12,2022-04-25 07:56:08,IP Address,94.211.244.41,20,14575,False,2022-05-02 07:56:14,R_2dXZy5xauGlxbma,,,,,,,anonymous,EN,neosilurus_omanensis,pseudodax_euryzona,,,,,,,,,,,,
2022-04-26 06:34:50,2022-04-26 07:46:49,IP Address,193.61.240.173,40,4318,False,2022-05-03 07:46:54,R_1F5Pk069RvxLKPk,,,,,,,anonymous,EN,naso_cassivellaunos,linckia_nattereri,25,37,56,publishable with minor revision.,,,,,,,,
2022-04-27 06:42:11,2022-04-27 07:12:02,IP Address,92.5.242.235,40,1790,False,2022-05-04 07:12:10,R_1n6MgIIobndzD3b,,,,,,,anonymous,EN,naso_cassivellaunos,linckia_nattereri,66,70,23,publishable with major revision.,,,,,,,,
2022-04-27 07:57:55,2022-04-27 08:43:22,IP Address,147.188.245.202,40,2726,False,2022-05-04 08:43:24,R_wLcFOwV7Wp5qxrj,,,,,,,anonymous,EN,hoplostethus_macrosteus,epinephelus_aztecus,95,89,97,publishable as is.,,,,,,,,
2022-05-04 13:50:47,2022-05-04 15:09:25,IP Address,128.252.25.52,100,4718,True,2022-05-04 15:09:25,R_ehbJGyyC8hbrAOt,,,,,38.6664,-90.322,anonymous,EN,trachyphyllia_lappa,aracana_bitatawa,50,75,75,publishable with minor revision.,"Our primary concern with the phonetic analysis is that, while the authors report manually correcting the adjective and noun boundaries, they do not mention any additional exclusions/complications on the basis of that hand correction. For example, how did they handle pauses between the adjective and the noun? See comments below regarding statistics.","Quantile generalized additive mixed models were used, but it isn't clear to us why this approach (which we are admittedly not familiar with) is better than standard mixed models. Linear mixed models are quite robust to violations of the normality assumption, which seemed to be the primary concern. However, even that concern was a bit unclear as they referred both to the normality of the residuals and the normality of the data.",See below.,See below.,"We did not fully understand the motivation for including number of syllables and not speaking rate in the final model for the duration analysis. It seems like number of syllables can be accounted for by the fact that random intercepts were included for nouns. Given that, speaking rate would make more sense as a fixed effect.","This analysis included both NF (3 levels of typicality) and ANF (2 levels of typicality) for duration. It was not clear whether both were included for the F0 analysis. 

Importantly, both repetitions of each item by each speaker were included throughout, but they did not control for repetition in their models. This is potentially problematic as an atypical combination may be less atypical the second time it is encountered.

These analyses included only the adjectives. However, it is entirely possible that speakers might phonetically mark the typicality of an adjective-noun pairing on the noun. It seems like a missed opportunity not to include the nouns in analysis.","F0 measures were z-normalized to avoid sex differences. Since participant was included as a random effect, this may have been unnecessary. ","This analysis included an important investigation into the typicality manipulation. Specifically, they looked at Google bigram frequency of the adj-noun pairs, finding significant overlap in the frequency of different typicality conditions. "
2022-05-02 10:15:26,2022-05-02 10:15:44,IP Address,184.64.221.169,20,18,False,2022-05-05 19:37:00,R_2rxrrDMr9GpbIGz,,,,,,,anonymous,EN,pseudopleuronectes_assasi,procambarus_maculosus,,,,,,,,,,,,
2022-04-29 07:18:57,2022-04-29 07:59:49,IP Address,89.206.64.8,40,2452,False,2022-05-05 19:37:04,R_2qsC5GQohNrzUoK,,,,,,,anonymous,EN,aratinga_lugubris,procambarus_maculosus,79,31,52,publishable with major revision.,,,,,,,,
2022-05-05 01:55:18,2022-05-05 01:59:49,IP Address,194.254.61.43,20,271,False,2022-05-05 19:37:08,R_1XJBHYiycHOytXj,,,,,,,anonymous,EN,genyonemus_evotis,lycodes_bradfieldi,,,,,,,,,,,,
