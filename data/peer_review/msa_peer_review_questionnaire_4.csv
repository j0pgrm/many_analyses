StartDate,EndDate,Status,IPAddress,Progress,Duration (in seconds),Finished,RecordedDate,ResponseId,RecipientLastName,RecipientFirstName,RecipientEmail,ExternalReference,LocationLatitude,LocationLongitude,DistributionChannel,UserLanguage,Q2,Q3,Q5_2,Q5_3,Q5_4,Q6,Q8,Q9,Q10,Q11,Q12,Q13,Q14,Q15
Start Date,End Date,Response Type,IP Address,Progress,Duration (in seconds),Finished,Recorded Date,Response ID,Recipient Last Name,Recipient First Name,Recipient Email,External Data Reference,Location Latitude,Location Longitude,Distribution Channel,User Language,"Your team name (i.e., the fantasy animal)",The team name (fantasy animal) for the analysis you are reviewing.,"Please rate the following aspects of the study under review with regard to how well they answer the research question (""Do speakers acoustically modify utterances to signal atypical word combinations in referring expressions?"") with the available data. - Rate the phonetic analysis","Please rate the following aspects of the study under review with regard to how well they answer the research question (""Do speakers acoustically modify utterances to signal atypical word combinations in referring expressions?"") with the available data. - Rate the statistical analysis","Please rate the following aspects of the study under review with regard to how well they answer the research question (""Do speakers acoustically modify utterances to signal atypical word combinations in referring expressions?"") with the available data. - Provide an overall rating",Would the analytical methods presented produce an analysis that is:,Please explain your ratings of this analysis.,Please evaluate the choice of statistical analysis type.,Please evaluate the process of choosing variables for and structuring the statistical model.,Please evaluate the suitability of the variables included in (or excluded from) the statistical model.,Please evaluate the suitability of the structure of the statistical model.,Please evaluate choices to exclude or not exclude subsets of the data.,"Please evaluate any choices to transform data (or, if there were no transformations, but you think there should have been, please discuss that choice).",Please use this space for any additional comment you may have at this stage.
"{""ImportId"":""startDate"",""timeZone"":""America/Denver""}","{""ImportId"":""endDate"",""timeZone"":""America/Denver""}","{""ImportId"":""status""}","{""ImportId"":""ipAddress""}","{""ImportId"":""progress""}","{""ImportId"":""duration""}","{""ImportId"":""finished""}","{""ImportId"":""recordedDate"",""timeZone"":""America/Denver""}","{""ImportId"":""_recordId""}","{""ImportId"":""recipientLastName""}","{""ImportId"":""recipientFirstName""}","{""ImportId"":""recipientEmail""}","{""ImportId"":""externalDataReference""}","{""ImportId"":""locationLatitude""}","{""ImportId"":""locationLongitude""}","{""ImportId"":""distributionChannel""}","{""ImportId"":""userLanguage""}","{""ImportId"":""QID2""}","{""ImportId"":""QID4""}","{""ImportId"":""QID6_2""}","{""ImportId"":""QID6_3""}","{""ImportId"":""QID6_4""}","{""ImportId"":""QID7""}","{""ImportId"":""QID9_TEXT""}","{""ImportId"":""QID10_TEXT""}","{""ImportId"":""QID11_TEXT""}","{""ImportId"":""QID12_TEXT""}","{""ImportId"":""QID13_TEXT""}","{""ImportId"":""QID14_TEXT""}","{""ImportId"":""QID15_TEXT""}","{""ImportId"":""QID16_TEXT""}"
2022-06-01 08:01:10,2022-06-01 08:06:56,IP Address,150.241.189.1,100,345,True,2022-06-01 08:06:57,R_33dtPdLm78AZJxa,,,,,43.3126,-1.9745,anonymous,EN,gymnothorax_spinulosus,comanthina_maculatus,16,10,13,deeply flawed and unpublishable.,"They only analyzed (coded) half of the data – I guess because of lack of time as they have done the coding manually (without using a forced aligner)
They did not take the condition (AF, NF, ANF) into account in their analysis, which lead to false conclusion because the effect of the condition is wrongly attributed to the typicality.
As ANOVA could not be applied here, they used t-test without explicitly correcting for multiple comparisons (unless I got it wrong) 
","The choice of doing multiple t-test does not seem good to me, as there are more than two modalities to compare. And it does not allow to take random factors into account.","Several dependent variables (which is not following the guidelines)
The process of structuring the statistical model is not really explained (since it’s t-test).
I acknowledge one good thing is that they rejected ANOVA because of the non-normal residuals.
","The condition should have been included as a fixed factor in the model as it clearly influences the prosody. (And not taking into account the condition leads to false conclusion on the effect of typicality)
The typicality has been included as a 3-modalities factor while I would prefer using the continuous variable typ_mean or typ_median not to loose information.
",I don’t know if we can speak about the model structure given that they only did some t-test. I would say the structure is not appropriate.,"Their choice is okay except that they did not analyzed half of the data (probably because they lack time I guess) which is not acceptable to me. They excluded errors properly, which is good. They did not exclude any outlier, which should have been done I think.","It’s okay. No transformation was applied, and I don’t think it would have been relevant.",
2022-06-01 07:31:37,2022-06-01 08:14:26,IP Address,96.242.236.104,100,2568,True,2022-06-01 08:14:26,R_3rSyqGFtq9RJdFb,,,,,40.5921,-74.6238,anonymous,EN,procambarus_mahogoni,aracana_bitatawa,90,75,80,publishable with major revision.,The explanation seems a bit inaccessible and over-complex for the given data set.,"The authors might have chosen a challenging statistical model instead of focusing on the research questions themselves. ","They chose duration and F0 of the adjective, which are good variables for answering the research question.","They are appropriate to answer the question provided given the data. ","Our minimal understanding of the model is that it is best suited for longitudinal data and for a larger data set. With that in mind, the model is too complex for the data.",N/A,"They z-normalized frequency values due to differences in sex of the participants. This was a good choice. ","We question the use of Google for frequency measures and the subsequent use of that measure in the statistical model, particularly given that we were provided with multiple measures of typicality, including a numeric one."
2022-06-01 07:41:43,2022-06-01 08:15:51,IP Address,85.245.142.120,100,2048,True,2022-06-01 08:15:52,R_1gI5xwPTZt6yfri,,,,,38.6417,-9.2401,anonymous,EN,eosipterus_pytyopsittacus,sphyrna_ellioti,40,60,45,publishable with major revision.,"This analysis aimed to examine typicality differences in duration, intensity, and F0 of the adjective-noun pair. The data processing steps were appropriate, especially the use of the MFA and the specified Praat scripts. However, the authors are not specific about which tokens they were examining, saying at one point that they were interested in the modifier-noun pair, but never further explaining whether they were looking at properties of the noun or of the adjective. Though this becomes apparent later when examining the model, their narrative description should have better detailed these choices. The choices of models and visualizations was also appropriate for their research question, but this analysis contains a critical flaw. By examining F0, duration, and intensity at the word level, the authors did not control for the fact that different segments have different expected properties. Crucially, by measuring F0 at the word onset, offset, and midpoint, they necessarily captured F0 values during some voiced and some voiceless segments, without controlling for segment identity. Similarly, by measuring the entire word duration and intensity, they introduced a lot of variation related to the fact that different words simply have different segments with different properties. This creates so much noise in the data as to make their claims very unreliable. A better method would have been to either control for segment identity, or to limit the analysis to vowels in the words and conditions of interest. ","The choice of statistical type was appropriate, and we appreciate their thoughtful choices with respect to data analysis. However, the strength of their statistics is somewhat undermined by the choice of variables, which has the outcome of producing results that are not reliable. These limitations are further discussed below. ","First and foremost, a major and critical flaw in the model is that they measured F0, intensity, and duration at the word level, as mentioned above. Since they did not control for the different segments, these measures will be so variant as to be meaningless in comparing values across typicality conditions.

In addition, the authors do not provide extensive justification for their choice of variables; essentially they are just looking for differences between typicality conditions. They do not state the direction of their hypotheses for these variables, which is a major limitation. Do the authors expect longer duration, lower/higher F0 or lower/higher intensity for entire words in the atypical condition, without controlling for segments at all? If so, what motivates these hypotheses?
","The acoustic variables were suitable for measuring acoustic differences between typicality conditions, though again, the authors did not provide a hypothesis or motivation for the variables they chose. The authors also did not control for effects of speaker, which is a major flaw given that this data set contains both male and female speakers, and F0 and intensity have been shown to vary predictably by gender. F0 measurements therefore should have been normalized, and speaker should have been added as a random effect in their model. ","The choice of a linear mixed effects model was appropriate.  The model included their variables of interest, but was limited by the fact that the F0 and intensity data was not normalized for important speaker characteristics (especially gender) which should have been included. ",N/A,"We think the authors should have normalized f0 (e.g., as a z-score according to speaker) to run measures on data that come from a variety of speakers.","There is a lot of good work here particularly in the data cleaning and statistical setup, but there are critical changes that would need to be made for the results to be meaningful: the normalization of F0 and intensity measures for each speaker, and a focus on a smaller target than the word-level, for the reasons discussed above. In addition, the authors are strongly encouraged to revisit the direction of effects in their hypotheses and to be explicit about what motivates these hypotheses. "
2022-06-01 17:17:59,2022-06-01 17:22:15,IP Address,166.88.131.233,100,255,True,2022-06-01 17:22:16,R_2cC2xQZFdnkWfVn,,,,,37.353,-121.9543,anonymous,EN,pervagor_meeki,alosa_atun,83,90,87,publishable with minor revision.,"Positives
- Pre-registration
- Well-organized report, most choices were well justified
- Statistical analyses are appropriate
- Well-defined procedure for arriving at the mixed effects model structure (starting maximal and pairing down via backward elimination)

Negatives
- Some of the pre-registered predictions are a little vague (e.g. for f0 and amplitude)
- Would have been useful to have p-levels for the model outputs (e.g., with lmerTest) as significance is hard to determine with t values alone
- Could have reported the model structure even for models that led to no significant effects
- Unclear if the fixed effects were treatment coded or not - if so, it might make more sense to use “T” as the baseline
",Mixed effects models are an appropriate analysis.,"1. There were a lot of dependent variables, some of which could be seen as redundant (e.g., both F1 and F2 and the euclidean distance between the two; several measures of duration). We would recommend narrowing down to fewer justified measures, even if the analysis is exploratory.

2. Including speech rate as a predictor is a good idea.

3. The team also nicely dealt with the uneven design by using typicality ratings rather than the typicality category. However since the ratings are not distributed equally across focus conditions (fig. 3) that might still lead to problems in the models (e.g. might be why there were convergence issues). A possible solution would be to run a separate model on each focus condition.
",The team mentions using the intensity/f0 from “den” as a control variable but it doesn’t appear to be included in any of the model structures reported,The overall model structure was well justified and there was a clear process for determining it.,"1. It would be useful to know how many trials included “den” and were therefore excluded from the analyses. The team could have included both for the /e/ analyses, adding phonetic context (/r/ or /n/) as a predictor.

2. How did the team identify “misleading or incomplete” observations, and how many were removed?
","1. We agree with the choice to center/scale trial number and speech rate (though we would suggest to use syllables x seconds rather than x minute)

2. Since the data included both male and female speakers, it would be appropriate to transform F0 and F1/F2 so that they’re both on linear scales (e.g., logging), rather than using an arbitrary 800 Hz upper limit.
",
2022-06-02 08:29:46,2022-06-02 08:39:41,IP Address,115.128.143.91,100,595,True,2022-06-02 08:39:42,R_1pMg4JzWNdrJ78X,,,,,-33.8715,151.2006,anonymous,EN,dunkleosteus_inscriptus,stygobromus_tyraica,90,80,85,publishable with minor revision.,This is an extremely comprehensive and robust analysis of the intervals of the speech dataset that are directly comparable (color adjectives in NF condition trials). The high dimensionality of the acoustic analysis is able to tease out differences between the utterances corresponding to changes in typicality. The major limitation of this approach is the restricted interval of speech which can be analyzed.,"The statistical analysis used in this study is entirely appropriate for the machine-learning methods deployed, although difficult to interpret.","The methods used to structure, evaluate and interpret the statistical models are state-of-the-art for this type of analysis.","The variables chosen for this analysis are generally appropriate, although the dataset was originally developed to analyze affective differences in speech, rather than prosodic differences. Nevertheless, one of the great advantages of this study is the use of high-dimensional acoustic parameterization, which may be able to detect differences between utterances not apparent with more simplistic acoustic characterizations.","The statistical models are structured in a way that is standard for this type of analysis, and entirely appropriate for this approach.","The exclusion of the 54 trials with notes is well motivated, as this removes utterances compromised by errors and hesitation break.  The analysis is restricted to the short interval of time corresponding to adjective production in NF trials; this selection is well explained and motivated as this technique requires directly comparable utterances, but it does mean that only a tiny subset of the data have been analyzed, so the results should be interpreted with some caution as this approach tells us nothing about overall patterns of production of the larger consistuents containing the adjectives.","The use of DCTs to parameterize the acoustic profile of the adjectives is entirely appropriate, and an effective way to efficiently represent the temporal acoustic dynamics of the speech intervals being compared.","This team have analyzed the acoustic profiles of adjectives in the NF condition utterances using a parameterized form of a set of 25 low level acoustic features originally developed for analysis of affective states in speech (GeMAPS). This is a comprehensive analysis of the way that the acoustic properties change over the speech intervals corresponding to the color words, and the data are interpreted by comparing the way that these dynamic feature sets differ with typicality, with respect to machine-learnt default characterizations.

Although this is a state-of-the art approach for affective computing, the analysis could use some further unpacking to make it more accessible to phoneticians less familiar with machine learning techniques. In particular, although the study is extremely well documented overall, it is not entirely clear how to interpret the significance of the findings, especially since the feature set used was designed to detect emotional, rather than linguistic differences between utterances.

Nevertheless, these data suggest that the utterances do differ with typicality, primarily in the spectral flux, loudness, spectral balance above and below 1 kHz, first three MFCCs, and F0 trajectories over directly comparable adjectives. It is not surprising that differences between utterances are encoded as complex combinations of acoustic properties, so this is an important contribution to the meta-study, as most teams will not have investigated multiple integrated phonetic properties, where subtle speech differences can be encoded."
2022-06-02 09:32:07,2022-06-02 09:33:24,IP Address,83.135.242.90,100,77,True,2022-06-02 09:33:25,R_e2LfBj8O2HQb1a9,,,,,50.973,7.1754,anonymous,EN,petauroides_fistulator,varanus_eulophotes,50,70,60,publishable with major revision.,"The phonetic analysis is described in great detail. The authors aim to extract average F0 values for each trial’s adjective. However, we fear that they did not regard the following issue: As an example, let us assume that two adjectives are of similar segments, i.e. that we have two productions of ‘grüne’. The segments of these two instances, however, differ in their acoustic durations. While for the first ‘grüne’ we find a relatively long vowel of the first syllable (i.e. the stressed one), for the second ‘grüne’ we find a relatively short vowel of the first syllable but a rather long nasal. Now, measuring the average F0 for both instances of ‘grüne’, we potentially find very different values even if the F0 of the stressed vowel is identical. Following the references given by the authors, this presents an issue: The vowel of the stressed syllable is the ‘main bearer’ of stress in German and thus should be main subject to any changes due to typicality; averaging F0 across all segments (ignoring their durations) potentially occludes such an effect. In sum, we think that the idea of using an average F0 is straightforward and well-motivated; however, the implementation lacks an integration of necessary detail.
The statistical analysis consists of two parts: 1) descriptive results, 2) inferential results.
Concerning 1), we are not sure why the authors include purely descriptive observations of their data. The differences shown across levels of typicality and across adjectives are small (i.e. they are small in their actual dimensions as given in the pertinent plots). The reader is not able to intuitively take away anything from the presentation but uncertainty.
Concerning 2), the authors used linear mixed-effects regression to analyse the influence of typicality on their dependent variable of choice, i.e. average F0. The authors try to obtain a more normal distribution of their F0 variable without success. However, this demonstrates that they are aware of such issues. They continue fitting their model with typicality as categorical fixed effect (3 levels) and random intercepts for speaker. We would have wished for a more in-depth discussion of how the random effect structure was chosen and why no random effects for item and/or adjective combinations were included. The authors report on the model’s residual distribution; yet they do not discuss it. We miss trimming of said residuals to achieve more reliable regression coefficients.
The overall rating is the mean of both other ratings. We chose ‘publishable with major revisions’ as we find that our concerns regarding the measurement of average F0 values as well as an overhaul of the statistical analysis is required.",We find that linear mixed-effects regression is an adequate choice of statistical analysis type.,"The authors make use of one dependent variables: average F0. The authors do provide motivation for their choice of dependent variables.
As independent variables, typicality and speaker are used. Typicality being the predictor variable of interest, including it is straightforward and requires no further motivation. Speaker was included as random effect to account for inter-speaker differences. 
As briefly mentioned above, adjective and item were not included in the modelling process, i.e. as potential random effects. This is something we would have liked to see.","Typicality is the predictor of interest; thus it should be part of any model trying to answer the present research question. However, we would have liked to see some sort of random effect variable for adjective and/or noun combinations, as well as the use of the continuous typicality variable.","We find the structure of the presented models to be overall suitable for answering the present research question. As mentioned before, a more sophisticated (initial) random effect structure – even if it is found that is does not improve the model and is to be removed – is preferable.","Data for which no typicality rating was available was removed. While this in itself is well-motivated in an analysis of typicality, we are unsure why the authors lost about 57 % of their data.","The authors attempted to transform their dependent variable, average F0, to achieve of distribution closer to a normal distribution. However, they did not succeed. Their attempt is well-motivated; proceeding after failure (which by no means is a lack of skill but due the nature of the data) is justified.",We do not have any additional comments.
2022-06-03 04:41:36,2022-06-03 04:43:12,IP Address,84.215.16.54,100,95,True,2022-06-03 04:43:13,R_qCkj0U0wFctA7cd,,,,,58.3383,8.5959,anonymous,EN,linckia_nattereri,eosipterus_pytyopsittacus,10,10,10,deeply flawed and unpublishable.,"The main problem of the proposed analysis is that it is out of the scope of the current project. The authors did not look at typicality but only at whether the noun, adjective or both were in focus (and worked only with medium typical utterances). This cannot contribute to answering the research question of the project, which was “Do speakers phonetically modulate utterances to signal atypical word combinations?”, as stated on the website.
Additionally, the report is not always clear. Some abbreviations are not explained (e.g., “ML”, p. 1), some procedures are only rapidly mentioned but not described or justified (e.g., extracting procedures for the k-means analysis), and some variables are not adequately described (acoustic measures included in the model).
Importantly, this analysis lacks reproducibility. Textgrids are not provided, even though a large amount of at least partially manual work was done to annotate them according to the PoLaR conventions. The whole PoLAR analysis is not reproducible at all. R scripts are not provided either, and the specifications of the random forests models are not provided.","The authors used a random forests classification model. The choice of the analysis is not justified, but seems appropriate with respect to what the authors are investigating.","The first step of the analysis was a k-means clustering analysis on three acoustic measures based on PoLaR labels: “the length of time coded as accent-related”, “the average scaled f0 height”, and “a measure taking into account the slopes of the f0 movement during the pitch accent”. 

The authors used the results of the k-means clustering as predictors in a random forest classification model trying to predict whether the noun, adjective or both were informationally focused. They also added some acoustic variables as additional predictors.

Running the k-means analysis first to use the results as predictors in the random forest classification analysis is standard and makes sense. However, the choice of the measures used as input to the k-means structuring is not really justified or explained. The authors just mentioned that they used PoLaR-BEAR to guide their analysis of the PoLaR labels.","The main problem with the analysis is that the dependent variable chosen does not enable the authors to address the question of typicality, as they examine whether the noun, adjective or both were focused (and, in the second model, whether there is a difference between adjective focus and other types of focus, as noun and adjective + noun seem to be marked similarly). Typicality is not included in the models.

The predictors are the results of the K-means analysis, in the form of the accent type for each word – suggesting that for each utterance, only one of the three variables (“AdjAccentTpe”, “NAccentType”, and “AdjNAccented”) contains a value, the other two being NAs (as each utterance has either the Adj, the N or both in focus). => is that a pb? Feels weird
Some additional acoustic measures were also included in the original model. However, their exact nature is not clear. It is written p2 that these are “acoustic variables of the utterance”, but authors report in the questionnaire that they “focused [their] analysis on the region of each utterance containing the determiner, adjective, and noun in the second half”. We therefore don’t know whether the f0 measures included are for the whole utterance, the NP in the second half of the utterance, or the focused word. These variables are however not kept in the final, simplified model.
In the end, the model seems to predict whether the adjective is in focus or not based on whether there is an accent on the Noun or not – the authors note than the most important factors are “about simple presence or absence of an accent”, with the specific type of accent as identified in the k-means analysis only “playing a much minor role”. The analysis does not seem very informative in the end and, again, does not address the question of typicality.","The structure seems appropriate but a lot of information is missing (package used, number of trees, number of predictors used in the random forests model). The formula for the k-means clustering analysis is missing.","The authors used only the data in the “medium typicality” condition. While their reason for doing so (only condition where there was an equal number of observations across focus types) makes sense regarding the research questions they chose to investigate, it is problematic as the common research question for the MSA project was to investigate how speakers phonetically change their utterance to reflect the typicality of the association between noun and adjective. The chosen subsets of the data cannot therefore contribute to answering the research question.","No transformations were performed, although the authors note that PoLaR annotations transform f0 values to scaled or normed pitch levels. ",
2022-06-03 10:15:25,2022-06-03 11:00:38,IP Address,134.69.55.168,100,2713,True,2022-06-03 11:00:39,R_1dA07CqsC0OqXNG,,,,,34.1325,-118.2076,anonymous,EN,hoplostethus_macrosteus,epinephelus_aztecus,60,70,80,publishable with minor revision.,"Overall, this write-up was well-written, well-explained, and left only a few questions unanswered. In terms of the phonetic analysis, we were left wondering precisely what acoustic and auditory cues the authors used to segment the determiner+adjective combination (i.e. waveform? spectrogram? periodicity? differences in intensity? formant information?). Though the textgrids were provided, including this information in the write-up improves the likelihood of faithful replicability.","The motivation for using the path models was well motivated and well-explained. ","Though the path models seem well motivated, we were unsure as to whether the DVs (duration, F0 mean, etc.) were standardized. It appeared so since the authors were comparing effect sizes/coefficients, but we were not totally clear on this. 
Overall (and we may be a bit biased due to our own usage of linear mixed-effects models), it seems that 5 separate linear mixed-effects models (that the authors included in addition) might have sufficed. ","Additionally, we expected to see a few other independent variables included in the analysis such as vowel (or color) and perhaps a variable representing a possible order effect. 
","We are not experts in path models, so to our knowledge, this seems fine. Again, it was well-motivated. ","The researchers excluded any errors in the ""notes"" tier of the textgrids. However, they do not mention exclusions based on hesitations or other types of annotations in the notes tier. No mention was made of any other exclusions, though we might wonder if there were any outliers or undefined pitch regions. We also observed many instances of creaky voice in the data, but no mention was made of this in this writeup. 
","No transformations were made for F0. Though later the authors fit individual-level models (and ran linear mixed-effects regression with participant as a random effect) to account for individual-level differences in vocal tract size, we might have expected to see these values normalized (via z-scores or semitones) for broader comparison.","On page 3, the authors focus in on the effects of pitch, saying that it ""stands out the most"", but we were not clear as to why. Its p-values were not the closest to 0.05, its effect sizes were not the largest, so we were left a bit confused. We appreciate the authors' justification of discussing nonsignificant results (since the model was well-fit), but we might have expected to see those described as ""trends""."
2022-06-06 09:43:55,2022-06-06 10:30:02,IP Address,141.201.219.162,100,2766,True,2022-06-06 10:30:03,R_3RkA1xsxKh5jIAe,,,,,47.8008,13.0443,anonymous,EN,anomalocaris_ornata,naso_cassivellaunos,81,90,85,publishable with minor revision.,"Neither of us is very familiar with Bayesian methodologies, from what we do know, the Bayesian analysis seems to have been carried out correctly.",A Bayesian approach seems suitable for the question type.,Variables used in the analysis are clearly defined and are justified.,See above,What the authors have done make sense. They explain their choices well.,"The reasoning behind only using a subset of the data is explained well and makes sense from an experimental point of view. However, with this particular data set, this means working with far fewer data points. The result of this is also the eventual loss of the medium category.

A potential issue which is not addressed is the production errors in the audio. There are 60+ such production errors that were not marked as such in the original files, this has very possible repercussions for the segmentation and mass analysis if these errors were indeed included.",The normalisation makes sense and is appropriate here.,
2022-06-06 09:54:17,2022-06-06 11:03:59,IP Address,73.14.34.31,100,4181,True,2022-06-06 11:04:00,R_3efpvnwDlM6FnbE,,,,,40.0373,-105.279,anonymous,EN,clione_dorsalis,pseudopleuronectes_assasi,80,71,76,publishable with minor revision.,"The phonetic analyses seemed to examine relevant variables for exploring a hypothesis about prosodic manipulation. 

We're not sure why the AF-NF comparison is relevant to the hypotheses and would have liked more explanation about the inclusion of this analysis. 

The authors don't clearly specify the models used (e.g., lmer and ANOVA vs Chi-squared).","The type of statistical analysis appears appropriate to answer the research question using the variables specified. The approach of comparison between a null model and a model with a single fixed effect seems non-standard; we're not sure how to interpret a linear mixed-effects model with no fixed effect. ","The variables are appropriate to answer the research question using prosodic hypotheses. We're unsure about the approach of comparing a null model to a model with one fixed effect. 
","It's unclear why the NF-AF condition comparison was relevant to the research question. The rest of the variables included the other models in the analysis are appropriate. 
 ","We're unsure about the approach of comparing a null model to a model with one fixed effect. The random intercepts included in the linear mixed-effects models are fine. ","It's unclear why the NF-AF condition comparison was relevant to the research question. 
The analysis of NF-only data for typicality is appropriate to answer the research question. ","The data transformation from Hertz to semi-tones was well-motivated. Given the variety of vowels, using the Euclidean distance measure was a good way to consider the vowel space as a whole.",
2022-06-06 13:20:31,2022-06-06 13:39:11,IP Address,95.90.194.21,100,1120,True,2022-06-06 13:39:12,R_UhzP1LCgqJySlbP,,,,,48.1663,11.5683,anonymous,EN,gnathosaurus_canadensis,psittacula_scabriculus,90,80,86,publishable with minor revision.,"The analyses are done very similarly to what I would have done, the variables chosen are well justified, the reporting of the results is a bit confusing though (this might be just the wording though, not necessarily the method).","I have not personally worked with the method, but based on my research, the method is suitable for an analysis of the type done in the report.","The choices were made based on previous literature, so that seems fine","average vowel duration is technically a good variable, however, I am not sure how well it works as an insular variable, especially because all the targets have different vowels in different phonetic contexts.",seems fine,"quite a number of trials were excluded based on either production errors or because the vowel was not articulated. These are good criteria, however, the report did not specify which trials were excluded and if this lead to unbalanced numbers for e.g., the different typicality conditions or the represented vowels.",If feel like the fact that the targets had different vowels in different contexts should have been addressed somewhere.,
2022-06-07 06:51:27,2022-06-07 07:11:23,IP Address,134.2.129.196,100,1196,True,2022-06-07 07:11:24,R_22m1wg0dbTzWhLQ,,,,,48.767,9.1827,anonymous,EN,aracana_bitatawa,paralichthys_undulatus,80,20,50,deeply flawed and unpublishable.,"The analysis does not present any motivation, expectations or hypothesis. 
It is not explained, why only the noun focus condition was analyzed.

The dependent variable ""RangeST"" was not motivated (it might be naively understandable, nevertheless, I would have expected a broader analysis in terms of mean F0).

Also, given that there are systematic differences between speakers, absolute changes may not be representative. Instead, I would have recommended changes in standard deviations. I at least would have expected that speaker differences in F0 would be discussed. 

No discussion was provided how the automatic extraction of F0 was checked or how gender differences were accounted for (the algorithm provided by Praat yields sometimes octave errors when parameters are set incorrectly).

In the light of the model structure, the analyst seems to assume that there are only main effects of the predictors. However, it is possible that typicallity may attack only either the adjective or the noun, or that the effects may be different on these both classes. This type of effect should have been tested by an interaction between word class and typicality (or at least reported that it had been tested). 

In the manuscript, the reader is pointed to the results in the tables and the figures. But no in deepth discussion is provided. 

No discussion of distributions is provided. In Figure 1, one can infer that F0 is not normally distributed. I would have liked to see a density plot for both classes (and typicalities). 

Also, Figure 2 is not discussed. While the results of the statistical analysis are summarized, the mean values in Table 3 are not discussed at all (simply presented on the platter for the reader to analyze them). 

No variables were tested to control for typical changes of F0 such as word duration phonetic context, speaking rate, etc.). 



","The statistical analysis is OK under the assumption that the distribution of the dependent variable is normal (which it seems not to be). ","The analyst chose the most obvious predictors: word class and typicality, in addition to standard random effects. 
The dependent variable was not motivated. 
The structure of the model is flawed or at least not properly discussed, as I have outlined above. ","The predictors are suitable for the analysis. 
The dependent variable seems to be not normally distributed, which may introduce problems in the evaluation of the model. ",The structure of the model is suitable to test the underlying question.,The analyst has not discussed the exclusion of the other conditions provided by the project.,"No transformations of the data have been performed. ","In my opinion, the analyst has done the bare minimum to analyze the data, both in terms of the analysis as well as reportage. "
2022-06-07 08:19:47,2022-06-07 09:17:15,IP Address,86.142.234.96,100,3447,True,2022-06-07 09:17:16,R_pi9u8euEeVmcKL7,,,,,53.9573,-1.0837,anonymous,EN,pervagor_adscensionis,trachurus_riukiuensis,82,81,80,publishable with minor revision.,"Overall we thought this was a very solid analysis, but we thought there were potentially issues with Praat settings for f0 analysis (perhaps wider range needed for female speakers) and we questioned the removal of outliers.",Entirely appropriate,Entirely appropriate,Entirely appropriate,Entirely appropriate,The process involved removing outliers. The decision to remove outliers wasn't justified and we think that this issue is more to do with measurement methods rather than statistical outliers (i.e. an issue with data extraction).,"Perhaps the f0 could have been converted to a perceptual scale, but we thought the use of raw Hz was fine",
2022-06-07 14:23:40,2022-06-07 14:39:44,IP Address,186.223.211.201,100,964,True,2022-06-07 14:39:45,R_2rOOEeDpTHybHgc,,,,,-21.9065,-47.8747,anonymous,EN,swiftia_ruber,anthracoceros_coronata,66,76,70,publishable as is.,"Segmentation was carried out at the word level and the team justifies this by pointing out difficulties in segmenting at the level of individual phones. Some of these difficulties also impact the segmentation at the word level, although this issue was not addressed in the report.

Acoustic correlates were measured at the word level and that probably affected the results, given the fact that the correlates the team chose to measure, duration, pitch and intensity are known to vary from syllable to syllable in a given word as a function of the degree of stress. So, measuring the correlates at the word level turns out no to be very informative and essentially limits the chance of observing a significant effect.

Three acoustic correlates were selected as dependent variables, despite the instruction given by the organizers to report just one numerical value in the final report.","The statistical analysis is very simple and straightforward, a simple linear model having the mean typicality index as dependent variable and the acoustic correlates as dependent variables. Separate models were run for what the team called ""condition"", that is, the three types of focus conditions (focus on Noun, Adjective or broad focus). The analysis seems appropriate in itself, although, as said before, the fact that the dependent variables were measured at the word level may have compromised the chance of detecting a significant effect.","As said before, the statistical analysis seems appropriate in itself, although the fact that the dependent variables were measured at the word level may have compromised the chance of detecting a significant effect.",The fact that the dependent variables were measured at the word level may have compromised the chance of detecting a significant effect.,The statistical model and the way it was structured is essentially correct and appropriate. A more sophisticated model would not make it more likely that an effect was going to be found.,The choices are very reasonable. Only trials that were labeled as containing error in the Notes field of the TextGrids were excluded. These corresponded to a small fraction of the total of trials.,"Raw duration values were log-transformed, which is a common practice. Log-transformed duration, intensity and f0 data was transformed to z-scores prior to the statistical analysis, which is also a common and reasonable choice, given the fact that the sample contained data from different speakers of both sexes and some form of data normalization is recommended in that case.",
2022-06-07 21:10:04,2022-06-07 21:12:24,IP Address,72.65.234.148,100,140,True,2022-06-07 21:12:25,R_1jlZ1KHFnulCMRi,,,,,40.4268,-79.8935,anonymous,EN,trachurus_riukiuensis,eriphia_laterispinis,30,70,40,deeply flawed and unpublishable.,"We have major concerns with the phonetic analysis.  We appreciate that in the roadblocks question of the questionnaire the team were forthright about their lack of skill in doing the word level segmentation–that's a nice honest disclosure, and we understand this group may have been expecting going into this project to only be doing the statistics part.  Their decision to take measurements over the entire sentence is deeply problematic, and we think it makes most of the results unreliable.  While using the entire sentence might have been workable for some measures, it’s nonsensical for others.  This is particularly true for the total duration, given that the start and end points of the labelled utterance are not themselves aligned with the audio, and so the duration of the sentence includes silence on either side; moreover, the duration of this silence is not uniform (varying by a few hundred milliseconds), and so this will certainly introduce a large amount of error.  We are also very concerned with the fact that no observations were excluded, even those that were specifically marked in the comments tier as having been produced with errors; in some cases, the errors were repetitions or even pauses of upwards of 100ms, and so again should not have been included.

The use of average intensity is inappropriate, as there is no evidence that mic-to-mouth distance was held constant.  From the low quality of many of the recordings, with echoes in them, we strongly suspect that head-mounted mics were not used.  Therefore intensity is useless unless normed within each utterance, which this analysis didn't do.

Finally, with respect to average F0, this is the only measure that could in principle work, though it’s so imprecise as to be uninformative.  By taking the average over the whole utterance, there may well be unknown confounds, or it may average away effects that are realised at a particular point of the utterance.  Additionally, we found creaky voice to be particularly prevalent throughout some speakers' utterances, and prevalent at onset of vowel-initial words for many speakers.  Since the pitch tracker rarely does well with creak, and often gives an extremely low value for f0 during creak (pitch halving), or no value at all, unanalyzed creak is likely to throw off the average f0 dependent variable.  We noticed that, to their credit, the authors use a maximum pitch of 400 Hz (therefore not the default of 500 Hz), thereby eliminating some of the spurious pitch measures taken during voiceless aspiration noise or frication.  But it is therefore puzzling that there is no discussion of the effect that creak might have on the results, since creak is very prominent (both audible and visually evident in the spectrograms and waveforms).

Finally, removing the middle typicality is an odd choice, and makes it difficult to interpret the results (to the extent that they are interpretable): for example, suppose medium typicality utterances had a higher average f0 than both the atypical and typical.  What would we make of that?  Perhaps the authors have a hypothesis that adequately addresses this possibility, but if so, it’s not made sufficiently clear in the report.
","A multivariate multilevel Bayesian regression model is a good choice here.  It allows the researchers to explore the influence of typicality on all 3 dependent variables without running 3 separate models. This approach also allows the researcher to take into account any potential correlation between the 3 outcomes. The actual Bayesian analysis is solid, we believe. The R code is thorough, well documented, and the models seem correctly specified. In a vacuum, the analysis would score a 100. Our score of 70 reflects the problems with the data itself and the authors' failure to consider these problems as they relate to the dependent variable. Here are a few of our concerns:

The authors did all of their acoustic analysis within R with the help of the ‘PraatR’ package (and others). This itself is fine, but it assumes that the files are ready for analysis. As we note above in Q9, this was not the case. Utterances had errors and hesitations, along with NA values from Praat and values that reflected creaky voice. A back-of-the-envelope calculation of our own data shows that the adjective duration was, on average, 100 ms longer in trials marked as ‘error’ compared to the unmarked trials. We found that participant JW_3 was especially problematic and removed them entirely from our own analysis. 

Related to the NA values, the authors note in their code in line 179 that NAs were replaced by the preceding value (time gets normalized so as to fix this). Although we see no problem with this approach, per se, NAs via Praat should always be further inspected. Were the NAs due to a pitch tracker error? Were they due to problematic settings? The authors appear to simply accept that NAs are inevitable. It is possible that the authors did not listen or look at the utterances in Praat, and only accessed the files through R. We see this as bad practice and strongly advise the authors to always first examine the speech in Praat before analyzing the speech in R. (It is possible that the authors did this, but given the failure to note errors or further explore the nature of the NA values, we believe this was not the case.)

We recognize that the creators of the “Many Speech Analyses” project are partly to blame here as we suspect this group, “eriphia_laterispinis,” believed little to no phonetics knowledge was necessary to take part in this project, and that the data were ready for analysis. (The group has also acknowledged this as much.)","The choice of weakly informative priors seems appropriate here given that we do not know which direction any effect of typicality might go.
","As discussed above, the dependent variables are highly problematic: the duration measure is confounded by the variable silence on either end of the utterance; intensity is not normalized within the utterance; and the f0 measure does not take creak into account. No errors or hesitations were removed from the data and NA values were replaced by the preceding value without proper consideration as to why they appear.
","The statistical model seems fine.
","The medium typicality condition was excluded in order to focus on the 2 levels of typicality that would most likely show a difference: typical vs. atypical.  Otherwise, no subsets of data were excluded.  Given that some of the trials marked as errors and hesitations, this presents a problem for the current analysis, especially for the duration measure, since sentences with hesitations would necessarily be longer than those without. It is possible that trials with hesitations are more likely to be of one type of typicality, although we have not investigated this.
","All three measures were standardized at the individual level, which seems prudent, but the intensity measure does not take into account the possibility of head-to-mic placement, and so ought to be normalized within the utterance.  For example, since all utterances used the same frame sentence (""Und jetzt sollst Du…""), one could normalize peak intensity during the adjective relative to peak intensity of ""jetzt"" or some other stressed syllable of the frame sentence.  This would fall beyond the authors'  acknowledged plans for omitting hand-labeling.
",
2022-06-08 02:38:33,2022-06-08 02:41:58,IP Address,83.213.185.179,100,204,True,2022-06-08 02:41:58,R_3nixFZJum0VUUI4,,,,,42.8561,-2.6946,anonymous,EN,pseudodax_euryzona,lycodes_bradfieldi,85,75,80,publishable with minor revision.,"The phonetic analysis is really promising. Yet, there could be some improvements, such as restricting the acoustic analysis to the relevant part, i.e. [(preposition + article +) adjective + noun (+ verb)], instead of taking the whole utterance including the carrier phrase. Focusing on the sequence of interest could improve the results, especially given that, apparently, the authors analyze mean AM and Mi. Besides, the analysis could have been explained more thoroughly. At some points it was not clear how the authors carried out the analysis and we had to turn to the references provided in the report.

The statistical analysis seems right, but we could not further evaluate it, since there was no easy way for us to reproduce it with the provided instructions (note also that we could not find a csv with the final data).","A repeated measures ANOVA analysis might be correct, given the categorical nature of the independent variables (typicality & and frequency band). Yet, the rationale for the analysis type of decision is not provided.",The rationale for selecting variables is explained in the questionnaire and seems right.,We deem the included variables appropriate.,"As far as we can tell, we have no major objections. The only caveat is that the process is not totally transparent and we could not reproduce it ourselves.",There is no mention of exclusions on the report and the criteria to include all the data given in the questionnaire is dubious: 1. Number of trials is already low. This should not be a criterion to accept bad utterances 2. Utterances are instructions and thus there is no clear exclusion criteria. This might be problematic to some extent. Many of the utterances had already been labeled with error or hesitation break and our team found some more errors and hesitation breaks and this should already constitute an exclusion criterion. It might be even more problematic if the errors happened in the atypical or medium typicality values (we did not check or test that).,"According to the questionnaire (Q7), there were no transformations. This does not seem correct. Mi seems to be a kind of transformation of AM, including a min-max normalization of the pre-final result.","The statistical analysis felt a bit obscure. There was no additional data or measurement file. Given that the whole analysis but the final ANOVAs was carried out on MATLAB proprietary software and that we could not find any csv file with the results of the acoustical analysis, we were prevented from actually evaluating the process and results ourselves. Replicability is compromised.

They refer to a /tipicalityTrials/ folder, which was empty."
2022-06-08 09:30:58,2022-06-08 09:33:31,IP Address,151.224.144.247,100,152,True,2022-06-08 09:33:31,R_3kCgbPprQDhLEbN,,,,,51.8842,-0.4208,anonymous,EN,stygobromus_tyraica,polymetme_brevirostrum,70,80,5,deeply flawed and unpublishable.,"This analysis is extremely difficult to rate. On the one hand, the choice to investigate F0 range is well argued, the phonetic analysis itself is sound, and the statistical treatment is careful, considered, and appropriate. On the other hand, the actual analysis provided uses duration (and not F0 range) as a dependent variable, and no results (other than no effect) are given. Thus, the analysis that is provided does not match the report that is given, and there is no effect size or CI given for the analysis that was carried out (only that there is no significant effect within the ROPE). Based on these discrepancies alone, the analysis that is given, as it currently stands, is unpublishable.","We consider the use of Bayesian mixed effects regression and 89% ROPE to be appropriate.

However, the summary document polymetme_brevirostrum.txt states that the criterion used to answer the research question was “the posterior distribution and 95% credible intervals”, which is not correct:  the 89% ROPE was used as the criterion. Furthermore, there is no effect or CI values provided for the ROPE, which was supposed to be provided.","The choice to consider F0 range in order to capture previously reported prosodic marking in German is theoretically sound; however, the analysis provided does not include F0 range, but only duration. Model selection using LOO cross-validation and ELPD comparison is appropriate.","The predictor variables are appropriate. The inclusion of a “FOOD vs. NONFOOD” variable is certainly interesting and seems to be argued well, but this effectively reduplicates (or even overrides) the typicality rating that is already provided; that being the case, we are not sure the effect that this may have on the final result. The suitability of the response variable cannot be evaluated, since the DV included in the analysis provide (duration) is not the same as the DV described in the report (F0 range).","The structure of the statistical model is sound, but the script could be annotated much more clearly to understand which model was retained in the end.",We consider the choice to observations with comments in “notes” to be appropriate.,N/A,"We find that there is a severe lack of clarity in both the R script provided and in the details of the results. Because of this lack of clarity, combined with the fact that the reported variable does not match the variable used in the script, we find that the analysis is nearly impossible to review properly."
2022-06-08 10:08:14,2022-06-08 10:31:09,IP Address,67.1.130.215,100,1374,True,2022-06-08 10:31:10,R_1lmIzLlPxqYCuGg,,,,,32.2699,-110.9853,anonymous,EN,dermatolepis_aculeatus,haematopus_fossor,93,94,93,publishable with major revision.,Good with some points needed to be clarified.,Good,Good,Good,Good,Good,"The vowel centralization part should be excluded! There is no point of having this part in the analysis. ","'- The plots plots should be commented (see, for instance, Gerke, 2020, G Reporting Standards for a Bland–Altman Agreement Analysis: A Review of Methodological Reviews.
- Additionally, both adjective duration and adjective vowel duration showed an effect of typicality, but what were the adjectives again? Is there any reason this may be due to the number of syllables in the word or some other factor, such as vowel quality? Low vowels tend to have longer durations than high vowels simply because it takes time to open the mouth farther.
- In regards to vowel intensity, in general  it doesn't vary much and is more dependent on phrase position, as intensity drops throughout an utterance. Sharf (1966) shows that intensity doesn't correlate with vowel opening, so this also doesn't go with their centralization argument either.
- It is really hard to tell anything from the plot on page 3, plus these are obviously non-normalized measurements and so it's hard to really see some vowel spaces, like that of participant TB.
"
2022-06-08 13:03:15,2022-06-08 13:10:34,IP Address,173.76.251.40,100,438,True,2022-06-08 13:10:35,R_3erVC5FHoQwt7uq,,,,,42.1246,-71.1149,anonymous,EN,trachyphyllia_lappa,pervagor_adscensionis,31,37,29,publishable with major revision.,"The authors firstly acknowledge the non-normality of the residuals and their measures but do not take any measures to correct for this. Secondly, the entire data is analyzed for typicality, when typicality was only manipulated in the NF condition, so it is unclear how the analyses reflect these differences.",We are not familiar with the type of analyses used in this report (the distance measures) so do not have comments on the technical soundness of the analyses. The lmer analyses are not appropriate for the measures chosen because of the non-normality of residuals.,We are not familiar with MFCCs at all so cannot comment on this - but it seems that calculating for the full dataset when the typicality manipulation applied only to NF condition is weird.,NA,NA,All the data was used but no indication of how the absence of typicality scores was handled.,,We did not fully follow this team's analysis as it is not common practice in our field.
2022-06-08 13:21:45,2022-06-08 13:32:02,IP Address,129.108.202.181,100,617,True,2022-06-08 13:32:02,R_3MF23KlasiPXDta,,,,,31.8378,-106.538,anonymous,EN,paralichthys_undulatus,petauroides_fistulator,70,80,75,publishable with major revision.,"They chose a relevant acoustic measures (f0 contour – measured at 10msec intervals) of just the noun. They labelled and measured them accurately and used a relevant statistical method (GAMM). A lot more detail could be given about the phonetic analysis, including maybe showing some example contours, and also motivating why they only examined the noun and not the adjective. It seems that they ""lined up"" the f0 measurements for each token but they did not explain this in much detail. ",They used general additive mixed models (GAMM) which seems reliable for this data.,"The dependent variable was f0 converted to semitones, and the independent variable was typicality. They also included a lot of other variables as random smooth terms.","The main relevant variable was typicality, which is what they examined as the dependent variable. The results that Speaker, etc, had a significant effect are also interesting but these are not described in detail. ","They did not give the formula, but having Typicality as the IV makes sense. ",They did not mention excluding data except where they could not get an f0 measurement. It is unclear if they included the tokens marked as errors or hesitations.,"F0 was transformed to semitones, which is a good idea in order to be able to pol speakers.","More detail on the motivations, analysis (particularly f0 measurements) and results (some descriptive figures) would have been useful. But the stud seems sound and the results are interesting! "
2022-06-08 13:02:30,2022-06-08 13:32:55,IP Address,71.104.44.228,100,1825,True,2022-06-08 13:32:55,R_2rvjsrQhZCMahlB,,,,,40.4992,-74.4996,anonymous,EN,lasionycteris_altavela,anomalocaris_ornata,100,63,81,publishable with major revision.,"I think the authors did a great job. There were a few issues I saw: 

1. No indication of effect size. 
2.  I have issues with their F0 analysis. Specifically,  introduction of new variables after looking at the data (low and high peak; dichomtizing). Also, the authors kind of gave trying to normalize the data. I am surprised they did not try  a log transformation would work.
","The choice of analysis seems appropriate. ","They ran a maximal model with backward selection to pick best model. If the maximal ran I am not sure why they engaged in this selection process.  This backward selection process is acceptable. ","No particular justification was given for the dependent measures, but intensity, vowel duration, and F0 are all viable correlates of contrastive focus and stress.
Independent variables for the analysis were selected via model fit (AIC) obtained from ANOVAs. A new variable was introduced by the team to separate speakers into voice-type groups based on overall F0. This was created post-hoc to deal with a bimodal distribution in F0.
",The structure was adequate,"F0 measures with values more than 1.5 times the interquartile range were removed (1.75% of total F0 tokens). This was done to filter any errors in the data transformation process. Given all the automated scripts in the data transformation pipeline were hand-checked, this seems very cautious but not inappropriate. The researchers did not report exclusion criteria for the intensity or duration measurements.","Transformations seemed appropiate. They squared the intensity measure due to non-normality.  

",
2022-06-08 21:30:06,2022-06-08 21:33:09,IP Address,132.181.235.171,100,182,True,2022-06-08 21:33:09,R_22FvzE1btyVNLpM,,,,,-43.5379,172.6151,anonymous,EN,alosa_atun,hoplostethus_macrosteus,85,50,60,deeply flawed and unpublishable.,"We were impressed with the manual coding of the segment and they did a fantastic job articulating their phonetic analysis. Furthermore, we believe the validity of the coding would be much higher as they were segmented by hand. However, removing the pitch and formant information wasn't justified just because gender information was not available as gender isn't a perfect correlate of vocal tract length. The statistical analysis was adequate with a few methodological quirks. Furthermore, the analysis is not reproducible even with the code provided as there were files missing for the script to run..",We believe the the statistical model selection was suitable for the analysis.,It would've been good to include Local measures of speech rate for the duration variable.,We noted that f0 and formants of the vowels were excluded from the outset. We don't think reasoning to exclude these variables were justified.,"Selected model for duration includes interaction terms without main effects included.
not clear on criteria of establishing significance (pvalues of what?)
post hoc analyses are conducted on interaction term but disregards main effects.
should have included local controls for speech rate / amplitude.","They only included observations from the noun-focussed condition as this was the only balanced dataset. They also removed observations 2 SD (which is different from the usual 2.5 SD) for the whole dataset, but not per speaker per adjective.",The authors centred and scaled the duration and intensity variables per speaker. We believe this is suitable.,"They didn't consider co-articulatory effects of the following word, though the following effect wouldn've been less apparent. There wasn't enough information about the modelling for us to evaluate the statistical model. There were no fixed effects listed. There were no controls for duration (i.e., speech rate) and amplitude. However, they did clearly outline their methods. It is hard for us to evaluate how effective their statistical model as they didn't test for interactions."
2022-06-05 08:01:06,2022-06-09 06:06:32,IP Address,147.188.245.188,100,338725,True,2022-06-09 06:06:33,R_3kdLdBbMGI6nasb,,,,,52.4425,-1.9442,anonymous,EN,psittacula_scabriculus,chelonia_brummeri,79,77,82,publishable with minor revision.,"This team project chose proper dependent variables and statistics models to answer the research questions. They considered a few phonetic features, including duration, intensity, and f0. The statistic models are advanced, not only considering dependence in the data but also using the Bayesian method.","The use of the Bayesian linear mixed-effects model is great and proper to answer the research questions. Having by-participants and by-items random effects, the dependence problem in the data can be solved.  Bayesian methods make the results less dependent on p-values and give more confidence in the results.","In the operationalization section, they mentioned five dimensions that possibly typicality could influence. What they also could do is give more supporting literature and background information on why they looked at the five dimensions.","They considered three fixed effects: typicality, syllable structure of the stressed syllable in the adjective, trial number, and one interaction between trial and typicality. They did not mention the rationale for choosing trial and syllable structure as covariates.  Also, there is no supporting literature explaining why it is expected to have interaction between trial and typicality.","They kept the main predictor in all of the models and used the proper way of coding the predictor and the models had random effects and mixed effects. However, they did not mention what the maximum mixed model was, and how they reached the best model. ","They only excluded trials indicating errors, which is proper to do so. Usually, trials with errors involve more cognitive cost and different cognitive routes. As long as being transparent with excluding data, it is acceptable. ",They did not transform dependent and independent variables. What they could do is to check the regression diagnostics even for the Bayesian by plots and check whether they need to transform data. They could inverse or log duration.,"They have done a great job! It would be great to see that they explain why they chose the informative priors. "
2022-06-09 06:24:21,2022-06-09 08:02:48,IP Address,81.111.13.164,100,5906,True,2022-06-09 08:02:49,R_2azxA4Fw2H2le5g,,,,,55.9335,-3.254,anonymous,EN,trigonias_lachneri,arapaima_modularis,85,85,85,publishable with minor revision.,"Analysis is absolutely fine, but a linear mixed model would have allowed to account for random effects (esp speaker)","Appropriate, see above.","A repeated measures ANOVA with typicality as a categorical variable with three levels and max pitch of the adjective in the NF condition is a relatively simple but appropriate approach. ","The study considers F0 only, which is probably a limitation as accent is a multivariate phenomenon, but toherwise this is perfectly adequate.",See above,"Entirely appropriate to only look at NF and adjective, as food items were not balanced for typicality across the NF condition, and neither adjectives nor food items were balanced for typicality in the other focus conditions.balanced ",no transformations.,
2022-06-08 08:05:28,2022-06-09 09:18:38,IP Address,139.124.208.24,100,90790,True,2022-06-09 09:18:39,R_SMLnwgBwpirAL97,,,,,43.2951,5.3861,anonymous,EN,eriphia_laterispinis,dermatolepis_aculeatus,65,65,65,publishable with minor revision.,"First of all, the manual correction of the noun and adjective boundaries is a remarkable effort that should be noticed. However, some methodological choices were not sufficiently supported by arguments, which limits the understanding of the analyses. These points are discussed in the following sections.","Mixed-effects linear models are a good tool to limit the influence of extreme observations and to take into account inter-individual or inter-item variability. However, it remains unclear whether the assumptions of these models were met (e.g. ,normality of residuals distribution, homoscedasticity)  and the script available on GitHub does not help in this regard. Also, regarding the choice of the fixed effects: could have other predictors than typicality had an influence on the pitch, such as the sex of the participants? ","As mentioned above, the choice of variables is not sufficiently justified. For example, we can ask whether other factors than typicality could have been added as predictors and thus improved the model’s fit: word length, sex of participants, order of items (in co-variable for example), etc. In any case, it would have been preferable to test these predictors, in a forward stepwise model selection procedure (for example) to select fixed and random effects of the model according the Akaike criterion (Akaike, 1973), and using the lmerTest package (Kuznetsova et al., 2017) for model comparison. Therefore, fixed effects, random effects, and random slopes could be only included if they significantly improved the model’s fit. The report gives the impression that none of these prerequisites have been implemented and this is why it seems to lack content and precision. ","Regarding the choice of variables, while the authors describe having detected delay and state that this delay can be an indicator of the typicality effect, one wonders whether this measure could not have been tested in the analyses.","To complete what we said about the choice of model, a word about the random structures. Indeed, all the random structures estimated here are ""intercept-only"" (1|speaker) and (1|noun). This could be problematic; indeed it is one of the points of agreement between the series of papers by Barr (2013; keep it maximal) and Bates (2015; parsimonious models) on how to specify random structure. The argument is that this type of model is a source of both false positives and false negatives (depending on the covariance matrix of the different predictors and VDs).","This ties in with our various comments about the lack of justification. Indeed, the authors seem to have detected and excluded some errors but decide nevertheless to keep the detected errors in the TextGrid. While these choices may be quite justifiable, it would be relevant to document why certain tests have been excluded or kept.","We have no comment to make on this point. ","We have no further comment. "
2022-06-09 10:27:29,2022-06-09 10:47:39,IP Address,64.130.67.79,100,1209,True,2022-06-09 10:47:40,R_w19qIqmobEQoEHT,,,,,33.5119,-101.9316,anonymous,EN,anthracoceros_coronata,trigonias_lachneri,90,90,90,publishable with minor revision.,"The only thing the analysis did not contain was a discussion of model selection—a fully specified model is used, but it's not clear that random slopes for color and speaker are justified.  This may have been analyzed, though, and just not reported.",Linear Mixed Model is an appropriate type of analysis for this data.,"I have to admit that I'm not very familiar with SPI, but the reasoning presented in the results document seems to justify its use.","Again, the variables used seem well-justified.","The only element that might be considered missing is a discussion of model selection, namely whether the speaker and color random slopes are justified in the model.  Why slopes and not intercepts?  If model selection was done, it would be great to include that in the text.","The only data that were excluded were items marked as errors or having other comments in the TextGrid files.  It's possible that there are a number of outliers that could have been excluded, so some discussion of these would be nice to include.",SPI was log-transformed because untransformed SPI was not normally distributed.  This is a reasonable choice.,
2022-06-09 11:28:29,2022-06-09 11:36:12,IP Address,128.187.112.17,100,463,True,2022-06-09 11:36:12,R_1Kl2xqA2AciTEHA,,,,,40.2584,-111.6591,anonymous,EN,trapezia_cantonensis,linckia_nattereri,100,100,100,publishable as is.,"This was an extremely thorough analysis, with detailed documentation of the many acoustic measures and statistical tests used. ","PCA was a good choice for the many variables they extracted. I'm not familiar with Bayesian models and how they work for many variables, but it seems to have been alright. ","Variable selection was good. They included several variables for formants, prosody, F0, and voice quality. They cite many sources for how these acoustic measures were extracted. The statistical model itself appeared to be straightforward: put everything in and see what happens. For an exploratory analysis like this, it seems good enough to me.","This team chose many variables representing a variety of cues in the acoustic signal and spanning different aspects of language (formants, prosody, voice quality, etc). At explaining them with the brief justification in their hypothesis paragraph. ","Again, for an exploratory process like this, dumping them all in and seeing what comes out at the end seems fine. ","It appears there were no exclusions, not even the ones marked by the lead researchers. Perhaps this could have been addressed in the write-up.","There did not appear to be any transformations, as far as I could tell. Some things could have been transformed, such as log-transforming formants. I'm not familiar with all the variables they used in this study, so I'm not sure what the distributions typically are.","This was extremely thorough and I enjoyed reading it. I'd like to refer back to this (including the scripts and supplementary materials) in case I need to do a similar analysis or use those acoustic measures. "
2022-06-09 15:03:52,2022-06-09 15:14:59,IP Address,2.98.46.35,100,666,True,2022-06-09 15:14:59,R_2xQNx9JAa7o6NVx,,,,,53.5039,-2.1959,anonymous,EN,naso_cassivellaunos,cromileptes_saxatilis,75,95,89,publishable with minor revision.,"We find this report very easy to follow, very transparent, and well-motivated! We appreciate the clarity, the motivation behind the choice of the phonetic analyses, the statistical analysis, and the sobriety in the interpretation of the findings. Team cromileptes_saxat are asking a clear and relevant question with a fitting measurement and sound procedures. However, the approach might be too minimalistic, since it leaves some other variables of potential interest (i.e. beyond adjective duration) unexplored. Also, conclusions would be strengthened by further consideration of non-linguistic effects (e.g.. to rule out learning or fatigue effects) and/or the cause of the divergence issue in the modelling process. Therefore, we recommend ‘minor revisions’, as the analysis is not quite perfect.  
","The authors performed a Bayesian mixed-effects lognormal regression, which is a well-justified state of the art statistical approach. Priors and random effects structure were reasonable. For model convergence issues with random slopes over typicality by speaker, the maximal tree depth was additionally tried to be adapted, up to a value which was not necessarily useful. Additionally, using more sampling in the warmup phase might have helped to additionally deal with the divergence issues.  
","The model includes typicality (treatment coded with two levels), random intercepts by speaker and by target noun, and random intercepts and slopes over typicality by target adjective. Additional random slope over typicality by speaker was also considered to be included in the model, but rejected due to divergent transitions. We do not expect these slopes to play a meaningful role, but further exploration of the divergence error (e.g., showing the distribution of data, being selective for ‘random structure’) would have been appreciated.
A maximal random effects structure was chosen, which is considered a good practice to include as many sources of variability in the data as possible. All prior choices were reasonable and well justified.

","This analysis can be regarded as a confirmatory analysis than an exploratory analysis. As a confirmatory analysis or a small contribution in a context of a collaborative exploratory project, examining only one acoustic variable might be a reasonable thing to do. 

However, considering that the research question broadly asked the typicality effect on acoustic outputs of speech production, probably more than one dependent variable should have been taken into consideration in the first place. Further, team cromileptes_saxat did not consider structural confounds – if they did, the conclusions would have been made stronger. While all adjectives were used for both typicality conditions (i.e. balanced), the different nouns with different inherent durations were not balanced. For the ‘typical’ NPs, the average syllable count for nouns in typical NPs is 2.8; for ‘atypical’ NPs, 2.2. The difference in the NP length could affect its duration (by polysyllabic shortening, for instance). 
","We evaluate the structure of the statistical model to be highly suitable. See more detailed comments above.

","Only typical / atypical combinations for the NF condition were examined (medium excluded). Tokens from utterances with any text on the notes tier (typically ""error"") were excluded, as were tokens where there was any pause between the adjective and noun as determined by the forced aligner. The choice of subsetting data to exclude the intermediate condition makes sense both a priori (as emphasising interpretability of the findings) and a posteriori (given the null result).


One strategy to mitigate the confounding effect of the word length could be examining a subset of the experimental items, e.g., disyllabic forms only; brau.nen Wal.nuss and grü.nen Boh.nen vs. grü.nen Möh.re, gel.ben Kir.sche and ro.ten Gur.ke.

","No transformation was applied before entering the duration values into the model – however, the model was lognormal, and also the priors were defined over log duration and not duration itself. This is appropriate since duration measurements are bounded at 0 and therefore follow a skewed distribution.

","All of us really enjoyed reading this report. Please take our somewhat picky comments as a sign of our positive engagement.

"
2022-06-09 21:37:46,2022-06-09 21:41:13,IP Address,184.64.221.169,100,206,True,2022-06-09 21:41:15,R_2XmtLNaiAzS5cUI,,,,,51.0406,-114.0764,anonymous,EN,pseudopleuronectes_assasi,ceratophrys_elephantotus,20,1,9,deeply flawed and unpublishable.,"No statistical analysis was provided, only the classification of phonemes produced based on the matrices created. There was also very little information provided to evaluate the report.",No statistical analysis was provided.,No statistical analysis was provided.,No statistical analysis was provided.,No statistical analysis was provided.,Unclear what the authors left out and why.,"The authors implemented the classification based on the matrices whereby the data points were transformed into lists. It was a well-motivated choice given that they decided for this approach. ","Very little information.
No statistical analysis. 
Not a lot was given to us to be able to evaluate their analysis. "
2022-06-10 03:31:02,2022-06-10 03:35:17,IP Address,138.246.3.169,100,255,True,2022-06-10 03:35:18,R_1CKoMOAJJ65Muew,,,,,48.1417,11.5644,anonymous,EN,procambarus_maculosus,trachyphyllia_lappa,60,40,50,publishable with major revision.,"The phonetic analysis was overall good. The two main points of concern are that hypotheses regarding the effect of typicality on the acoustic measurements were missing and it was unclear why the measurements were taken for the whole words and not just e.g. the stressed vowel.
The statistical analysis had some major flaws both in the construction of the LMERs and the reporting of the results.","Linear Mixed Effect Regressions (using standard R packages) are an appropriate choice of statistical analysis for the derived acoustic data and chosen variables. Also appropriately, type II chi-square tests were conducted to assess significance, and eta squared were used for effect sizes. Given that sometimes the interaction between fixed effects in the LMER was significant, pairwise comparisons would have been interesting to compute (e.g. using emmeans).","While we do not understand the inclusion of target_colour as a fixed effect in the LMER, it was correctly tested by means of BIC whether models with or without interaction between the fixed effects provided a better fit. Otherwise, we cannot evaluate the process of choosing variables for and structuring the statistical model because the process was not described in more detail.","The acoustic variables – duration, minimum pitch, maximum pitch, pitch range – are likely to be associated with the phonetic realisation of typicality (or, rather, stress or prominence). However, none of these choices are explained in the report, and no hypotheses for directional effects of typicality on these variables are provided (but would have been necessary for a scientific report). It also remains unclear, why these measurements were taken for whole (and phonetically very diverse) words, and not just for e.g. the stressed vowels.","Overall, we think there are major flaws in how the LMERs were constructed. First, it remains completely opaque why target_colour was used as a fixed effect in the LMERs. It would have made  much more sense to include it as a random intercept or as a random slope (typicality | target_colour), if the authors think that the target_colour has some sort of random influence on the acoustic measurements – even though it is unclear what this influence would look like. Second, given that target_colour was included as a fixed effect, it is unusual that no statistical results are reported for it (even though the models sometimes find a statistical effect of target_colour on an acoustic measurement). Third, it is not very clear from the report what is meant by “phrase” which was included as a random intercept; the scripts reveal that “phrase” refers to the combination of colour and noun (but there was an error in the creation of the “phrase” categories, resulting in 17 instead of 15 categories). Anyway, there is no explanation for why this intercept was necessary. Our proposal would be to construct slightly different LMERs for nouns and adjectives:
measurement_noun ~ typicality + (typicality | speaker) + (1 | noun)
measurement_adj ~ typicality + (typicality | speaker) + (typicality | adjective)
Lastly, we have run the models with duration as dependent variable and found that some of them threw errors which were ignored in the reporting; therefore, none of the reported results (for this dependent variable – but possibly also for the others) are reliable.
In summary, we think that the report would have benefited from a conceptual explanation of the statistical model with clear statements about the expected effects.","In addition to the tokens that were flagged as erroneous by the MSA coordinators, 8 further tokens were excluded due to hesitation breaks between adjective and noun. However, it was not clear how such breaks would interfere with the analysis, i.e. why it was necessary to exclude them (and the other flagged tokens).
Trials with numbers higher than 35 were excluded because uttering the same atypical word combination for the second time might decrease phonetic effects of typicality. This is okay in principle, but it leaves only 15 trials per speaker. To justify this procedure, a pretest with a statistical comparison would have been useful to show that the acoustic parameters in the first repetition differ significantly from those in the second repetition. Following the authors' idea, this would have to be the case in particular with atypical word combinations, since the first occurrence seems more unusual to the speaker than when he/she sees it the second time. If this was not the case, both repetitions could have been included in the main analysis.
Both nouns and adjectives of the NF condition were analysed, though it remains unclear why effects of typicality should show up in adjectives when the noun is focused.","The TextGrids were manually corrected; more specifically, it seems like the word boundaries were corrected, although from the report we first thought that the phonetic segments had been corrected (i.e. the term “segments” should have been defined).
Duration was not normalised, neither for individual speech rate nor for length of word. The latter would have been especially necessary, because the target nouns consist of between two and four syllables. This length variation is not necessarily accounted for by including a by-phrase intercept in the LMER.
Pitch was not normalised for sex; the speakers’ sex could have therefore impacted the statistical analysis without having been taken into account by e.g. adding sex as a fixed effect.","From the report: “overall, atypical nouns had shorter durations than other nouns, except for nouns preceded by the colors orange and brown” – this is neither visible in Fig. 1 nor does that become apparent from the stats.
From the report: “As shown in Figure 2, this effect may indicate a slightly higher pitch range for nouns preceded by medium typical adjectives, compared to nouns preceded by atypical and typical adjectives.” – this sentence is wrong: adjectives are not divided into typicality groups; and from the plot it cannot be seen by which adjective the noun was preceded. What the authors probably meant to write was: “As shown in Fig. 2, this effect may indicate a slightly higher pitch range for medium typical as compared to atypical or typical nouns.”"
2022-06-09 22:29:08,2022-06-10 04:04:16,IP Address,141.5.2.21,100,20108,True,2022-06-10 04:04:17,R_3hcFdv2E0UbqMHJ,,,,,50.1189,8.6921,anonymous,EN,lycodes_bradfieldi,trapezia_cantonensis,95,60,70,publishable with major revision.,"The analysis of typicality effects in adjective-noun phrasal combinations focuses on vowel formant trajectories, F0 trajectories, and duration of the stressed vowels of the adjectives in the phrases. From a linguistic viewpoint, the analysis is compelling and exhaustive, and would meet publication standards with minor revision to enhance the clarity of the decision pipeline in case of ambiguities in boundary segmentation.
Similarly, the choise of the statistical approach using generalized additive mixed models (GAMM) is optimal, in that it considers the likely high correlation between the response variables (typicality levels per each type of feature extracted). However, the application of the statistical approahc and the intrpretation of the results appears not to be smooth enough, and warrants a thorough revision.
  ","The author creates three spearate GAMM models with one predictor for each model, tested against the null model obtained by removing the predictor while preserving the random effects, and looking at AIC as a way of assessing the predictive model.  
Including all the terms in one GAMM model, rather than creating three separate models, could have resulted in a better estimate of the effects as the terms of choice are likely also correlated. For example, this would allow checking the effects of typicality on F0 while accounting for differences in intensity. ","Unless we are misinterpreting the results, it seems that Figures 1,2,3 show that data  selection is only partially comparable across adjectives. For example, for BRAUNEN the non-food category is not represented, while for ORANGEN the atypical is missing. This potentially leads to glitches in the overall interpretation of the effects of typicality across adjectives.  ",See above,"One particular issue with the authors' interpretation of the statistical results is hard to understand from our viewpoint, and would require major revision. Namely, the inference that typicality is not a significant predictor of vowel formant trajectory differences, notwithstanding the fact that the model with that predictor is significant. The authors conclude that this is merely statistical noise, and hence there is no meaningful difference, but this conclusion seems unwarranted, as the authors must be bound to the fact that their model is significant, regardless of the fact that one of their assumptions, namely that the effects are ordered from atypical to typical, is not borne out.  ","See above, regarding the comparability between the results fro each adjective category.",-,
2022-05-30 07:03:39,2022-06-03 04:43:16,IP Address,84.215.16.54,40,337177,False,2022-06-10 04:43:19,R_3iQKx8XGX1S6uH9,,,,,,,anonymous,EN,linckia_nattereri,eosipterus_pytyopsittacus,80,42,23,deeply flawed and unpublishable.,,,,,,,,
2022-06-10 06:24:53,2022-06-10 06:47:06,IP Address,92.242.59.106,100,1333,True,2022-06-10 06:47:06,R_1nPxKoidfAoBJD2,,,,,55.7483,37.6171,anonymous,EN,aratinga_lugubris,pervagor_meeki,97,88,92,publishable with minor revision.,The authors conducted a proper acoustic analysis with minor inaccuracies in the statistical models.,"Linear mixed-effects models are a good choice for this type of analysis.
","Because of singular fit the authors applied different random effect structures (intercepts or slopes) for the same dependent variables for nouns and adjectives. This inconsistency doesn’t allow comparing results.

The authors predict acoustic cues’ values based on the typicality rating, but we believe that it should be the other way around: we need to find how acoustic cues affect typicality.","Raw intensity and duration of words might have distorted the results, some normalization procedure should have been performed.
Gender was not included into the statistical models.
The authors did not take into account the fact that in the experiment each stimulus was produced twice, so the observations were not independent which is a violation of regression model requirements.",Overall we think that model structures are reasonable.,"The authors excluded all ‘problematic’ tokens with background noise, hesitations, errors etc. We think that since they were looking for acoustic parameters of nouns, this approach is correct.","The authors used Montreal Forced Aligner for annotation of the sounds. Since they manually checked the results, we suppose that it was correct.
Raw acoustic data (intensity and duration) was not normalized by speaker, which makes observations hardly comparable.",
2022-06-10 06:50:39,2022-06-10 07:11:09,IP Address,77.161.90.97,100,1230,True,2022-06-10 07:11:10,R_3JxUx4p4aiv6Caz,,,,,51.4361,5.4958,anonymous,EN,neosilurus_omanensis,lasionycteris_altavela,50,75,55,publishable with major revision.,"We had some difficulties interpreting what this group has done exactly, because of the rather minimal reporting. For example, it did not become fully clear to us which segments exactly were used (we assume sentences), similarly which trials were used, and on which part of the segment the intensity was measured precisely. We also wonder why focus-conditions were not explicitly taken into account during analysis. And we missed a proper discussion of the findings. All this makes it difficult to fully appreciate the results. We do understand the choice to concentrate on intensity, and this is also properly motivated in the document. And, we do really appreciate the explicit description of which r-packages were used. The authors appear to be well-versed in the statistical analysis, hence our relatively high rating of this aspect of the analysis.  ",The use of a linear mixed effect model makes sense,"This is all done very well ",It makes sense to focus on intensity (as we note above) even though there are also other variables that could have been taken into account,This is fine,There is very little information about this,Not applicable,
2022-06-10 07:21:56,2022-06-10 07:28:49,IP Address,89.88.224.243,100,412,True,2022-06-10 07:28:49,R_20SWdxCDBhDGOWf,,,,,48.4289,0.0915,anonymous,EN,ceratophrys_elephantotus,dunkleosteus_inscriptus,70,100,90,publishable as is.,"With respect to the phonetic analyses, only duration was used. The choice was motivated by the goal of automatic analyses. Other phonetic extractions can be realized in an automated way as well.  ","Linear mixed effects models which is a fine choice. ","The variable choice is made clear throughout the paper: noun and adjective durations as a function of typicality. ","Fine. ","Fine. ","Choices are well motivated. Next to the ""error"" annotations, automatic alignments which were too short or too long were also excluded which is a good way to clean the data. ","The team rather used relative noun adjective durations in order to neutralize speech rate and the number of syllables each word contains which is a fine choice. ",
2022-06-02 07:03:14,2022-06-10 08:04:33,IP Address,5.132.95.23,100,694878,True,2022-06-10 08:04:33,R_30wNvkjHfckqjUz,,,,,51.7285,5.8849,anonymous,EN,ctenosaura_limax,clione_dorsalis,55,55,55,publishable with major revision.,"The report is a list of bullet points which did not contain sufficient information for evaluation. The scripts were not included in the osf directory. The choice of analysis points seem to be random without sufficient justification. ",The authors used lmer models which could be a plausible way of analysis.,"The authors used lmer models without explaining how variables were chosen and how the reported models were selected. ","The variables included are fine. However, no interaction was included. It is unclear whether the reported models were reduced from full models were theory-driven.",It seems fine but it is hard to evaluate without full information.,The authors did not use vowel duration because the segmentation is hard. This does not sound legit to me. The authors extracted five points for F1 and F2 measures but only chose two of them. This is not justified either.,NA,
2022-06-10 08:22:44,2022-06-10 08:45:51,IP Address,35.46.71.221,100,1387,True,2022-06-10 08:45:52,R_2E6TZfjxf9ju0iV,,,,,42.2623,-85.6148,anonymous,EN,arapaima_modularis,ctenosaura_limax,90,95,90,publishable with minor revision.,"This overall a very good and compelling analysis. However, most of the justifications for the several decisions taken here appear somewhere else (Eyben, 2015), which leaves the reviewer with two choices: either trust the authors or go consult Eyben. For the sake of time, I did something in the middle, that is, I read the overall rationale and premise of Eyben's work. In any case, I wish authors had included a bit more information in their own report, especially for the acoustic analysis. ","The statistical analysis is better explained than the acoustic one. The stats seem appropriate, especially in terms of narrowing down the analysis to variables that are interpretable, rather than pursuing the analysis until the end with all 88 features. ","Very good, though, as I said before, I wish authors had elaborated a bit more on their decisions rather than referring the reader to other sources. ","Appropriate. ",Appropriate,"There is no mention of excluding trials identified as containing errors. This would be the main reason why I did not give this analysis a higher score. ","Good ",
2022-06-10 08:56:55,2022-06-10 09:00:12,IP Address,80.7.115.73,100,196,True,2022-06-10 09:00:13,R_cYn4le6RCUzw9K9,,,,,53.9744,-1.1783,anonymous,EN,chelonia_brummeri,procambarus_mahogoni,90,90,90,publishable with minor revision.," The models are appropriate and structured correctly; however, a singularity warning is thrown that seems to be ignored. "," The mixed-effects linear regression is fine. "," The variables included in the statistical model are fine. "," No concerns."," Fine."," Fine."," Fine.","The slight deduction for the phonetic analysis was because the extraction guidelines/parameters were omitted from the write-up. Overall the report is quite short: some more detail on measurement extraction would be welcome for increased replicability (e.g. were the measures averaged over the vowel, or taken at the midpoint?), as well as more detail on whether the measures were transformed/scaled or if any exclusions were made (e.g. based on outlier status)."
2022-06-10 10:16:57,2022-06-10 10:20:48,IP Address,73.217.118.234,100,230,True,2022-06-10 10:20:48,R_2qeKVNmEL6QR14M,,,,,39.9834,-105.143,anonymous,EN,nestor_idahoensis,aratinga_lugubris,75,90,80,publishable with minor revision.,"They first did a perceptual analysis and agreed that they couldn’t hear any acoustic differences between productions of the same color for different typicality rates so they decided to exame non-acoustic cues to see if they differentiate typicality. The results of the preliminary perceptual experiment - that the team couldn’t meaningfully perceive any acoustic differences between conditions - and Hypothesis 4 - that the team could perceive meaningful differences in emphasis between conditions - are incongruent. The authors addressed this in a footnote at the end of the paper but additional discussion of the acoustic cues that the authors believed might vary individually is necessary to justify their assumptions. The authors do not present inter-rater and intra-rater agreement data for perception of emphasis. This should be included in a minor revision. I would also like to see discussion of how raters were masked to condition information while rating the tokens in order to control for subconscious rater bias. 

They then moved beyond a phonetic analysis and instead assessed accentedness of nouns and adjectives and the number of errors/hesitations/longer pauses. For accentedness, they did another perceptual analysis where team members marked the colors for accentedness for the noun or adjective pair.

For errors/hesitations, the tokens were marked for error type. A list of the “mistakes” included in this analysis would have been helpful – were they consonant substitutions/omissions, or were these just prosodic (hesitation) errors? 
","They did a reliability analysis using Cohen’s Kappa to compare their annotations of errors with the organizer’s annotations and found high reliability. This was a thorough and appropriate analysis. However, it was unclear whether the identified disagreements were resolved or ignored.
To analyze if speech errors were concentrated at the beginning vs. end of the experiment, they made a distribution figure to see how distributed the errors were across the experiment. Based on visual analysis, the errors were generally equally distributed. A visual analysis seems appropriate for this. 
Then to look at the relationship between typicality and speech error, and typicality and accentedness, they built two Bayesian mixed effects regression models, both of which had appropriate structure. My only critique is that they included random intercepts by participant and color, but not random slopes. It would have been nice to have used a maximal random effects structure. They also originally included color as a random effect but then excluded it because they didn’t get model convergence; so they only included speaker as a random effect which seems appropriate. 
A big critique is that they used default priors in their Bayesian models which are rarely appropriate. It would have been better to use minimally informative priors that assumed no effect instead of the flat priors used in the defaults.
","The process of variable selection was well-described. The preliminary perceptual analysis informed their variable selection. It was interesting that the authors did not include acoustic variables in the current analysis (e.g., f0, duration, etc.), but the choice not to include these variables was likely appropriate, since the listeners did not note differences here during the perceptual analysis. However, there are often differences that are not perceptible (e.g., covert contrast), so we would recommend also examining acoustic variables with this dataset.","They ran two Bayesian mixed effects models both with typicality as the dependent variable and with random intercepts by speaker and color. They said that the models didn’t converge with color included as a random effect but then color is included as a random effect in the model code. This is confusing and needs to be explained further. The predictors for each model were speech errors and accentedness, which both seem appropriate. 
They excluded acoustic variables from the model because their original perceptual analysis did not reveal any differences. This is appropriate, although it is possible that there are undetectable acoustic differences. 
","The structure of the model is appropriate. I do recommend including random slopes instead of just random intercepts. They could have also run one big model with the predictors together instead of separate. ","Including only the NF condition (and excluding the AF condition) here was appropriate. At the end, the authors note that certain speakers may have been appropriate to exclude from analysis based on their speech characteristics. While the authors did not exclude these speakers from the current analysis, it does demonstrate the benefits of the preliminary perceptual analysis, to identify whether certain speakers might be using a different register that might impact the results.",N/A,Duration of hesitations/pauses may have been informative in the current analysis.
2022-06-10 11:42:09,2022-06-10 12:01:05,IP Address,173.245.206.162,100,1135,True,2022-06-10 12:01:06,R_1FYBYJMq93uE1Jn,,,,,33.7722,-84.3928,anonymous,EN,polymetme_brevirostrum,genyonemus_evotis,96,70,70,publishable with major revision.,"Ratings were made on the basis of motivation from previous research, soundness of variable selection and coding, statistical analysis technique chosen, results, and interpretation of the model results.",The initial dimension reduction approach using t-SNE effectively demonstrates the correlation among the various metrics under consideration and is appropriate for an analysis without definite a priori direction. The use of a generalized linear model is also appropriate for the data (though see comments below regarding selection of independent variables).,"The researchers take a shotgun approach to analyzing acoustic features, selecting a smattering of potential correlates and seeing how those correlates cluster by condition. This initial approach to selecting variables (t-SNE) is acceptable given the researchers' lack of prior hypotheses, but the steps taken afterward are not. ","The results of the feature analysis suggest that several of the acoustic metrics selected are highly correlated to one another, so it is inappropriate to add each as a main effect in a generalized linear model (due to multicollinearity and the concomitant decrease in precision in regression results).",The statistical model is inappropriately structured. The model is likely to overestimate the contribution of the predictors on the dependent variable and likely has inflated Type 1 error.  This is due to multicollinearity among the predictors and inadequate specification of the random effects structure (only including intercepts by subject).,"The authors made minimal exclusions for extreme outliers, but they did not exclude tokens that were tagged as errors (which may exert more influence on the model result than one or two extreme outliers, if the model is correctly specified). ","I was curious why the authors did not use the output from the feature analysis as predictors for the regression analysis, given that the feature projections are by definition orthogonal to one another and capture similarity among the various acoustic measures.",N/A
2022-06-07 10:20:22,2022-06-10 14:15:03,IP Address,128.2.149.6,100,273280,True,2022-06-10 14:15:04,R_22XNke9A0awIqU0,,,,,40.4324,-79.9247,anonymous,EN,sphyrna_ellioti,procambarus_maculosus,75,75,75,publishable with minor revision.,"I appreciate the originality of the analysis. While the research question was simple, analyzing F0 offers many possible approaches to do it. I was unfamiliar with this approach and am interested in learning more. There were some decisions that I would ask for more information about. For example, the decision to substitute missing F0 values within the vowel with the value at the previous timepoint. It seems this could really affect the measures, and there may be better methods to avoid pitch halving or doubling artifacts (such as resetting the threshold values for a speaker). ",The multi-level model used seems appropriate for the question.,"I think choosing the primary components for the f0 contour rather than raw values was an interesting choice. I am unfamiliar with this type of analysis, although my impression is that it seems promising. To me, it is the part of the analysis that stands out the most. The statistical technique itself is fairly simple, but is appropriate given the question; that said, I'm not sure why the pruning was carried out, rather than report on the initial model including things that were apparently not significant.","The included and excluded variables seem well-justified. One aspect of this that I would like more information on is on how the cutoff gets decided for deciding what principal components to include/exclude. ",The overall structure of the statistical model was suitable.,Exclusion decisions are well-justified and suitable.,"The major transformation in the project involves the conversion from F0 measures to principal components. I am somewhat unfamiliar with this approach, although the authors do a good job at explaining the process briefly. ",
2022-06-10 12:47:08,2022-06-10 14:39:39,IP Address,81.97.172.223,100,6751,True,2022-06-10 14:39:40,R_3kul7OLM2Pmqjc1,,,,,55.0021,-1.6287,anonymous,EN,haematopus_fossor,gymnothorax_spinulosus,75,75,75,publishable with minor revision.,"Phonetic analysis: 
This analysis looked at (relative) vowel intensity. Intensity is a relatively inconsistent cue, compared to fundamental frequency or duration, to prosodic focus and stress. It is not clear from the methods document how precisely the recordings were made, but based on impressionistic auditory inspection of the recordings it appears that the participants did not necessarily have a constant distance between the mouth and the microphone. This makes any estimation of intensity inherently unreliable.
The reliance on uncorrected forced-aligned measurements is perhaps not the best possible approach, but there’s only so much time in life and we all have to make sacrifices.
Otherwise, the phonetic analysis appears to have been competently done.
Statistical analysis: 
The model overall appears to be well-constructed and well-though-out. As the analysis was done on the continuous typicality values (rather than the categorical one), we expected a graph with a continuous x-axis, rather than the categorical figure 1. The distribution of typicality values, however, may give some cause for concern as it is multimodal. It wasn’t mentioned in the results but it appears that there’s a main effect of focus condition, such that AF adjectives are louder than the other conditions – this is not unexpected but it bolsters the idea that the analysis is overall reliable.","A linear mixed effect regression model was used to analyze the data, which is appropriate.","The choice of IVs was reasonable. The choice of DV was questionable – as discussed above, there are better measurements (such as f0 or duration) that could have been made.",See above.,See above.,"The analysis included data from all focus conditions – i.e. NF, ANF, and AF. However, the typicality values are not evenly distributed throughout these conditions. Notably, only the NF condition features the full range of typicality (“atypical” through “typical”), the ANF condition only has phrases of high and medium typicality, while the AF condition only has phrases of low and medium typicality. This confound between focus condition and typicality makes interpretation of the results challenging.",No transformations were made. It may have been helpful to center the relative intensity data around zero before entering it into the model but it is unlikely that this would have affected the conclusions in a meaningful way.,No further comments.
2022-06-10 14:19:37,2022-06-10 14:40:13,IP Address,83.41.133.195,100,1236,True,2022-06-10 14:40:14,R_33x9UTAHHivCuvX,,,,,41.4928,2.0403,anonymous,EN,saron_pictus,pseudodax_euryzona,65,70,68,publishable with minor revision.,"This was a difficult analysis to rate, as none of our team members know enough about FPCA to properly evaluate it. In general, we are unclear why not modelling pitch contours with something more directly interpretable was warranted, and this doesn't seem to be strongly motivated. Our understanding of PCA more broadly for dimensionality reduction doesn't seem to be relevant here given the simplicity of the design and a small number of relevant predictors. As this method is not standard, it should have been explained in depth, and not referenced the reader to other papers. ","We were not able to recreate the analysis based on the given materials, as we encountered a number of issues running the code, possibly due to namespace issues of unspecified packages, so we were not able to check if the models were appropriately specified.","The variables of s1 and s2 were not particularly well explained, so this is difficult to evaluate. ","Regarding the inclusion of PC1 and PC2, there was no mention of why they were included and why the remaining principle components were excluded. This is an important aspect to include while using standard PCA, so if this does not apply to FPCA it needs to be made explicit.","Again, this was hard to evaluate as we were not able to run the code and check this for ourselves, and no model diagnostic plots were provided by the authors. One issue with the model is that speaker and/or stimulus variance components made up one of the dependent variables, which to us makes the interpretation of the statistical models strange.",,We have a small issue with the fact that f0 values were interpolated when the true value in voiceless sounds should be undefined.,
2022-06-10 16:21:18,2022-06-10 16:34:41,IP Address,71.14.128.99,100,803,True,2022-06-10 16:34:42,R_1CdvOaDFegnEjOY,,,,,32.7979,-97.3586,anonymous,EN,varanus_eulophotes,swiftia_ruber,70,70,70,publishable with major revision.,"Bayesian modeling is informative; however, they mentioned that they took out random variables because of the computational load of the model and because the splines of the first model did not differ when the variables were included versus when they were not. However, this seems like the random variables should have been included in all models for the most thorough analysis. At the very least, I think a basic regression model could have been computed to show any effects of random variables. 

Another concern is how representative the data they analyzed are, and how could the pattern be generalized (See below for more detailed concerns). I'd also like to know more detail about vowel segmenting criterion, how many data points for each condition they are analyzing, especially for the typical/atypical phrases under the NF condition, and whether the difference in figure 1 is statistically significant.",Analysis seems appropriate with above caveats,See above comments,See above comments,See above comments,"They excluded the medium typicality category, which limited the amount of data analyzed and (as they mentioned) made their distribution uneven. I think they could have at least done some analyses within the medium typicality subset (just as they did with the other subsets, e.g. AF vs NF conditions within the atypical phrases) instead of leaving it completely out.",Data transformations are appropriate,
2022-06-10 15:34:45,2022-06-11 15:07:33,IP Address,24.85.249.153,100,84767,True,2022-06-11 15:07:34,R_2Cf7GbTnfKbsgLI,,,,,49.2293,-123.1882,anonymous,EN,cromileptes_saxatilis,psittacula_scabriculus,90,72,75,publishable with minor revision.,"Overall strong analysis with a few errors in the statistical analysis (especially in the random effects & prior specifications) – however, these do not affect the outcomes too much.",The statistical model (Bayesian mixed effects model) is entirely appropriate for this analysis.,"The process of choosing variables was transparent and clearly described. The authors opted to look at average vowel durations within word tokens, which is OK, though my impression is that the literature has more examples of work on word durations. One advantage of using average vowel durations in this scenario is that while word durations will vary widely across nouns simply as a function of the segments they contain, the average vowel durations are more stable. The main predictor variable is typicality with all three-levels included, which is a straightforward and appropriate choice.",They are well-suited to the analysis & the research questions.,"There are two issues with the statistical model:
(1) The model includes a random slope over typicality by item, but the nouns *did not vary* across the typicality conditions – each of them only occurs in one typicality condition. Therefore, this random slope cannot be estimated from the data. I've checked what happens when it is included, and the results are essentially the same, so in the end this does not make much of a difference – nonetheless, this is an error in the model specification.
(2) The authors suggest that they chose a weakly informative prior, but (as far as I understand) the scale of the prior here is not really congruent with the scale on which vowel durations vary. That is, the authors went for a prior of N(0,1) for the typicality effect, but the vowel durations vary within a much narrower range (0.036 s to 0.44 s); so a more appropriate distribution might have an SD of, say, 0.1 (which would still easily allow differences of 0.2-0.3 s among the groups, even though such large differences in vowel duration are still not really expected).","There were some exclusions based on the original annotations & observed vowel deletions in the data. These all seem perfectly justified, and, given the negative results, there's really no indication of data dredging.","Perhaps the only transformation to mention is the averaging of vowel durations within tokens. It would have been possible to fit the data to the raw vowel durations (and perhaps include phoneme identity as random effect!), but I doubt it would have changed much.",Overall impressive analysis!
2022-06-11 16:06:51,2022-06-11 16:16:42,IP Address,24.85.249.153,100,591,True,2022-06-11 16:16:42,R_2tmy50ug5AQFoXU,,,,,49.2293,-123.1882,anonymous,EN,cromileptes_saxatilis,nestor_idahoensis,94,83,87,publishable with minor revision.,"Both the phonetic and statistical analysis are competently executed, though I have some minor concerns about the latter (specifically about prior specifications & multivariate modelling).","The authors fitted a Bayesian multivariate lognormal mixed regression model to the data; this seems appropriate, but I should note that the fact that this is a multivariate model is not mentioned anywhere in the report, which is problematic! It is also not made clear how a multivariate model is more appropriate here than separate univariate models for each of the outcomes. (I'm not arguing that it isn't – but there should be some discussion / contextualisation in the text).","There were clear a priori reasons for picking each outcome variable, and the predictors are straightforward. There are perhaps slightly too many outcome variables that are evaluated, though the authors' arguments for including all of them are compelling.",The variables are suitable for addressing the main research questions.,"I have some concerns about the prior specifications for the models: namely, this is a multivariate model, and each outcome variable is on a very different scale; but the priors are the same (SD=10). I don't think that such a prior works well for e.g. F2 values, where differences of 50-100 Hz are not at all surprising; and it seems overly permissive for duration values that are represented in seconds. The RMarkdown file seems to include a sensitivity analysis, but this is not clearly described in the report.

Also, the lognormal distributional assumption may not hold for some of the outcomes!","Any choices to exclude data were grounded in strong a priori argumentation, so no issues here.",There were no data transformations.,
