StartDate,EndDate,Status,IPAddress,Progress,Duration (in seconds),Finished,RecordedDate,ResponseId,RecipientLastName,RecipientFirstName,RecipientEmail,ExternalReference,LocationLatitude,LocationLongitude,DistributionChannel,UserLanguage,Q2,Q3,Q5_2,Q5_3,Q5_4,Q6,Q8,Q9,Q10,Q11,Q12,Q13,Q14,Q15
Start Date,End Date,Response Type,IP Address,Progress,Duration (in seconds),Finished,Recorded Date,Response ID,Recipient Last Name,Recipient First Name,Recipient Email,External Data Reference,Location Latitude,Location Longitude,Distribution Channel,User Language,"Your team name (i.e., the fantasy animal)",The team name (fantasy animal) for the analysis you are reviewing.,"Please rate the following aspects of the study under review with regard to how well they answer the research question (""Do speakers acoustically modify utterances to signal atypical word combinations in referring expressions?"") with the available data. - Rate the phonetic analysis","Please rate the following aspects of the study under review with regard to how well they answer the research question (""Do speakers acoustically modify utterances to signal atypical word combinations in referring expressions?"") with the available data. - Rate the statistical analysis","Please rate the following aspects of the study under review with regard to how well they answer the research question (""Do speakers acoustically modify utterances to signal atypical word combinations in referring expressions?"") with the available data. - Provide an overall rating",Would the analytical methods presented produce an analysis that is:,Please explain your ratings of this analysis.,Please evaluate the choice of statistical analysis type.,Please evaluate the process of choosing variables for and structuring the statistical model.,Please evaluate the suitability of the variables included in (or excluded from) the statistical model.,Please evaluate the suitability of the structure of the statistical model.,Please evaluate choices to exclude or not exclude subsets of the data.,"Please evaluate any choices to transform data (or, if there were no transformations, but you think there should have been, please discuss that choice).",Please use this space for any additional comment you may have at this stage.
"{""ImportId"":""startDate"",""timeZone"":""America/Denver""}","{""ImportId"":""endDate"",""timeZone"":""America/Denver""}","{""ImportId"":""status""}","{""ImportId"":""ipAddress""}","{""ImportId"":""progress""}","{""ImportId"":""duration""}","{""ImportId"":""finished""}","{""ImportId"":""recordedDate"",""timeZone"":""America/Denver""}","{""ImportId"":""_recordId""}","{""ImportId"":""recipientLastName""}","{""ImportId"":""recipientFirstName""}","{""ImportId"":""recipientEmail""}","{""ImportId"":""externalDataReference""}","{""ImportId"":""locationLatitude""}","{""ImportId"":""locationLongitude""}","{""ImportId"":""distributionChannel""}","{""ImportId"":""userLanguage""}","{""ImportId"":""QID2""}","{""ImportId"":""QID4""}","{""ImportId"":""QID6_2""}","{""ImportId"":""QID6_3""}","{""ImportId"":""QID6_4""}","{""ImportId"":""QID7""}","{""ImportId"":""QID9_TEXT""}","{""ImportId"":""QID10_TEXT""}","{""ImportId"":""QID11_TEXT""}","{""ImportId"":""QID12_TEXT""}","{""ImportId"":""QID13_TEXT""}","{""ImportId"":""QID14_TEXT""}","{""ImportId"":""QID15_TEXT""}","{""ImportId"":""QID16_TEXT""}"
2022-05-16 08:43:57,2022-05-16 09:11:56,IP Address,98.114.11.227,100,1679,True,2022-05-16 09:11:57,R_UT5LkRWyZTFwiSR,,,,,39.9206,-75.1826,anonymous,EN,polymetme_brevirostrum,varanus_eulophotes,65,73,75,publishable with major revision.,"My rating was based on the replicability, accountability, and validity of the data extraction and statistical analysis. In general, the analysis is appropriate, but there are several potential drawbacks that may lead to erroneous interpretation of the data. ","Linear regression is an appropriate start for the given outcome variable (mean f0). ","Variable selection, which was parsimonious and justified by previous research and theory, is appropriate and does not reflect data dredging. However, the selection of variables does not reflect the full experimental design. The overall choice of structure for the statistical model is appropriate, but formulaic; the structure could be better tailored to the hypotheses and the data.","The selection of variables is quite minimal and does not encompass the full experimental design. For example, foods and non-foods may show distinct effects of mean f0 for different typicalities, because non-foods are more likely to come in a variety of colors than food items. The model structure does not account for specific items, so there are several lurking variables that may underlie the null result. ","The statistical model structure could be better suited to the data and specific hypotheses. For example, typicality is an ordinal variable, but this relationship is not captured by treatment coding. Additionally, the inclusion of only random intercepts by speaker fails to account for speaker-specific variation in the effect of typicality on f0 (i.e., the current model accounts for distinct mean f0 by different speakers, but some speakers may disproportionately distinguish typicality by f0). To capture this, a random slope for typicality should also be included. Finally, some notion of variance by item needs to be included in the statistical model. The typicality of each stimulus is different (even within typicality groupings), and typicality may interact with color and whether the item is a food or non-food. The authors' statistical model structure does not account for any of these potential covariates. 

Regarding the fitting procedure, it is apparent from the residuals that the outcome variable is not linear. Though the authors could have re-run the analysis on a subset of the data which is ""well behaved"" (cf. Baayen and Millin 2010), an analysis that accepts nonlinear outcome variables (e.g., GAMs) might be more appropriate. ","The data selection process is accountable and minimizes issues with typographical errors, but it does not exclude those utterances which were tagged as errors in the annotation tier. ","The authors attempted standard transformations (log, inverse) to normalize the residuals of the model to no avail. Rather than attempt another technique to model the data, the authors retained a poorly fitting model. The authors could have considered more sophisticated modeling techniques (e.g., Bayesian regression) or models that do not assume linear relationships between outcome and input variables (e.g., GAMs). ",
2022-05-16 10:04:58,2022-05-16 10:48:18,IP Address,134.69.55.186,100,2599,True,2022-05-16 10:48:19,R_1JDce011SUAW0Tm,,,,,34.1325,-118.2076,anonymous,EN,hoplostethus_macrosteus,polymetme_brevirostrum,80,75,60,publishable with minor revision.,"We found ourselves having to go back to the team's Qualtrics responses for many of the answers to the questions we had as we were reading the very brief write-up. We are concerned at the inclusion of typicality for all three conditions (i.e. NF, AF, ANF), since we understood that typicality ratings outside of the NF condition were unreliable. We would also liked to have observed the following: a) more information and/or verification of the alignment using the Montreal Forced Aligner b) more information (tables, figures, etc.) about the results and c) a clear response to the research question in the write-up and clearer supporting evidence. 

We did appreciate the brief review of previous literature as motivation for the dependent variable to be used in the analysis.","We often used linear mixed effects regression, but found that the explanation of the statistical analysis left out some important information and included some information that was not clearly motivated. For instance, we are still uncertain as to what the dependent variable was-- pitch range could have been explained more clearly, what were the units of the DV, etc. The end result was confusing.","Again, we're a bit confused as to why the Typicality ratings were included across conditions, since those were marked as NA in the ratings sheets. Otherwise, the variables look fine (random variables for object, color, and speaker made sense).","'- We don't think there was a strong enough motivation for the inclusion of Category and Condition
- We don't think there was a strong enough motivation for beginning with a ""kitchen sink"" model by including all possible interactions among the main effects. In fact, to our understanding, interactions should only be included in analyses when there is a) theoretical motivation to include them or b) data exploration has suggested an interaction that helps better explain the model. ",Answered above,"The researchers excluded any observations that had comments in the ""notes"" tier of the textgrids, this is fine. No mention was made of any other exclusions, though we might wonder if there were any outliers or undefined pitch regions. We also observed many instances of creaky voice, but no mention was made of this. ","To our understanding, no transformations were needed given that pitch range relies on each speaker (and is therefore normalized by speaker). Confirmation of this in the write-up would have been helpful. ","Organizers-- We were not sure whether we *could* use the survey responses in addition to the write-up provided. If you would prefer that we solely relied on the write-up (called ""Analysis_Summary"" within the ""Runbook"" folder), we are happy to re-do this analysis. Please let us know (we've also emailed). Thanks!
"
2022-05-16 11:57:21,2022-05-16 13:41:09,IP Address,96.242.236.104,100,6228,True,2022-05-16 13:41:10,R_yPhNau1hl1N65c5,,,,,40.5921,-74.6238,anonymous,EN,procambarus_mahogoni,trachyphyllia_lappa,90,90,90,publishable as is.,"The authors explained well what they did and how they went about completing analyses. It is easy to follow. ","We believe the model that was chosen fits the data well. ",The only issue we have with the process of choosing variables is that the authors could have used typicality as a continuous variable instead of categorical one.,"Duration and pitch are suitable variables for answering the research question, we wonder if they would consider exploring intensity as well.","The structure of the statistical model is suitable for the data and data frame. ","Authors excluded data based on errors in speech production and justified why they were excluded well. ",N/A,"We didn't fully understand the plots, particularly the right hand side of the plot that focused on nouns. "
2022-05-16 21:46:31,2022-05-16 21:54:30,IP Address,115.129.131.53,100,478,True,2022-05-16 21:54:30,R_1dAHJ8hZbI09OS0,,,,,-33.8715,151.2006,anonymous,EN,dunkleosteus_inscriptus,paralichthys_undulatus,50,50,50,publishable with major revision.,"Very little information is provided about any aspect of the analysis, so it is difficult to understand and assess exactly what was done, and why.","Linear Mixed Effects models are suitable, but because no hypotheses was proposed or motivated, the NHST does not seem to be an appropriate framework. Bayesian Mixed Models might have been a better approach, given the exploratory nature of much of the analysis.",No information is provided about the process by which the final model was chosen and no motivation is provided for the model structure used.,"The variables included in the model are appropriate for the exploration of influences on pitch range, assuming the data are sufficiently normally distributed, but no details are provided about how the final model was chosen or the suitability of the data.",The model seems appropriate for examining the interactions between F0 range and key factors in the dataset.,"The use of the NF (Noun Focus) condition only, excluding errors and hesitations, is appropriate.","The use semitone scaling for F0 is appropriate for fundamental frequency analysis, but no explanation is provided for why 100Hz was chosen as the reference frequency, or how this was motivated by the data.","This team have analyzed fundamental frequency in the Noun-Focused utterances to examine the effect of Typicality on F0 range. A single linear mixed effects model is presented and analyzed in a NHST framework, and the team report that ""we cannot conclude that speakers modify the f0 range of an utterance with an atypical versus typical referent"", but no specific hypotheses is outlined and the choice of model and variables is not motivated. No analyses are presented to validate the suitability of the data for the model chosen. The data were ""manually aligned based on visual and auditory inspection"", but no details are provided about how the segmentation was conducted, which landmarks were used, and how the data were validated.

F0 range is a key phonetic parameter which is certainly of interest in this dataset, and if it is the case that Typicality does not affect overal pitch excursion, that will be an important contribution to our understanding how how speakers modulate (or don't modulate) utterances of this type, but unfortunately, not enough information is provided to properly understand the details of the phonetic analysis, and the statistical results cannot be properly interpreted in the absence of a clear hypotheses and better motivated models.

Materials on OSF repository should be anonymized for blind review."
2022-05-16 21:49:37,2022-05-16 22:10:54,IP Address,184.64.221.169,100,1277,True,2022-05-16 22:10:55,R_324qWz18m6zzL2Q,,,,,51.0406,-114.0764,anonymous,EN,pseudopleuronectes_assasi,procambarus_mahogoni,0,10,5,deeply flawed and unpublishable.,"The authors stated that they measured the duration, pitch and intensity in Praat, but they did not specify the details of this analysis, for example, how they annotated and spliced the audio files. They merely presented the measurements in an Excel file. There is very little presented and given. ","The authors chose to carry out a mixed-effects linear regression. Given the dependent and independent variables and the research question of the study, the choice of the statistical analysis is well-motivated.","The authors analyzed the data by using linear mixed effects regression models. They did not compare the outcome of their model with the outcome of the null model, which is why we cannot be certain whether their model was different than the null model.","The authors selected duration, pitch, and intensity as dependent, and median typicality as the independent variable. As regards the dependent variables, the authors selected them based on the research conducted by Gordon and Roettger (2017). The dependent variables were well-motivated. The authors did not explain why they chose this one as their independent variable. They used the median that the organizers had included in the info they gave us. They also included random effects by-participant and by-mean typicality. Again, it is not clear why the authors selected the independent variable mean typicality as a random effect.","The authors analyzed the data by using linear mixed effects regression models. They did not compare the outcome of their model with the outcome of the null model, which is why we cannot be certain whether their model was different than the null model.",The authors excluded AF and ANF trials from the analysis. They included trials with errors. No description of the data collection was provided.,No transformations were carried out.,"Not anonymized.

The report has very little text and it is primarily the authors' R code."
2022-05-17 15:35:22,2022-05-17 15:54:51,IP Address,68.201.51.109,100,1168,True,2022-05-17 15:54:52,R_1110MtrT8L2D0mt,,,,,31.7775,-106.4903,anonymous,EN,paralichthys_undulatus,trachurus_riukiuensis,70,85,80,publishable with minor revision.,"They chose two relevant acoustic measures (duration and f0) of the article, adjective and noun, they labelled and measured them accurately and used a relevant statistical method. I am not quite clear on their reason for examining the article, as well as only the stressed syllable of the noun - more motivation would be helpful. ","They used linear mixed models on each measure, which is a valid approach for this type of data. ","The dependent variables were duration and f0 peak - the only issue here is that the instructions were to only include one in the writeup. The independent variable was typicality. Each condition (article, adjective, noun) was examined in a separate model. As noted above, the choice to include the article was not clearly motivated.","Participant and item were random intercepts... random slopes would be more appropriate but led to convergence issues. In the noun, they only examined up to the stressed syllable - again, without a clearly stated motivation for this. While this logically makes sense in terms of pitch accents, this is not stated in the report.",Using a linear regression model for each of the acoustic variables is a valid approach to answer this research question.,"They excluded sentences that were marked as errors or hesitations, which makes sense. They also excluded one speaker JW_3 due to them having a high error rate - this seems unnecessary. They also excluded any values that were +/- 2.5 standard deviations from the mean, which is logical.","The f0 measures appear to have been left in Hertz, which is not clearly stated but there is no mention of transformation. Converting them to semitones would have been more appropriate since the participants were pooled.","They examined more than one acoustic measure, and it would have been appropriate to not use raw Hz for the f0 measures. "
2022-05-18 08:09:22,2022-05-18 08:44:23,IP Address,5.132.95.23,100,2101,True,2022-05-18 08:44:24,R_3gL2JGiD4isNcRg,,,,,51.7285,5.8849,anonymous,EN,ctenosaura_limax,psittacula_scabriculus,78,78,78,publishable with minor revision.,"This analysis is concise and contain most information that is needed. The main issues I have with the analysis are: (1) Data exclusion. ""Trials containing longer pauses were not excluded "" -- why? It is unclear what 'longer pauses' refers to and how they would affect the vowel duration. It could benefit from having a sentence or two to explain the criterion. (2) Bayesian analysis. While I know the Bayesian analysis method, I cannot say I am an expert in it. I think this is the status for most people in the field since the traditional lmers are still the mainstream way. It is therefore needed, at this point of time in history, to explain more to the readers how the models are configured. It is true that all the parameters were reported, but without reading a book on Bayesian statistical analysis, I, as a reader, cannot gauge well whether the parameters were set in the optimal way. This is especially the case with the priors, which I think is quite important in the analysis. (3) Uploaded data file. The data file uploaded to the OSF does not match with what was used in the script. Fortunately, it seems to contain the correct data.","Good choice, but needs more explanation.",Reasonable,Suitable.,Suitable.,"As mentioned above, more explanations are needed for why 'trials containing longer pauses were not excluded'.",NA,
2022-05-20 01:38:11,2022-05-20 01:47:08,IP Address,195.221.243.131,100,536,True,2022-05-20 01:47:08,R_2bZW7ygixI1XSZ0,,,,,48.0014,0.1901,anonymous,EN,ceratophrys_elephantotus,aracana_bitatawa,50,97,74,publishable with minor revision.,"The research report does not clearly state at what level duration and f0 were extracted: word level, segmental level or even adj-noun group level. ","I do not know QGAM. But it seems to me that the applied methods are solid. ","Seems fine. However I am not sure about including google bigrams as the furnished data set already contains typicality rates collected from humans. ","Duration and f0 were processed independently in two different models. The other variables are fine, too. ","I do not know QGAM analyses. Froma what I know about mixed effects models, it seems fine. ","All erroneous productions were excluded. Ok. ","F0 was transformed. A z-normalization was applied in order to smooth variation according to speaker gender. Only five speakers were male, the normalization process is a good idea in order to smooth out gender bias in the values. ","I'd really like to know more about how acoustic measures were extracted. "
2022-05-20 03:34:40,2022-05-20 03:45:19,IP Address,88.10.224.231,100,639,True,2022-05-20 03:45:20,R_1pRmWzVEV1SqgG7,,,,,43.3126,-1.9745,anonymous,EN,gymnothorax_spinulosus,trapezia_cantonensis,75,26,36,deeply flawed and unpublishable.,"The author seems to have ignored the focus condition (AF, NF, ANF), which could have an important impact on the analysis.
The use of GAMMs appears very flawed for this analysis. All p-values are extremely significant, yet in the analysis the author concludes for one model that there is no consistent effect at all, for one model that there is possibly a small effect, and for one model that there is a large effect. This calls into question the purpose of using a significance criterion at all, especially without reporting an effect size.
We note that they did not follow the guideline to choose only one dependent variable (instead they analyzed formants, pitch, duration and intensity separately).","The choice of generalized additive mixed models for pitch, intensity and formants appears deeply flawed. All models were highly significant, but the author seems to focus his/her analysis entirely on the graphs, with very different conclusions for each model. Above all there is no justification for using such complex models and linear mixed models could have been sufficient. I believe it’s better to choose simple models and only use more complex models when simple models are not suitable.
The choice of a linear mixed model for the duration analysis appears sensible.
","The process is not very clear, there is no explanation about why the focus condition (AF, NF, ANF) was ignored.
Without being an expert on GAMMs, it is difficult to check whether the models’ assumptions were respected.
The author did not explain why they choose the categorical encoding for typicality (rather than the continuous scale e.g. typ_mean or typ_median). 
","The author ignored the focus condition (AF, NF, ANF), with no justification. This means that the typicality conditions were not properly balanced with regards to focus (for example the “non-food” typicality value was not present in the AF condition, when the focus of the sentence was on the adjective).
The choice to use the categorical encoding for typicality (rather than the continuous scale typ_mean or typ_median) is not a very good choice because some information is lost by reducing a continuous scale down to a 4-categories factor, with the “non-food” category in particular not easily interpreted in relation to the others.
","I do not entirely understand the transformation operated to take into accounts the different formants in the first GAAM, but I have to question the suitability of a model that can be extremely significant without the data showing any consistent direction.
For the other GAMMs, the author’s analysis appears mostly based on certain conditions being consistently higher or lower than others, which calls into question the use of a time-series analysis rather than just using an average value over the whole interval.
","Trials marked as errors were not apparently rejected, with no explanation either way. The author only excluded outliers for the F0 analysis, choosing to exclude the samples with F0 equal to 0 while keeping the samples around them. This could be a questionable strategy, depending on the proportion of samples with f0=0, and whether samples around them would have artificially low F0. There is not much information on this.","The author does not appear to have transformed the data, which is fine to me",
2022-05-20 06:33:19,2022-05-20 06:54:26,IP Address,95.223.75.249,100,1266,True,2022-05-20 06:54:26,R_Z4w5Iy030ir1Vfj,,,,,50.1188,8.6401,anonymous,EN,lycodes_bradfieldi,anomalocaris_ornata,75,80,75,publishable with major revision.,"The authors test the effect of typicality (categorical) on f0, vowel duration, and intensity, at the word level, for only the object and color words. Mixed models were used with speaker and word or word type (col_obj) included as random effects. Additional fixed effects were included for voice type and col_obj (i.e., color vs. object word). 

While the authors seem to have a strong command of statistical modelling, the variety of exclusions and transformations, as well as the additional inclusion of variables not initially included in the dataset, make the overall analysis and conclusions somewhat confusing / questionable. The f0 work may be particularly fragile, given the transformations and splitting.  

It is interesting that the authors find an intensity effect for the object word, rather than the color word, as one might have expected. The result is weak, but not because it is just or barely below alpha = 0.05 (meaningless statement, given that the authors take an NSHT approach; they should get rid of such statement), but because the effect seems very small. The inclusion of effect size would have helped in interpretation. 
",The choice of a linear mixed model is appropriate. Details about the model are discussed below.,"The authors were interested in the following dependent variables:
-	Intensity in dB of the entire word (for colour and object), 
-	F0 (looking at only the stressed vowel in both colour and object) 
-	Vowel duration (of only the stressed vowels in both the colour and object levels).

They considered these variables relevant based on previous literature, particularly what is known about the structure of the German language. 

Their dependent variables were: 
-	Typicality (categorical), color-obj (indicate whether it was a color vs. object work), and voice type (high vs. low pitch). The interaction between typicality and color-obj was also included. 

A random effect was included for col_obj nested in speaker. In the model predicting vowel duration, word and speaker were included individually as random effects, as the previous structure (sol_obj|speaker) failed to converge. In other words, not all models had the same random effects structure. 

We are slightly confused why voice type was included as a fixed, rather than random effect. Further, isn’t the inclusion of the random slope and intercept for participant enough to account for differences due to their voice type? 
","The included variables are generally suitable. 
The authors did a significant amount of additional work to conduct their analyses. They seem to have created new text grids, a new analysis of production errors for the sake of exclusion criterion (though what exactly was done here is not totally clear), and they also added an additional variable of voice type, which they coded by hand into high pitch or low pitch. Please see the answer to the previous question with respect to the inclusion of voice type. 
",See previous answers.,"The authors seem to have excluded 26 production errors in some way, though it is unclear how exactly (full trials? individual words?). It would also be nice to know what the criteria for coding these errors were. 

The analysis was done only on the variables of interest during the production of color or object words, i.e., all other words in the full utterance were excluded. 

Words with e.g., f0, values falling outside the 1.5 IQR were excluded as outliers. 
","f0 data showed a bi-modal distribution and were first split into low vs. high voice type; however, this transformation did not solve the bi-modal distribution problem so the data were instead split into above vs. below 150 Hz. 
We find this transformation confusing (what is underlying this bimodality?) but respect the authors careful checking of these matters. 
",
2022-05-21 03:51:58,2022-05-21 06:35:22,IP Address,138.246.3.187,100,9803,True,2022-05-21 06:35:23,R_1luI8DC0NX9Xmex,,,,,48.1787,11.5617,anonymous,EN,gnathosaurus_canadensis,eosipterus_pytyopsittacus,75,60,68,publishable with minor revision.,"The analysis done looks fine enough to me, however, I really don't understand how the analysis answers the research question, so I gave it a bit of a lower score. The analysis, especially the statistical model, seem to answer the question whether f0 contours are different depending on the focus condition and not whether typicality is marked using prosody. 
I do think that the analysis is done well overall, I just had a very hard time judging it against the background of the project. If I had only scored based on the suitability for answering the research question, I would have given a much lower score.","The model seemed to work well for the question the researchers investigated (i.e., prediction of the focus condition). I would have been interested to see if this model could also be used to predict the typicality condition.","Since the variables (f0 slope; f0 height and duration) were based on the PoLaR annotation I am not familiar with, it is difficult to judge the accuracy of these annotations. However, I could not find any specification of which durations or f0 values were measured, only the rather vague ""all analysis [was limited"" to the parts of each utterance containing the determiner, adjective and noun"", so it is unclear to me how exactly the values for the variables were optained. It is also not clear to me if the PoLaR method includes acoustic measurements or if it is based on relative (and more subjective) categorization like in the ToBI system. ","Duration, f0 height and f0 slope are adequate variables to judge prosody. The choice of the focus condition as the main variable is great to answer the research question posed in the report, but not to answer the research question posed by the project.",seems good to me,"only the medium typical condition from all focus conditions was included. As previously said, I don't think it is possible to answer the research question posed by the project with this subset of the data. If I only take the research question posed by the researchers themselves into account, then I am unsure why no control condition was chosen. It would have been possible to compare medium typical and typical combinations in the different focus conditions.
Furthermore, no data was excluded based on errors or hesitation etc. Since one of the variables was f0 slope, I figure that a hesitation break would have an effect. There is however no explanation as to why these trials were not excluded.",-,-
2022-05-21 07:27:37,2022-05-21 07:33:01,IP Address,78.203.139.61,100,324,True,2022-05-21 07:33:01,R_1FIzMAm3fmI3YI8,,,,,45.748,4.85,anonymous,EN,linckia_nattereri,cromileptes_saxatilis,80,80,80,publishable with minor revision.,"The focus on a single parameter (i.e. duration) enhances the overall legibility of the study. The hypothesis (which is eventually not supported by statistical analysis) is justified by evidence from the literature that predictability is negatively correlated with duration. While opting for parsimony (and duration) is a legitimate choice, we feel that perhaps the motivation for this should be supported by more references. Ditto for the authors’ choice to “minimise researcher degrees of freedom”: since this is the driving principle behind their workflow, a reference allowing readers to get a clearer idea of what this entails would be welcome. The report is very clear, with just enough detail to allow other researchers to reproduce the analysis pipeline. Only adjective and noun pairs from the NF condition were analyzed. The Praat and R Markdown scripts are provided. A potential issue with the Praat scripts is that: 1) they were written with the old Praat syntax (3 dots after function names, single quotes for variable substitution, etc.) – which, of course, is not problematic per se, as Praat still accepts it, but it may look a little opaque to younger Praat scripters and, 2) there are no comments in the Praat scripts (the RMd file has some, by definition). Perhaps “where there was a pause between the adjective and the noun” should be clarified: what counted as a pause here? “no apparent anomalies or obvious outliers”: a well-established method like boxplot inspection would sound more convincing. “orangen, which was typically pronounced with a fricative”: this is a little confusing since it implies that there’s something wrong with what the native speakers in the experiment produced. The explanation (that the German dictionary for the aligner only has a velar nasal and no fricative) actually appears in the R Markdown file but maybe it would be clearer to mention this in the report (or leave out this detail altogether).  ","The authors used a Bayesian mixed effects lognormal regression model, and justified their choice as follows: “lognormal distribution with a log link function is used to better approximate the distribution of the duration data”. To the best of our knowledge, this is appropriate. ","The structure of the model looks valid : adj_dur ~ typicality + (1 | speaker) + (1 | target_noun) + (1 + typicality | target_adjective). It is said that an additional random slope ((1 + typicality | speaker)) was added but removed due to convergence issues. The choice of priors is thoroughly explained. Perhaps a reference for the whole methodology should be given since we expect that many potential readers are not specialists of Bayesian models and how priors should be chosen. ","The structure is suitable but it should be noted that the authors only kept two levels of the typicality factor: atypical vs typical, thus leaving out the medium modality. The justification for this is “simpler and more easily interpretable models with fewer parameters; and these two groups are where the most pronounced difference is expected”. This of course makes perfect sense, but it would probably be more appropriate (for the sake of scientific transparency, and the possibility to perform post hoc pairwise comparisons) to include all three levels of “typicality” in the analysis. ","The structure is appropriate. ","As mentioned in previously: the exclusion of the “medium” level of the “typicality” factor, while pragmatically justified, is perhaps questionable ","The intrinsically skewed duration data is not explicitly converted to log values but the use of a log link function implies that the model works in log space under the hood. So the authors reasoned both in terms of log and raw duration values to build their model, but the output is shown in raw duration (seconds), which is desirable since it is more interpretable. ",NA
2022-05-22 14:18:21,2022-05-22 14:19:33,IP Address,222.154.100.210,100,71,True,2022-05-22 14:19:33,R_33vAIeRQrgc1e4M,,,,,-43.5379,172.6151,anonymous,EN,alosa_atun,stygobromus_tyraica,75,75,80,publishable with minor revision.,"The current study doesn't control for co-articulatory affects. For example, the authors only focussed on the adjective, but they haven't controlled for the noun. Furthermore, the analysis doesn't connect with the signal and how this might affected by linguistic environment. There is opaqueness in the analysis as we don't know if this is an environmental affect or typicality affect. The acoustic measures were included without research justification. We would like to see more details on variable selection.","We like the training and test set-up, but it doesn't control for variable selection. They could've held out noun categories or created a subset so that we can control for typicality and create a baseline. Classification problem that tests for typicality that accounts for the noun condition (which isn't balanced).","They didn't choose specific acoustic variables, even the top 10 variables are quite similar.",They didn't explain the acoustic qualities and didn't relate this to phonetics. They didn't exclude any variables. The variable importance is misleading. No justification to use a one tailed binomial test there's no existing hypothesis.,We don't think it's suitable based on our review.,"The authors removed segments with notes and known errors. They did not hand correct alignments; however, this wouldn't be necessary if they removed outliers.",They scaled and centred each variable by speaker. We believe this is suitable.,"We appreciate the presentation of their analysis in the markdown, and we are confident we could reproduce their analysis. It would be nice to summarise the results or relate their analysis back to the research question or hypothesis. It would be useful if they contextualised the results."
2022-05-24 04:26:48,2022-05-24 05:25:56,IP Address,194.117.18.99,100,3547,True,2022-05-24 05:25:57,R_aeBNr4biMcRWntv,,,,,38.731,-9.1373,anonymous,EN,eosipterus_pytyopsittacus,nestor_idahoensis,20,75,40,publishable with major revision.,"This analysis contained some appropriate methods, and we were impressed by the rigor of the data preparation and the clarity of the write-up. However, it was also subject to several serious flaws in the experimental design. Chiefly, the choice to collapse all vowels together in comparing F1 and F2 is not appropriate. Each vowel has its own set of formant properties, so for example, comparing F1 of /u/ and F1 of /i/ in a collapsed analysis muddles the data so much that no claim can be made about formant differences. Additionally, because the data set contains male and female speakers, collapsing their F0 measurements creates an additional set of problems related to the fact that they did not use any normalization methods. It is therefore unsurprising that none of their results were significant, because the data is so hypervariant as to be informative. As a result, it cannot be validly compared against typicality conditions. ","The choice of statistical type was appropriate, and we appreciate their thoughtful choices with respect to data analysis. However, the strength of their statistics is somewhat undermined by the unusual choice of variables, which has the outcome of producing results that are not necessarily reliable. These limitations are discussed below. ","First and foremost, a major and critical flaw in the model is that vowel identity was not included. Since vowels were not separated from one another, measures of F1/F2 will be so variant as to be meaningless in comparing F1/F2 values across typicality conditions. (To be clear, vowel identity must be included in the model so that the F1/F2 values of one vowel in one typicality condition are compared to only the F1/F2 values of that same vowel in another typicality condition.)

In addition, the authors do not provide extensive justification for their choice of variables; essentially they are just looking for differences in acoustic measures related to prominence between typicality conditions. They motivate this with the claim that prosodic stress can be used for pragmatic emphasis. This is uncontroversial, but they do not state the direction of their hypotheses for these variables, which is a major limitation. Do the authors expect longer duration, lower/higher F0 or lower/higher formant measures for stressed vowels in the atypical condition? If so, what motivates these hypotheses?
","The acoustic variables were well very much suitable for measuring acoustic effects of prominence, for a language like German. However, we are puzzled why the authors took measures only for adjective words (Sidenote: it ought to be mentioned in the write-up which words were considered “target words”, when the experimental condition had two target words), when the NF condition was selected. To be clear, it would seem to us that, in the NF condition, the *noun* would presumably be the item that is most prominent (thus subject to variability in degrees of prominence). In fact, since “typicality” is about the noun-adjective *combination*, it perhaps would have been even more appropriate to run the model on measures from *both* the noun and adjective (due to the nature of what defines typicality, in this experimental context).","The choice of a Bayesian mixed effects model was appropriate, though it would have been useful to have more information about their “weakly informative priors”. The model included their variables of interest, but was limited by the fact that the F0 and formant data was not normalized for important speaker characteristics (especially gender) which should have been included. ","The authors excluded segments of forced-aligned intervals shorter than 50 ms, however they did not report how many such vowels were excluded.","We think the authors should have normalized the F1 and F2 measures of speakers, in order to use data from various genders and body types (both known to influence formant values) to analyze the effect of condition on F1/F2. Similarly, f0 also ought to have been normalized (e.g., as a z-score according to speaker) to run measures on data that come from a variety of speakers.","There is a lot of good work here, but there are *only two* critical (and straightforward!) changes that must be made for the results to be meaningful: the normalization of F1/F2/f0 measures for each speaker, and the inclusion of vowel identity in the model. (In addition, the authors are strongly encouraged to revisit the direction of effects in their hypotheses and to be explicit about what motivates these hypotheses.)"
2022-05-17 06:57:13,2022-05-17 07:05:42,IP Address,138.246.3.55,40,509,False,2022-05-24 07:05:46,R_2xLfD1GQWc8KXqt,,,,,,,anonymous,EN,procambarus_maculosus,pervagor_meeki,51,50,50,publishable with minor revision.,,,,,,,,
2022-05-24 07:51:49,2022-05-24 07:54:59,IP Address,100.12.211.163,100,190,True,2022-05-24 07:54:59,R_3PjVIw0KNNqDX29,,,,,40.7465,-73.909,anonymous,EN,pervagor_adscensionis,hoplostethus_macrosteus,90,20,40,publishable with major revision.,"Unsure about why ±2 std were removed. Seemed like color and observation should have been random effects rather than fixed effects, noun could also have been entered as a random effect, observation could have been removed once it became clear it wasn't significant. Would have used emmeans package rather than Tukey test for pairwise comparisons. Would have been nice to see the AIC values for each of the fitted models to understand why they chose the ones they did. F0 and other measures could have been taken and analyzed regardless of gender given that participant was entered as random effect.",LMER works fine for this question (as long as you define the fixed and random effects appropriately).,Fixed and random effects did not seem to be chosen appropriately (see above). Could have used other phonetic variables given that their rationale for excluding F0 doesn't take into account that a random effect of speaker would allow for comparison.,See above,See above,"Fine to exclude observations with notes, but didn't seem like they justified their exclusion of ±2 std of data","Data seemed fine as it was, but should have noted how normalization was carried out (z-score?)",
2022-05-24 08:40:01,2022-05-24 08:49:22,IP Address,82.1.240.127,100,561,True,2022-05-24 08:49:23,R_PSt6K8RA46pxUAx,,,,,55.9335,-3.254,anonymous,EN,trigonias_lachneri,comanthina_maculatus,10,5,7,deeply flawed and unpublishable.,"There are several major concerns related to the statistical analysis. Overall, there is not enough detail in the report to enable replication. Here are some of the specific major issues.
First, only 15 participants were included, lowering the power the analyses. Second, it appears that measurements were taken from the nouns (focus condition is unspecified), as opposed to the adjectives and no rationale was provided. As the former were not counterbalanced across the conditions, there might be confounds on the measurements due to vowel category and segmental context, as pointed out by the authors. Third, the statistical models do not include a random structure, which may increase the risk of false positives. Fourth, the authors do not report effect sizes, making the interpretation of their statistical results difficult and not fulfilling the task requirement. Fifth, while the authors point to some references regarding the choice of variables to study, they could have been better integrated to provide a stronger argument. Lastly, they tested multiple independent variables and do not report  a single effect size with a rationale to research question, as per the requirements of the task.

A positive aspect of their approach is that the authors checked if the data fulfils the assumptions for an ANOVA test and took steps to correct for that using some non-parametric test and some alpha adjustment.","The report does not make explicit what model was used to generate the final results. It appears that the authors may have used either Mann-Whitney U-Tests or Wilcoxon Signed Rank Tests. At one point in the report they refer to them as unpaired non-parametric t-tests and in another part they say that they carried out pairwise comparisons. In either case these models assume independence of observations, which is violated in the provided dataset, as each participants provided multiple data points. This may lead to increased risk of false positive results. They also do not report how they adjusted the alpha levels.
","The authors justified their choice of dependent variables using references but did not integrate them clearly in the report. They tested multiple independent variables and did not report which one specifically is the one answer to the research question. ","It appears that each of the models only included one dependent and independent variable, which are appropriate, considering the research question. We have already addressed our concern that there are three analyses of three independent variables given that the task requires one answer. We have already addressed our concern that the models do not include random effects.",Too little information is provided for us to be able to provide feedback on the structure of the models.,"Data labelled as “noise” or “error” was appropriately excluded. It is not completely clear if the authors excluded adjectives from the analysis. Including nouns is problematic, as the nouns were not balanced across the three typicality conditions. Their varying segmental and syllabic composition, stress pattern and length may lead to confounds in the typicality condition, as pointed out by the authors. 
No justification is provided for only including 15 participants. This lowers the power of the statistical analysis and may increase the risk of type II errors. Also no information is provided about the basis on which the remaining participants were included.
As Praat f0 measurements sometimes produce values that are 2x higher or lower than the real values, checking for and filtering out of extreme values would have been appropriate.
The authors report excluding pretonic and posttonic measurements, so it is unclear how many data points were included at the end. It is unclear what was the rationale behind these choices.
","We believe that given that the RQ is interested in within-speaker variation and the amount of data per speaker is balanced, the lack of transformations would not be an issue, if it was clearer what data were included in the analyses.","The report is overall lacking in detail. The use of R software had to be implied from the manual provided in the supplementary results. The procedure for extracting measurements could have been described in more detail, without having to refer to the provided Praat script. The author of the Praat script is not cited. As segmentation was carried out by hand, more detail should have been included to describe the visual criteria used to label onsets and offsets of segments. The provided example textgrid does not reference the exact sound file and location, so its addition has not been helpful."
2022-05-24 11:05:59,2022-05-24 11:45:39,IP Address,67.1.130.215,100,2379,True,2022-05-24 11:45:39,R_z8pgAIvvqwFQDwR,,,,,32.2699,-110.9853,anonymous,EN,dermatolepis_aculeatus,pseudodax_euryzona,95,40,70,publishable with major revision.,"The model was not adjusted for the tokens random effect for word level or sentence level.  There are only two minor points that I noticed. The authors wrote that they considered several ways of tackling the research question (at the word level, sentence level, prepositional phrase level), but they do not give reasons why they decided to examine the last five words at the end. Also, it is not clearly defined what is meant by silence between two words (e.g. the duration of the break).  
Very minor point regarding the selection of ""random"" variables in Figure 1: they don't mention what method was used to ""randomly"" select the data --this matters because computers can only simulate randomness, so the package should be reported.",Very good.,very good.,very good.,"One thing was missing in the structure of the statistical model, ( 1 | token level) & ( 1 | sentence level)","very good. These choices were sound (and basically the same ones we made, just  with fewer error categories). They only included those with typicality judgements and eliminated tokens that likely would have had abnormal prosodic contours.","Their normalization procedures were appropriate, and the scaling they did to make the z-scores more Hz-like is helpful when interpreting f0 data. Their interpolation of undefined data points was also fine.",
2022-05-24 12:25:45,2022-05-24 12:36:34,IP Address,192.145.118.247,100,648,True,2022-05-24 12:36:34,R_6F20AjnG9G2HP7X,,,,,37.3931,-121.962,anonymous,EN,pervagor_meeki,dunkleosteus_inscriptus,60,55,57,publishable with major revision.,"Positives:
- Identified f0, intensity and duration as relevant measures (although only duration was analyzed)
- Excluded error trials and validated using a force aligner
- Motivated measuring syllable rate
- Considered using a relative duration measure to account for overall speaking rate

Negatives:
- Several issues with the structure of the models (see comments below)
- Unclear why f0 and intensity could not be measured in an automatic and replicable way
- Included data from all focus conditions when testing for typicality without acknowledging the unbalanced design, and maintaining the typicality condition as “NA” for data from the AF and ANF conditions
- Did not report effect sizes in the report. Unclear how to interpret the effect sizes reported in the survey
- Unclear criteria for data validation and exclusions (see comments below)
","Mixed effects models are an appropriate analysis type. It would have been useful to include an explanation for why both mixed effects models with NHST and equivalent Bayesian models were used, as well as more explanation for how to interpret the ROPE analysis. 
","1. The team described having measured the number of syllables in the noun and adjective, but it is unclear whether this was used in the statistical analyses. Controlling for number of syllables is a good idea, but it doesn’t look like this was used to calculate relative duration of noun and adjective (the main DV) or included in the models as a fixed or random effect.
2. Similarly, the team identified speech rate as a potentially relevant factor to control for, but did not include speech rate as a covariate in the models. 
3. The team performed different models to test for the effects of focus condition, and typicality. However, the models on typicality included data from all focus conditions (including conditions where typicality was coded as “NA” - more on this later). We disagree with this choice: if data from all focus conditions is being analyzed in a single model, then it is critical that the model include both typicality and focus condition as fixed effects, as well as their interaction.
4. We disagree with the team’s claim that there are considerable methodological difficulties with measuring f0 and intensity (two very relevant acoustic measures associated with focus) or that it could not have been done through automatic methods. While it is true that f0 cannot be tracked over voiceless intervals (e.g., consonants), this can easily be circumvented by averaging f0 over voiced segments (vowels) for each word, as has been done in previous research (e.g., Lam & Watson, 2010), without the need to use ToBI annotations. Secondly, as the design was entirely within-subject and many relevant factors (speaker, target noun etc) can be controlled for in the mixed effects models as random effects, there are no methodological issues with measuring intensity.
5. It was unclear why the team performed all of the duration measurements indicated in Table 1 (e.g., including the whole utterance, the matrix clause etc) when only a subset of them were used in the analyses.
","1. We don’t agree with the choice to analyze data from all focus conditions when testing for the effect of typicality. That is because the AF and ANF conditions were not designed to be balanced across typicality levels and included non-fruit target nouns (filler items). Thus, the only focus condition that includes color-noun combinations across all 3 typicality levels is the NF condition. If the team wanted to include data from the other focus conditions, they could have done so by (1) including focus condition as a predictor, (2) coding the typicality factor as either typical, medium or atypical based on the typicality norming data, instead of leaving it as NA, and (3) acknowledged that the resulting model would still be imperfect due to the unbalanced nature of the design.
2. A further issue with including data from the AF and ANF conditions in the typicality models, coded as NA for typicality, is that it leads to a very unbalanced dataset (~250 trials x typicality conditions in NF, versus ~900 trials coded as NA across AF and ANF). 
3. The coding scheme for the mixed effects models was not specified. We would assume that the team used the default R treatment coding with Atypical as the baseline (as Atypical does not appear in the model outputs); we would suggest to specify and justify the coding scheme, and perhaps use Typical or Medium as the baseline.
","Other than the issues described above, we would also recommend including by-Participant random slopes for Typicality in the initial random effects structure, and then simplify it in case of convergence issues (Barr et al., 2013).
","1. The criteria for data validation were not well defined and justified. Why did the team use both -2SD and +3SD as outlier cutoffs? (Why not just +/- 2SD or 3SD?) How exactly did the team determine if these cutoffs were “too aggressive”, and in which distributions did they adjust them?
2. We suggest that the team could have used a different force aligner (e.g., Montreal Forced Aligner, MFA; McAuliffe et al., 2017) leading to fewer errors. It was unclear how exactly the team determined which trials should be excluded from the analysis based on force aligner error, and which should not (as they note in the Discussion that erroneous data remained even after data validation and cleaning).
","The team could have provided better motivation for why it was necessary to use relative duration as the main DV. Similarly, it was unclear why the team conducted the same analysis on both relative and absolute duration.
",
2022-05-25 10:03:38,2022-05-25 10:06:08,IP Address,24.18.173.245,100,149,True,2022-05-25 10:06:08,R_2ylolmhV4zjr4IZ,,,,,47.1037,-122.3235,anonymous,EN,epinephelus_aztecus,genyonemus_evotis,70,70,70,publishable with major revision.,"Phonetic ratings: The authors use a blanket term of F0 and several speech properties, but they do not provide clear details for the justification of these different properties, particularly the harmonics. The authors note that time-course should not be examined, but this was not clear why, since lengthening could be a potential way to signal typicality in speech.

The use of a forced aligner may be a good choice for parsing large amounts of data, but it was not clear whether any of the data were hand coded or examined to ensure accuracy. The method of alignment and data extraction was not particularly detailed, and it is not clear whether another team could replicate the data extraction based on the description. 

There were some points in the analysis that were unclear as to whether the authors were making judgments about typicality in line with the original norming study or using additional metrics.

The authors provided very detailed visual analyses of the data. However, the motivation and method of the visualization was not explained in enough detail to be accessible to a non-expert, and there was so much data that it was overwhelming at times. In addition, it was unclear how the visualizations were integrated into the logistic regression and the interpretation of the analysis. For example, if the visualizations had led to no clear differences in typicality, would the model still be run in the same way? ","The logistic regression is a standard analysis tool in the field, but it is unclear how such a large model should be interpreted","Comparing typicality by acoustic feature seems appropriate, but there was some confusion as to why the data were divided among the three focus conditions, and how the different focus conditions integrated into the analysis/hypothesis, since the NF focus condition was the critical condition. Since many of the acoustic features are highly related (e.g., the various harmonics), it was not clear whether these should have been grouped separately. ","It seemed appropriate to include all the variables that were extracted from the speech stream for comparison, but (as noted above), it was not entirely clear why all of those were included.",The model makes use of a very minimal random effects structure. More discussion is needed about the choice of this random effects structure rather than a more complex model (with random slopes and additional random intercepts) instead of a model with a large number of fixed effects (without interactions).,"The authors note that data above 97.5% and below 2.5% should be excluded, which seems like a reasonable choice. It is not clear whether the authors excluded trials that were marked by the data collectors as errors, or if other criteria were used within each trial.","The authors’ did not explicitly say why they chose to normalize the F0 values to semitone, and why they chose the 10th percentile as baseline as opposed to another. Other than that, their choice to normalize the other measurements to Z-score seems appropriate.","A lot of the analysis was very confusing, and it seemed at times overwhelming with so many visualizations, acoustic variables and running the model on all three focus conditions.

The presentation of the data generally only included statistically significant effects, but it would be helpful to include all the effects in order to evaluate which harmonics were significant and which were not. 

It was hard to draw conclusions from the data. It seemed like most everything was statistically significant, and the directions of the effects were not clearly stated. The authors do try to tie the results back to theory, but this could be strengthened, perhaps in motivating the choices earlier and understanding the ways that speech does (and doesn’t) change as a result of typicality."
2022-05-25 11:04:57,2022-05-25 11:21:52,IP Address,85.243.196.228,100,1014,True,2022-05-25 11:21:53,R_117QiOUIZvCLmQs,,,,,38.731,-9.1373,anonymous,EN,naso_cassivellaunos,ctenosaura_limax,66,66,22,publishable with major revision.,"'Ctenosaura_limax' used 10 acoustic features from the openSMILE toolkit that represent a diverse (and somewhat arbitrary) set of features. These 10 features vary in their consistency with respect to articulation or perception of speech and they are disconnected from linguistic structure beyond the noun phrase. We address the suitability of these measurements in more detail below.

'Ctenosaura_limax' used multinomial logistic regression models for statistical analysis. We are not familiar with the methods used, and it was challenging to understand the description of the descriptions of the statistical analysis method. Then the information in ctenosaura_limax.txt helped us to better understand the statistical analysis. As far as we could tell, there were no significant errors. Our rating for the statistical analysis reflects that it took significant effort to make sense of the relevant part of the report. 


The overall rating reflects our concerns about how to link the research question, data analysis, and interpretations. The choice to measure the whole noun phrase has unfortunate implications. This problem affects all the acoustic variables as it appears to blur distinctions across the board at two levels of analysis: (1) ignoring the distinction between the two words of the noun phrase — the adjective and the noun; and (2) ignoring the distinction between syllables within words, namely the stressed and the final syllables that tend to carry most of the prosodic weight in distinct ways. This decision essentially prevents the possibility to interpret any of the findings in terms of actual acoustic events. We believe that this interpretability problem at the heart of this study greatly undermines an otherwise worthy effort by 'ctenosaura_limax’.


'Ctenosaura_limax’ stated that “[w]e initially fitted models with 88 acoustic features that were commonly used for machine learning in speech. However, we found that many variables were not linguistically interpretable (MFCCs), even though they were highly predictive. So we later decided to select a subset of 10 f0 and formant features that were more familiar to linguists as the variables for regression analysis.” In our view, the linguistic relevance of the subset of the formant features is not clear.  

","We are not experienced in the techniques in the present analysis. The descriptions of the analysis procedure in the report were too technical. As stated above, the teams’ response to the questionnaire (ctenosaura_limax.txt) helped us to understand the procedure, and there seemed to be no significant errors. ","'Ctenosaura_limax' used the openSMILE toolkit to extract 88 acoustic features. They ignore 68 features unrelated to voice sources, and they eliminate 10 out of the remaining 20 to improve ""model interpretability"". The authors claim that they eliminated features based on them being highly correlated, but they do not mention the criterion for choosing which one should remain. The remaining 10 features represent a mixed bag of very straightforward (e.g. F0) and more complex (e.g. the ratio of energy in the first harmonic and the energy of the highest harmonic in the third formant) measurements.

The main concerns regarding these measurements are with what 'ctenosaura_limax' refer to as ""high-level features"": the calculation of means and standard deviations over the entire adjective-noun phrase, without the ability to link any of the measurements to elements in the linguistic structure analyzed.
","'Ctenosaura_limax' used the openSMILE toolkit to extract 10 acoustic features. These include some very basic measures, like F0 that simply refers to pitch, and some more complex measures that refer to aspects of voice quality, such as the ratio between energy in the first and second harmonics (H1-H2). All measurements were calculated as the mean and standard deviation over the entire adjective-noun phrase. The standard deviation was not calculated for the two F0 slope measurements, which are presented as ""meanRisingSlope"" and ""meanFallingSlope"". We could not find an explanation (including external sources from openSMILE) as to what this slope measurement in fact reflects (does it select the min and max F0 points for the whole phrase? that would inevitably capture many unrelated F0 trajectories). The interpretation of the voice quality features is also lacking here. What is the perceptual effect that is associated with the ratio between the energy of the first 3 formants and the energy of F0? The latter is the most predictive feature in the model and we do not understand what is the articulatory or perceptual effect that it is assumed to cover (this could be our own ignorance, of course, but the authors should have made this clearer).

Note also that voice quality measures (6 out of 10 in this study), that are very sensitive to physiological differences between different speakers, are also quite reflective of differences in the segmental makeup (e.g. voiceless vs. vocalic material, different vowel qualities), such that they may be quite problematic in the context of this data set which is not lexically balanced by design.

","The structure seemed to be suitable, but we are not entirely confident about our judgment. 
","'Ctenosaura_limax' analyzed only NF tokens. This choice is justifiable given that we were interested in the ‘typicality’ as a predictor within the NF condition. That said, they did not exclude the tokens flagged as errors of various types in the original data, which would have been a justifiable move (although probably not very consequential). We also point out that ‘ctenosaura_limax’ has only provided acoustical analyses for the Noun Phrase, excluding the utterance portions before and after the NP, in case this can be construed as an example of subsetting the data.","Mean-variance normalization (z-scores) was applied. The transformation seemed appropriate. ",
2022-05-25 12:56:12,2022-05-25 13:09:23,IP Address,67.218.231.198,100,790,True,2022-05-25 13:09:23,R_ByOvgKz2fXnkit3,,,,,42.8561,-2.6946,anonymous,EN,pseudodax_euryzona,lasionycteris_altavela,55,65,60,publishable with major revision.,"The analysis, while correct, appears overly simple. The textgrids were used without any modifications, which made it impossible to distinguish measurements in the relevant parts of the sentence from these at the repeated carrier phrase. The choice of the main measurement, i.e. peak intensity at the sentence level is problematic: the identified peak might lie in the carrier phrase. Finally, it could have been more interesting to model the intensity curve instead of just a maximum point.",The choice of an LMER model seems correct.,"The choice of peak intensity as the dependent variable is justified to some extent, but the choice of the whole sentence as the target of the phonetic analysis is not. Mean typicality is used as the independent variable, but the decision to use the numerical variable and not the categorical one is not sufficiently justified.","The model includes the random effect of the target noun, but not of the adjective or any other word. This is done under the assumption that the peak intensity will always be found in the noun for the NF condition. The rationale behind this is not entirely convincing. ","Including varying slope (1|filename:target_name) apparently causes singularity issues, not mentioned in the report. The results reported are in fact for the model without this random effect and only with the reported random intercepts, ie lmer(Intensity ~ typ_mean + (1|target_name)+ (1|filename)).","Only noun focus data was included, which is appropriate. Trials including notes in the textgrids were excluded. This may not be enough. Our team had to mark extra sentences as errors or hesitation breaks in addition to the ones already marked as such in the provided textgrids. Errors and hesitation could affect the measurements.","The data was not transformed. We would recommend a by-speaker normalisation of the intensity values, because the intercept-only speaker random effect cannot account for all the variability between speakers.","The confidence intervals and pseudo R2 values appear a bit surprising (“pseudo R2 < .001 95% CI [.000, .999]”).
"
2022-05-25 14:20:46,2022-05-25 14:25:25,IP Address,71.104.44.228,100,279,True,2022-05-25 14:25:26,R_1gBjKvDpstBArqx,,,,,40.4992,-74.4996,anonymous,EN,lasionycteris_altavela,trigonias_lachneri,95,100,99,publishable as is.,"The preprocessing was well documented and walked the reader through each step. The choices were sufficiently explained and well reasoned with citations. The only additional step I would recommend is examining if the full model structure was needed. ","The model was appropriate. 
","SPI was chosen as a single variable to incorporate several key markers into one outcome variable using prior literature. Typicality was included as a continuous variable on the NF conditions, while speaker and color were used as random factors. ","These choices are appropriate. 
","
Model structure was appropriate to capture random variance due to participants and stimuli as well as using continuous typicality ratings. Unclear if the random slopes were necessary but they did not seem to hurt the model. 
","Data was excluded by examining trials with comments due to error in the trial or noise. These choices seem reasonable. ","The SPI was log-transformed to deal with non-normality, which seemed like an appropriate choice. ",The SPI  was developed by researchers to study prosody in patients with Parkinson's disease. It looks like the measure hasn't been picked up in the general literature.
2022-05-26 06:10:18,2022-05-26 06:51:50,IP Address,213.55.224.240,100,2491,True,2022-05-26 06:51:51,R_27BfNPHxxmV4a3n,,,,,47.3934,8.5163,anonymous,EN,aratinga_lugubris,ceratophrys_elephantotus,48,24,36,publishable with major revision.,"As the authors point out, the data was extracted automatically and in many cases automatic extraction produced unreliable results.
Typicality measurements were somehow transferred to individual nouns and adjectives, which does not seem reasonable: typicality defines combinations of adjective+noun.
The analysis is based on intensity and pitch of stressed vowels, but gender and vowel minimal pairs are not considered. Since gender and vowel quality affects both intensity and pitch, including all vowels into the data set distorts the results.
The authors should have considered mixed effects models since observations in the analysis should be independent, but in the provided analysis hidden grouping of observations into speakers is ignored.
There is a problem with independence of observations in the analysis, since each speaker produced more than one utterance with the same values of variables under analysis (e. g. Der rote Paprika was produced twice by every speaker), this should be considered in the statistical analysis. 

","Decision tree analysis is applicable here, but you’d need to control for speakers, gender and repetition of words as random effects.","The authors classified nouns and adjectives into categories of typicality which is not reasonable: only combinations of Adjective+Noun can be classified as typical or atypical.
Vowel quality was not considered when structuring the model, as well as gender differences and repetition.
","The choice of variables is generally reasonable, but:
- Automatic extraction of data wasn’t always reliable
- Vowel quality wasn’t taken into account
",It would be better to use mixed-effects models for this type of data.,The authors did not exclude the data points where they had doubts about the quality of parameters extracted automatically. The authors should have excluded unreliable formant and fundamental frequency data.,NA,
2022-05-19 11:04:29,2022-05-26 07:47:15,IP Address,90.221.215.47,100,592966,True,2022-05-26 07:47:16,R_2AHICTE17M0clOS,,,,,50.9469,-1.4112,anonymous,EN,psittacula_scabriculus,sphyrna_ellioti,90,90,90,publishable as is.,"This analysis is clearly explained and each step has been described in detail. All files are available and I have not found errors. The limitations have been described by the team (the authors expected typicality to have been independently manipulated independent of the condition, which was not the case and had to be taken into consideration during the analysis).","Linear mixed effects models in this case allow to check statistical significance of the effect so the tests was chosen correctly to my knowledge. It takes into consideration random effects, therefore this analysis is more suitable than simple linear regression. ","I am not an expert but to my knowledge the model was fitted in appropriately and the predictors were selected and implemented in the analysis logically. Dependent variables were log duration, intensity, and F0 for critical words (adjective + noun), which are aligned with the research questions. 

Assumptions were checked and where necessary, log transformations were employed. ","The team aimed to check  whether the typicality of a modifier-noun pair affected how the words were said, so they chose to focus on the duration, intensity, and F0 of the adjective and noun pairs. The choice of variables allows to answer the research question.

Typicality mean scores instead of the typicality factor was used in the model as not all typicality was represented for all conditions, which might have had an influence on the results (no obvious effect of this variable) but this was due to the data that the team worked with. ","I have not found anything that would be worrying or needed rethinking. ","The authors focused on noun phrases only (adjective + noun) and no other exclusions have been made. The focus on adjective + noun data only is motivated by the fact that these were the manipulated words, which means the effect should be the easiest to detect. This allowed the authors to narrow the analysis. ","Log transformations were used to address distribution, which is correct in this case. ","I am not an expert but to my knowledge, this analysis has been done correctly. "
2022-05-26 11:07:01,2022-05-26 11:22:27,IP Address,104.28.50.170,100,925,True,2022-05-26 11:22:28,R_2uZGVYWbLKrn2BJ,,,,,33.5716,-101.8545,anonymous,EN,anthracoceros_coronata,gymnothorax_spinulosus,90,100,95,publishable as is.,"The analysis in general was sound.  The only consideration I would add is that only the intensity of the adjective was looked at, even though it's possible that intensity of the noun may have varied based on typicality, especially in the NF condition",The statistical analysis is sound.,"Again, the only consideration I would add is that only the intensity of the adjective was looked at, even though it's possible that intensity of the noun may have varied based on typicality, especially in the NF condition","The variables included were reasonable—condition, typicality, target color, and speaker.",The model was entirely suitable.  A backward stepwise process was used to confirm that the maximal model was appropriate.,Measurements ±1.5 sd from the median were excluded—about 5% of the data.  This is a reasonable cutoff.,Mean intensity of the critical vowel was normalized by subtracting it from the mean intensity over the whole sentence.  This is a reasonable transformation in order to filter out any effects of louder or softer sentences.,
2022-05-27 00:34:10,2022-05-27 01:09:17,IP Address,109.190.253.13,100,2107,True,2022-05-27 01:09:18,R_2f1IoQQagjkyc6m,,,,,48.8582,2.3387,anonymous,EN,eriphia_laterispinis,saron_pictus,90,80,85,publishable with minor revision.,The phonetic analysis seems very relevant and well-conducted (but I am not an expert) and the statistical modelling is also well-conducted.,"The statistical modelling strategy is relevant and the rationale is explained nicely in the summary provided by the team. If I were to suggest a minor revision, I would suggest complementing the estimates and credible interval with hypothesis tests, as the HDI alone (and/or comparing it to some value) does not allow for testing hypotheses.","The structure of the statistical model is sound, I think including trial as a predictor to control for drift in word duration throughout the experiment is a good idea.","All included variables are relevant. Maybe the authors could have analysed other acoustic indexes as well (e.g., F0, intensity).",The structure of the statistical model is sound.,"The authors excluded trials that had any sort of issue denoted in the notes column, which sounds a bit crude.","The authors used a Lognormal distribution for the response, which is equivalent to using a Gaussian distribution on the log-transformed raw data, which I think is reasonable given the prior and posterior predictive checks presented by the authors.",NA
2022-05-27 03:51:26,2022-05-27 03:59:32,IP Address,77.4.96.242,100,485,True,2022-05-27 03:59:33,R_2WUWfwHzImEZi17,,,,,48.1084,11.6102,anonymous,EN,procambarus_maculosus,pervagor_meeki,90,90,90,publishable with minor revision.,"There are only minor flaws in both the phonetic and statistical analysis of this study. Even though some of the changes we propose in this review might affect the overall outcome of the analysis, they are mostly suggestions and not obligatory.",Linear Mixed Effect Regressions (using the latest versions of standard R packages) are an appropriate statistical analysis for the derived acoustic data and chosen variables. Computing effect sizes with estimated marginal means is also fine.,"The process only included small changes to the originally planned analyses, both of which are reasonable: the exclusion of by-word random slopes for the LMERs on nouns because word did not vary with typicality (but see answer below: excluding a random intercept by word is not justified); and a comparison of the NF and AF conditions which was impossible because in AF the nouns were not balanced across the typicality conditions.","The acoustic variables – mean and max F0, mean intensity, and duration – are reasonable choices because these can be acoustic correlates of prosodic prominence.","In the LMERs for nouns, “word” was completely excluded from the random effects. Since word did not vary with typicality, it makes sense to have no by-word slope for typicality, but there should have been a random intercept for word, given that these words are phonetically very diverse. Using the provided scripts and datasets, we computed the LMER on mean F0 in nouns, but included a random intercept for word. The results were not significant for all three pairwise comparisons, showing that the intercept for word could have a major impact on the outcome of the other statistical results as well.
Otherwise, the structure of the LMERs seems to have been carefully chosen and is well explained in the report.","Only NF was analysed and sentences with speech errors, hesitations, etc. were excluded. Both of these choices are justified, although with more time and some manual work one could have saved some of the excluded sentences probably.
Both nouns and adjectives of the NF condition were analysed. While it is somewhat unclear (though not entirely inconceivable) why effects of typicality should show up in the adjectives when the noun is focused, the analysis of the adjectives is nevertheless interesting because it can (and does) show that typicality is mostly not expressed prosodically in the adjectives.
The acoustic measurements were extracted for whole words, not just for e.g. stressed vowels. There seem to be precedents for whole-word-analyses, but it would have been interesting from our perspective to constrain the analysis to stressed vowels only given that prosodic effects will likely show up in the stressed vowels rather than somewhere else within the words.
Outliers, i.e. data points exceeding three standard deviations from each speaker’s mean, were excluded which is reasonable.","F0 was transformed into semitones, a choice that is not explained in much detail but should be fine. More questionable is the use of fundamental frequency values that do not account for differences between males and females; the speakers’ sex could have therefore impacted the statistical analysis without having been taken into account by e.g. adding sex as a fixed effect.
One speaker’s sound file and the corresponding TextGrid were slowed down by a factor of 1.5, but it remains unclear why 1.5 was chosen and which possible acoustic effects the slowing down of the sound file had (e.g. overall lowering of F0?). It was unclear whether the artificially slowed down audio files were also used to extract F0, or whether these were only used for duration measurements.
More generally, the extracted duration values were not normalised in any way, neither for individual speaking rate nor for length of word. The latter would have been especially necessary, because the target nouns consist of between two and four syllables. Therefore, word type is a confounding factor in the analysis of duration.",The report was well written and easy to follow.
2022-05-27 04:32:59,2022-05-27 04:52:29,IP Address,77.161.90.97,100,1170,True,2022-05-27 04:52:30,R_C4ztB185ly7K6Vr,,,,,51.4361,5.4958,anonymous,EN,neosilurus_omanensis,anthracoceros_coronata,59,55,57,publishable with major revision.,"We had some issues with the way word boundaries were marked (who did this? did they receive training? how reliable was the marking?). Additionally, the report contained no predictions and no motivation for the variables that were selected. This makes it somewhat difficult to evaluate the results - the authors find some effects, but state they are unlikely to be of linguistic significance. We were wondering what standard is used for determining this. Also the visual representation of the results could have been a bit more intuitive.","The choice for linear mixed effect modelling is a good one. However, we did not fully understand why the models did not converge, and also wondered about the fallback to standard linear regression.","The focus on pitch, duration and intensity makes intuitive sense. However, why only mean and maximum are measured for each could have been motivated better.",No additional comments,No additional comments.,The way outliers were handles appears to be fine.,N.a.,"It was sometimes difficult to follow what the authors are doing exactly, and why they are doing it, also because the explanation is sometimes written down in a way that is a little confusing (e.g., ""Similarly, for pitch, the maximum pitch and the maximum intensity [should be “mean pitch” we assume] of the word were measured"")"
2022-05-27 07:09:19,2022-05-27 07:11:03,IP Address,83.135.242.69,100,103,True,2022-05-27 07:11:04,R_RUNvfH4mKxPcN2h,,,,,50.9897,7.1349,anonymous,EN,petauroides_fistulator,eriphia_laterispinis,70,95,85,publishable with minor revision.,"We find that concerning the phonetic analysis, not much has been done. However, this is not meant to be a negative statement. The authors explained that they lacked time and skill to provide alignment at the word level, i.e. as they had planned originally. Instead, they used the provided sentence level information and extracted their measures on sentence level, respectively.
Concerning the statistical analysis, we have little experience with running Bayesian models ourselves. However, the report provided by the team does a very good job in explaining their statistical procedures. We only find one minor issue with the statistical analysis, that is the authors did not incorporate an effect of item. As they did not motivate their decision, we are left wondering why this might be.
On a more general note, we are not sure whether taking into account the complete sentence to analyse the phonetic nature of a rather specific part of that sentence is sensible. While we do not deny that later parts of sentences may very well influence earlier parts, we nonetheless find that earlier parts can also be different due to very different factors, e.g. due to speakers’ motivation, outer influences, etc. That is, while the analysis presented is very thorough and well executed, we are uncertain whether the broad scope of incorporated data points per measure per sentence really is meaningful.
The overall rating is the mean of both other ratings. We chose ‘publishable with minor revisions’ as we do not find any insurmountable issues with the statistical analysis, but wish for a discussion of the sentence-scope measurement computation.","As mentioned above, we cannot speak in detail towards the Bayesian statistics part. Yet, after consulting relevant sources, we find no issues with the statistical analysis type. The only minor concern regards the incorporation of item as a variable, as already mentioned above.","The authors make use of several dependent variables: average F0, intensity, and duration of the whole sentence. The authors do not provide motivation for their choice of dependent variables.
As independent variables, typicality and speaker are used. Typicality being the predictor variable of interest, including it is straightforward and requires no further motivation. Speaker was included as random effect to account for inter-speaker differences. Comparing a model with random slopes and intercepts to a model with only random intercepts, the authors found the latter to be most parsimonious. 
As briefly mentioned above, item was not included in the modelling process.","Typicality is the predictor of interest; thus it should be part of any model trying to answer the present research question. However, we would have liked to see some sort of random effect variable for adjective and/or noun combinations, as well as the use of the continuous typicality variable.","We find the structure of the presented models to be overall suitable for answering the present research question. As mentioned before, a more sophisticated random effect structure – even if it is found that is does not improve the model and is to be removed – is preferable.",No subsets of the data were excluded. We find that trials with pertinent comments in the ‘Notes’ tier of the provided TextGrids should have been checked and removed if necessary.,"The three dependent variables, i.e. average F0, intensity, and duration of the whole sentence, were standardised by subtracting the mean and dividing by the standard deviation to account for inter-speaker differences. We find this method appropriate.","We would like to stress again that, regarding the Bayesian part of the statistical analysis, we are laypersons. One group member has basic theoretical knowledge of Bayesian statistics from a linguistics perspective, another member as theoretical knowledge of Bayesian statistics from a mathematical perspective. However, no group member has ever worked with Bayesian methods from a practical point of view."
2022-05-27 08:55:41,2022-05-27 09:17:22,IP Address,72.75.217.214,100,1300,True,2022-05-27 09:17:22,R_3JKMkiGvd1fAXxE,,,,,42.9767,-78.7959,anonymous,EN,sphyrna_ellioti,aratinga_lugubris,70,65,67,publishable with major revision.,"Given that many of the analyses depended on listener judgments, I would want more detail on what the listeners were listening for or what they were expecting when listening to the recordings. I have some questions about how listeners could not notice an acoustic difference but could notice a difference in accentedness. I think being clearer about what types of acoustic differences were being listened for would help. Additionally, I would like more information on why the models had typicality as a dependent variable and things like error rates as independent variables. It's not that I think this choice is wrong, but I would like to understand the decision better.",The statistical analysis type itself seems sound and appropriate.,"I'm not sure why the random effects structure only included independent intercepts. I'd also want more information behind the decision to include typicality as the dependent variable rather than the independent variable. ","The chosen variables seem suitable for the questions the analysts posed. ",The structures of the models seem suitable. I agree that going with default priors seems justified in the current situation.,"I think it was clever to look at error rates and hesitations as part of the data itself, therefore not having to exclude that data.",I didn't notice any transformations or lack of them that seemed inappropriate.,I think the questions and analyses these analysts pursued are very original and interesting! I'd just like more information or justification for some of the choices.
2022-05-27 10:11:14,2022-05-27 10:15:26,IP Address,80.7.115.73,100,251,True,2022-05-27 10:15:26,R_3NKtQyuh0CRwM6c,,,,,53.9744,-1.1783,anonymous,EN,chelonia_brummeri,procambarus_maculosus,25,35,30,publishable with major revision.," The fPCA and related analysis seems to be well implemented, and the authors ‘reverse engineer’ the fPCA results for interpretation fairly clearly. However, the results are likely to be misleading (in our view) due to the problematic choice of measurement domain (see below). "," LMER on the results of fPCA is a good/appropriate approach, and has been carefully implemented and clearly explained. The choice of variables/domains seems to ‘miss the point’ for us, however. ","We do not understand i) why only f0 was measured and, for f0, ii) why f0 measurements were taken in the noun in each adjective-noun combination, rather than in the adjective. 

Prosodic prominence has a range of phonetic exponents, and other measures could have been taken, e.g. duration. Since f0 is measured on a time-normalised basis the analysis sets aside possible effects of typicality on duration completely, which is a potential gap. 

The choice to measure in the noun is not really explained; the authors say that it is in the noun that they “expect the largest possible f0 differences”, but do not say why they expect this.  The choice to measure in the stressed vowel only is appropriate, though even in the adjectives the syllable structure varied, making the stressed rhyme a better domain to use.","The model only looked for effects of typicality and speaker sex, and finds an effect of sex only (based on estimated sex for each speaker). Inter-speaker variation in f0 range (a large part of which will co-vary with sex) could be controlled for by normalising the f0 values for each token by a baseline measure for that speaker (e.g. mean of all min f0 values in all tokens) prior to performing the fPCA. The eventual model could then look at e.g. typicality * vowel.   

The model does not control for vowel quality and length, despite the acknowledged variation in segmental content across nouns; this would have been fairly simple to include.
",Inclusion of a random slope for speakers by typicality is appropriate.,"The authors analysed the NF subset of the data, which was the test portion, so is appropriate. They manually corrected the transcripts for any hesitation or other errors which did not affect the test word (= noun, in their analysis) and excluded two cases where the target noun was mispronounced. This was a good approach if working on the nouns; you would need to exclude tokens where the adjective was mispronounced if the analysis focussed on adjectives."," No transformations were applied, other than time-normalisation of the f0 contour.  ","In a review we might offer a major revision/revise and resubmit because there might be something here if they were to re-run the same analysis on the adjectives; they could normalise f0 within each speaker’s pitch range to abstract away effect of sex on f0, instead of estimating it based on auditory impression. "
2022-05-27 10:12:48,2022-05-27 10:25:34,IP Address,128.187.116.12,100,766,True,2022-05-27 10:25:35,R_2dM8ArvVg4xTwTT,,,,,40.2342,-111.6442,anonymous,EN,trapezia_cantonensis,naso_cassivellaunos,95,95,95,publishable as is.,"Seemed good. I am unfamiliar with Bayesian statistics, so I cannot evaluate it very well, but there was a lot of detail in the methods and how the stats were run.","Bayesian was probably fine, though I'm not familiar with the phonetic analysis they did so I'm not sure what Bayesian offers that a frequentist analysis can't do.",Appeared to be fine.,"Appeared to be fine. ","Appeared to be fine. ","Appeared to be fine. I think cutting out words that didn't fit the tetrasyllabic frame they were aiming for might have lost some important data, but I appreciate the method for the sake of keeping things controlled. ",I don't think there were any transformations.,I'm unfamiliar with what the phonetic analysis was about. They used a tool that I had never heard of and I don't think the explanation of what they were actually measuring was particularly clear. A better write-up might have explained things with a little more detail.
2022-05-27 08:06:36,2022-05-27 10:36:42,IP Address,141.201.219.162,100,9006,True,2022-05-27 10:36:43,R_268sA3ctuZdU8u0,,,,,47.8008,13.0443,anonymous,EN,anomalocaris_ornata,arapaima_modularis,64,60,60,publishable with major revision.,"The choice of statistical test was appropriate. The analytic steps are well-documented and easy to follow. We are concerned about the number of exclusions, and the fact that entire speakers were removed instead of just the outliers. Removing outliers in this way is potentially very problematic. Mean F0 measures are removed, meaning all results for those speakers are now lost. If outliers are going to be removed, this should be done on the raw data points, these individual points can then be removed. It is not very surprising that no variation was found here as substantial degrees of variation have potentially been removed.","The choice of statistical test was appropriate. However, normality was checked on the raw data, not on the model residuals, running the ANOVA residuals on the data given shows that the residuals are fairly normally distributed, but could be improved with transformation.","Pitch and typicality were appropriate for this analysis. Pitch was selected and motivated by reference to ""many languages"", it is possible that German might rely more on intensity for the purpose of accentuation (e.g., Gut 2009: 138).



###
Gut, Ulrike. 2009. Introduction to English Phonetics and Phonology. Frankfurt: Peter Lang.",It would have been beneficial to have looked at more variables (e.g. intensity/ duration).  We wonder what the effect of voice-type was on the exclusion criteria (i.e. lower and higher voices indexing gender).,ANOVA structure was fine. It would have been good to select a statistical test that allows inclusion of random effects for speaker and word (at minimum).,"Using mean values (of the max) is problematic as the difference between max values at higher frequencies (in Hz) is potentially less meaningful than at lower frequencies. The analysis might have been more informative with actual mean values, rather than the mean of the max. 

As mentioned above, removing speakers completely, rather than just the individual measurements is potentially problematic.","It may have been beneficial to transform the data, as the residuals do not appear to be normally distributed (this shouldn't be too much of an issue for robust statistical tests however).","The methods are nice and clear, we really enjoyed the thorough description of the acoustic analysis. The author makes some very good observations regarding creak, pitch excursions, etc. and treats the data accordingly.

"
2022-05-27 11:59:59,2022-05-27 12:04:50,IP Address,151.224.144.247,100,290,True,2022-05-27 12:04:50,R_bJxCgMB5nVp4W09,,,,,51.8842,-0.4208,anonymous,EN,stygobromus_tyraica,petauroides_fistulator,10,0,0,deeply flawed and unpublishable.,"Our ratings reflect two main issues we found with this analysis. The first issue is the choice to analyse the F0 patterns of the nouns, which is reflected in the rating for the phonetic analysis. Target nouns are mutually exclusive across typicality conditions. As they comprise a range of number of syllables and different placements of stressed syllables, we were not convinced that their F0 patterns were comparable, both within and across typicality conditions, without a more nuanced consideration of these factors. The second issue is the implementation of GAMMs in this analysis, which we consider to be deeply flawed, for reasons explained below. Taken together, we did not find this analysis to be reliable for the current research question.",We consider the use of GAMMs to be appropriate for analysing F0 dynamics.,"The choice to consider intonation (and consequently F0) is theoretically sound, although we would be interested to learn about the process of deciding on intonation specifically, rather than, say, prosody more generally. The maximal approach to predictor inclusion is one of the established approaches in model fitting, but we have concerns about the role of each included predictor in the model (explained in Q12 and Q13). GAM checks were performed, but only the basis dimension checking results were reported. A cursory examination of the residual plots suggests that some transformation or data exclusion might have been required, and we would have liked to see more consideration of these.","Of all the variables included, we are in particular concerned with the suitability of ID, which we elaborate in Q13.","We are of the opinion that the model structure was problematic for a number of reasons. Modelling typicality as a parametric term rather than smooths (e.g. s(id, by = typicality)) meant that any non-linear shape differences in the F0 trajectories across typicality conditions were not modelled. The characteristics of the nouns in different conditions as explained in Q9 further compounded this issue. We raise a similar question for the inclusion of random effects – especially target name – as s(bs = ‘re’) terms in the model, as shape differences were again left out. Fitting F0 over ID instead of normalised time, when (word duration and) the number of data points per trial was not uniform, was also problematic. As the number of data points varied greatly even for the same words, the same ID would correspond to different parts of the word. Furthermore, the model was impacted by a small number of outliers with extremely high duration, which meant that a majority portion of the fitted curves had no meaningful reading for most tokens. The result is that the curves in the final model were simply not a meaningful or fit-for-purpose representation of the data.","We consider the choice to include only trials in the NF condition to be appropriate. We were not aware of any further exclusions being discussed, but we are curious what considerations the authors gave to any potential mismeasurements or to trials marked (e.g.) ‘error’.","We consider the conversion of F0 measurements from Hz to semitones to be appropriate. As mentioned in Q13, we believe that ID should have been transformed to normalised time (e.g. from 0 to 1).",N/A
2022-05-27 12:04:11,2022-05-27 12:28:28,IP Address,189.4.76.221,100,1456,True,2022-05-27 12:28:29,R_9ZTQsKHYTZr1fz3,,,,,-27.6147,-48.4976,anonymous,EN,arapaima_modularis,gnathosaurus_canadensis,70,75,70,publishable with major revision.,"This is, overall, an acceptable analysis. Simple yet effective. I wish authors had introduced their analysis and explained their rationale a little better, though. 

My main concern has to do the the phonetic analysis. Why focus on the stressed syllable only to extract pitch peaks? We know that in many languages (e.g., Spanish), peaks associated with stressed syllables in certain positions (e.g., prenuclear) tend to appear outside the segmental boundaries of the stressed syllables. What if German, or in some cases or for some speakers, a similar process occurs? This analysis would not capture that. 

A couple of more details regarding the phonetic analysis:
-How was classification for participants' gender done? Information on gender was not provided. Also, 250Hz for male speakers (or any speaker) is too low. Especially when doing analysis of pitch maxima, it’s important to have a generous upper limit, to be safe.

- Why extract pitch means? What is the rationale for this? Also, why were these extracted manually? Not only is it unnecessary work, but the likelihood of errors also increases when doing this work manually. ","It seems appropriate. Producing one single mean per condition and per speaker is not ideal, though, as variability is lost. ","The dependent variable is correct, and it is the expected variable to choose to answer the research question. 

The independent variable is, in principle, intuitively appealing. However, I wish authors had explained at more length why they chose it. For example, why did they produce a difference between F0 mean in nouns and F0 mean in adjectives? Why not simply measure the noun, or the adjective, for example?","Authors decided to focus on one very specific phonetic cue, and thus excluded other potential acoustic analyses. I do not have an issue with this, but I just wonder why authors thought it was the best predictor variable to answer the research question. ","It seems appropriate, except that, as explained above, producing one single score per participant per condition disregards  the variability in the data. ","Why exclude trials labeled as ""errors"" but not trials with ""break"" or ""hesitation"" labels?

It is not clear what criteria authors used to determine which cases were outliers. ",N/A,
2022-05-27 12:50:34,2022-05-27 12:53:54,IP Address,72.65.234.148,100,199,True,2022-05-27 12:53:55,R_3O0wJMNDLNuMH1E,,,,,40.4268,-79.8935,anonymous,EN,trachurus_riukiuensis,epinephelus_aztecus,55,65,60,publishable with major revision.,"We have a few concerns about both the phonetic analysis and the statistical analysis. Regarding the phonetic analysis, we appreciate that the team carried out their acoustic analysis by hand. Their methods, however, could benefit from more clarification. For example, the authors wrote: “Boundaries were created at zero crossings using large acoustic/auditory cues.” What cues were these exactly and how were they defined given the onset/offsets of the target words? Since just one member of the group checked all difficult cases, the measurements are probably consistent, but the methods as described are not replicable.  Additionally, while trials marked as errors were removed, there was no mention of whether pitch tracker errors and/or creaky voice tokens were removed. We found creaky voice to be especially prevalent in vowel-initial adjectives, especially after vowel-final ""der"", as in ""der orangen"", but can also occur in ""den orangen"", and for some speakers creak is common in many of the articles and adjectives.  The pitch tracker is not likely to do well with creak and will often give an extremely low value for f0 during creak (pitch halving).  Since usually part of the adjective is in modal voice, this will give an extremely large f0 range for most tokens that contain creak. Related to this, the authors have set their  pitch analysis range in their Praat script to 70 Hz - 550 Hz. The pitch tracker is likely to have some pitch tracker errors that give very high ""pitch"" during voiceless aspiration noise or frication noise, where there is just enough of a repeating pattern for a brief bit for the pitch tracker to think there's voicing.  Restricting the determination of max pitch to voiced portions at least 30 ms from the onset or offset of voicing would help with this, or hand measurement of max and min would, or setting a narrower range for pitch analysis, perhaps with the max determined for each speaker's actual pitch range.  A process of checking outliers could also help.

Regarding the statistical analyses, we like the first SEM approach, and find it interesting and appropriate (we note the R code is excellent and we really appreciate the careful attention to detail here). We also appreciate the second analysis involving linear mixed-effects models and the concern here for by-participant effects. We think this approach is generally in line with the SEM results. The authors claim that there are significant differences in the lme models, however, we note that given the additional five models run, the authors should adjust their p-values for multiple comparisons, which would then result in similar null results.  Finally, while this criticism may be due to our group’s relative lack of familiarity with SEM approaches, we were unclear as to the decision making that led to duration being included as a covariate of some measures but not others.

In a similar vein, we are unconvinced by the general approach; if we are wrong about our interpretation of the method, then this requires the motivations to be made much more explicit in the write up.  To take an uncharitable interpretation, it seems as though the authors used the SEM analysis and when they found that nothing was significant simply looked at which non-significant effects might be interesting anyway to run additional statistics (regressions) to back up the interesting non-significant ones from the SEM analysis.  Finding three significant effects, only one matches the interesting but non-significant SEM effect, and so they focussed exclusively on that one.  We are generally in favour of using multiple statistical approaches, and we appreciate that the authors are not bound to p-values, but the results as they stand are (or perhaps as they are presented) are unconvincing.  Moreover, given the extremely subtle distinctions found, we question whether the distinctions putatively found would be perceptible.

Furthermore, to the extent that the results can be trusted, we found some of them puzzling and there was insufficient discussion to assuage our concerns.  In particular, the authors found that intensity mean and intensity range are lower for Medium than for Typical, but do not go lower yet for Atypical; Intensity Range goes the opposite way for Atypical.  If the significant effect is reliable, one would expect that the results for Medium would be in the middle of the other two conditions, and the fact that they’re not merits some discussion.  

The third analysis involving the AF and ANF conditions alongside the NF condition is very interesting, however, we are unsure whether these are truly comparable in the way the authors have set them up. In the AF condition–as the authors note–there was no typicality condition. In the ANF, there was but there was no ambiguity. We think this is problematic in terms of testing  “how acoustics are modulated in comparison to items that are lacking typicality”. Because Typicality is not manipulated in the AF and ANF conditions but is in the NF condition, there is an inherent confound between Typicality and Focus Position that we believe makes it impossible to test the effect of Focus Position accurately within this design.  If Typicality has any effect, it cannot be having the same effect in all three of AF, ANF, and NF, and therefore the effect of Focus Position could be skewed by any effect of Typicality. Furthermore, it is unclear whether the speakers were producing the utterances in AF/ANF conditions without problems. As far as we know, there were no comments in the AF/ANF tiers, meaning many of these trials may have been problematic in terms of errors/hesitations/etc. It is unclear whether this affected the authors’ results. ",The statistical analysis is fine other than the need to adjust for multiple comparisons and the issue with the AN/ANF conditions.,"We only have a limited knowledge of structural equation models, but based on our understanding, the model seems appropriate.","The dependent variables were fine, though we note that pitch tracker errors were prevalent in the data that we analyzed. A method of automatically taking max - min over the span of a whole word is almost sure to get quite a few of the pitch maxima falling in these pitch tracker errors. Pitch tracker errors and creaky voice could also throw average f0 off by inconsistent amounts.",The SEM model is fine. The linear models should adjust for multiple comparisons. The third model involving AF/ANF conditions does not seem to be as straightforward as the authors claim.,"We agree with the decision to exclude errors. However, we would like to note that we don’t think that information about errors/hesitation breaks/etc. were annotated in the AF and ANF conditions. For example, in JW_3, who had 9/30 NF trials marked as an error/hesitation break, none of the AF or ANF trials for JW_3 were so marked.  It seems unlikely to us that JW_3 only produced errors on the NF trials.  This introduces an inconsistency in how the different conditions were treated with respect to errors and points to the problems with including the AF and ANF conditions.

One might also want to exclude speaker JW_3 entirely, as this speaker had a very high proportion of stimuli marked as errors and seems to have struggled with the task.  However, since the actual error tokens were excluded, this seems like more a matter of preference, it could be fine either way.

We would also look for some method of excluding creaky voice from the f0 range measurements.  Hand-placement of measurement points could avoid this, or one could use a measure other than range, to avoid including f0 minima that reflect creak. ",None,N/A
2022-05-27 12:55:20,2022-05-27 13:13:03,IP Address,139.47.83.156,100,1063,True,2022-05-27 13:13:04,R_3m7Cun5bZJJG7hb,,,,,40.4163,-3.6934,anonymous,EN,comanthina_maculatus,linckia_nattereri,100,100,90,publishable with minor revision.,"While the approach and statistical analysis with the presentation of the statistical results seem excellent, the overall conclusion is masked by data.","Out of my league, but seemingly appropriate.",The removal of correlated variables was good.,"The number of variables included was high, perhaps too high for a targeted analysis.",Seemingly very appropriate.,Focus on NF condition appropriate for the RQ; there is no mention of how the tokens marked as 'Error' were treated.,,
2022-05-27 12:03:32,2022-05-27 13:20:15,IP Address,73.14.34.31,100,4602,True,2022-05-27 13:20:16,R_1GOWi85SaUym7UE,,,,,40.0373,-105.279,anonymous,EN,clione_dorsalis,chelonia_brummeri,80,90,90,publishable as is.,"The chosen variables were well-motivated and analyzed in a straightforward way.  ","The statistical methods were well-motivated and explained. ","The models chosen were appropriate and well-motivated for the research question. Considering F1 and F2 separately in this case fails to capture expected vowel space expansion as a whole; further, it limits the analysis to examining each vowel separately.  ","It would have been helpful to have more justification for the specific relative duration and intensity measures used in the analysis. Discussion of the interpretation of the raw F1 and F2 analysis would have improved the analysis. However, the inclusion of both prosodic and spectral variables was appropriate. The independent variables were also appropriate. ","The Bayesian and GAMM analyses were well-motivated.  ",The researchers made appropriate choices to examine adjectives in noun focus conditions.,"Data transformations were fine. ",
2022-05-27 14:43:51,2022-05-27 14:46:20,IP Address,73.217.118.234,100,148,True,2022-05-27 14:46:20,R_21vtcrz9JUcLbAh,,,,,39.9834,-105.143,anonymous,EN,nestor_idahoensis,pseudopleuronectes_assasi,75,70,70,publishable with major revision.,"Phonetic (85) - They show one case of boundary placement but demonstrating reliability quantitatively through ICCs would be beneficial. 
They have some heuristics to flag implausible values, but need to describe how many tokens this impacted and justify why they did not manually remeasure the flagged tokens and a subset of the non-flagged tokens for reliability. Also how were these excluded tokens distributed across speakers and conditions?
Praat formant extract is known to be sensitive to speaker characteristics and the details at how LPC settings were customized for each speaker were omitted from the paper. A tool like Fast Track might have helped here, at least for determining speaker-specific Max Formant settings if not for extracting the formants in full. 
Why not exclude the liquid from the segmentation of the vowel, and take measurements throughout the vowel? 
How did they handle the cases of pitch-halving that were not handled by changing the F0 floor to 100 for female speakers?
I remain unconvinced that intensity could be meaningfully measured given the lack of precise experimental control for the purpose of measuring intensity.

There appears to be poor inter-rater reliability for start and end points of stressed vowels, despite the detailed guidelines for annotating the utterances. It was unclear whether the annotation in Figure 2 was prior to adopting these guidelines or after adopting these guidelines, or whether there was any method for determining inter-rater reliability (i.e., by comparing 10% of the segmentations across all segmenters). 

Formant Distance measure: I have some reservations about determining F1 and F2 averages across all vowels in this case, as it appears that the authors include syllable-final r and l within the vowel segments. This decision may have influenced the formant measures across all vowels. In addition, did the authors investigate whether one vowel may have been overrepresented in the corpus before using a mean measure of F1 and F2 as the basis for determining formant distance.

How many formants had a z-score of greater than 2 and were therefore automatically eliminated? 
","The model formulation was appropriate, especially with the inclusion of random effects by speaker and item. Comparison to the null was appropriate but unusual. I would have liked to have seen F or T scores reported from the models. Also normality of the raw data was not important for the regression analysis, but rather normality of the residuals. 
","The choice of acoustic variables to be evaluated was well-motivated by previous literature on German stress. The decision to compare AF and NF nouns does not answer the research question, as it only relates to the atypical condition, and there are likely not enough tokens of the AF measures included for this analysis. Excluding the AF measures may have resolved the reported difficulties in the analysis. Overall, the statistical models in 4.2.1 and 4.2.2 do not appear to be appropriate to answer the research question.
For 4.2.3 [for the f0 dependent variable], it is unclear why the authors chose to divide the group by sex, in addition to using participant as a random intercept. It seems more likely that this would be an individual difference than a sex-based difference. 
Please note that the measurements taken of the acoustic variables, however, are not optimal (see above).
","For the F0 analysis in the NF condition, there was no need to analyze by sex, as this difference would be captured by individual effects.
For the analyses in 4.2.1 and 4.2.2, the inclusion of AF tokens was not suitable, as it allowed only for the comparison of atypical tokens and did not contribute to answering the research question.
",The basic statistical model for 4.2.3 appears to be appropriate (with the exception of investigating sex effects for the F0 dependent variable).,"I would have liked more information about the individual tokens that were excluded due to Praat formant tracking difficulties. ","The use of Euclidean distance for the vowel dispersion measure was fine, although I have reservations about including coda /l, r/ in the calculation of the “mean” vowel and questions about the frequency of different vowels appearing in this calculation.
",
2022-05-27 16:14:12,2022-05-27 16:22:50,IP Address,71.14.128.99,100,518,True,2022-05-27 16:22:50,R_1gI76rxnkcz0Ljt,,,,,32.7979,-97.3586,anonymous,EN,varanus_eulophotes,dermatolepis_aculeatus,92,93,93,publishable with minor revision.,"The authors used a linear mixed effects model with condition and typicality as independent factors, random slopes for speakers, and random intercepts for either noun, adjective, or overall phrase. This seems like an appropriate and concise statistical measurement. ","The linear mixed effects model is appropriate. ","The variables and structure are appropriate. ","The variables of condition and typicality as independent variables are suitable since this is what the overall project is examining. ","The structure of the model seems suitable as it included independent factors as well as random slopes to account for differences among speakers. ","They excluded data points that because of mispronunciations, false starts, and recasts as they might have affected pitch with regards to typicality. However, they did not exclude data points with hesitation breaks, as this would not affect pitch, nor did they exclude trials with mistakes unrelated to the noun-adjective pair. This seems to be an appropriate approach to data cleaning, though it might be nice to add a post hoc analysis verifying that the trials with hesitation breaks do not systematically differ in pitch.","There was no report of data transformation. This seems okay with the given model, and would not likely affect the outcome of the analysis.",This was a straightforward and concise write-up and analysis. A slightly more extensive conclusion that explains what the density plots show and a brief explanation of the statistical results in plain language would be beneficial to the reader.
2022-05-28 07:43:09,2022-05-28 07:44:34,IP Address,177.18.234.132,40,85,False,2022-05-28 07:49:20,R_1pR2wxIwqIMtFNG,,,,,,,anonymous,EN,swiftia_ruber,haematopus_fossor,85,80,80,publishable with minor revision.,,,,,,,,
2022-05-23 13:07:19,2022-05-23 13:35:10,IP Address,128.223.223.55,20,1670,False,2022-05-28 07:49:23,R_28M0Iqt4jQeN2Ok,,,,,,,anonymous,EN,epinephelus_aztecus,genyonemus_evotis,,,,,,,,,,,,
2022-05-28 09:11:52,2022-05-28 09:26:56,IP Address,177.18.234.132,100,903,True,2022-05-28 09:26:56,R_86xAXbcLGsplCTL,,,,,-15.7792,-47.9341,anonymous,EN,swiftia_ruber,haematopus_fossor,85,85,85,publishable with minor revision.,"The analysis consisted of 8 acoustic variables: frame duration (from onset of utterance to onset of adjective), adjective duration, noun duration, adjective stressed vowel duration, noun stressed vowel duration, noun vowel intensity, adjective vowel [F1-F2] centralization, and noun vowel [F1-F2] centralization. We had understood that each team should have tackled only one response variables, but in this case a total of eight statistical models, one for each acoustic variable, were fitted. The acoustic variables chosen and the statistical models used are appropriate.","A total of 8 linear mixed-effects regression models, one for each acoustic variable, were fitted. Variables were centered. Effect sizes were said to be calculated by pseudo-standardising the coeﬀicients, but there results were not reported. Typicality, a variable with three levels, was helmert-coded. The models therefore carry out two comparisons: one between the typical trials to the mean of the medium and atypical trials, and one between the medium and atypical trials. The choices are appropriate.","Fixed effects were typicality, trial number, and their interaction. Random variables were varying intercept for participant and random intercept of word. No random slope was included (perhaps for convergence issues?). ",Condition was not included because the analysis used only the NF condition (perhaps because of the lack of no full crossing of variables in the data).,"Models were fitted and reported adequately, though a total of eight models were fitted and reported. Most of them yielded non-significant results. And significant results arouse, their were mild. In some results, there seems to be an apparent emphasis for the typical combinations (longer stressed vowel of adjectives, and more peripheral vowels), but no explanation is given. ","Data was force-aligned, and hand-corrected only for target trials in the NF condition. Trials marked with “error” or “hesitation break” in the notes tier were not corrected and were excluded from further analysis. Decisions are appropriate. ","No transformation was done, and perhaps using relative durations instead of raw durations could have eliminated a possible effect of speech rate.","Answer to the main research question was of no evidence for an effect of typicality on speech production in this experiment, which is similar to our own results and to the other two already reviewed."
2022-05-30 03:50:02,2022-05-30 04:07:20,IP Address,128.240.225.38,100,1038,True,2022-05-30 04:07:21,R_2aqSQMI5hthcOMV,,,,,54.9836,-1.5895,anonymous,EN,haematopus_fossor,lycodes_bradfieldi,40,65,60,publishable with major revision.,"Phonetic analysis: 
This analysis looked at amplitude modulations over the entire sentence. Two metrics – AM and Mi – were calculated, but the methods accomplishing this were not entirely clear from the writeup. (The cited papers use different terminology (AMa and AMi) and it’s not clear which measures were being used.) This makes it difficult to evaluate precisely what was done.
Moreover, how the frequency bands relate to speech is unclear. Delta and theta correspond to word- and syllable-level oscillations, but the higher frequencies are less interpretable. Given that the main result includes effects in the alpha, beta, and lower gamma bands, this is a cause for concern – what exactly about the speech is changing here? And why was this observed only for Mi and not AM – what does that mean?
The linking hypothesis made in the analysis appears to use the following reasoning: surprise in reading leads to particular neural oscillations; reading oscillations correlate with speech oscillations; therefore, atypical sequences should display particular speech oscillations.
There are two possible issues with this line of reasoning. One is that the task did not involve reading in the same way as most prior neurolinguistic studies have investigated reading. The other is that, due to the nature of the task, it is possible that participants would “habituate” to the atypical sequences – in an experimental context where purple potatoes are perfectly normal, a green cherry doesn’t seem so surprising.
Statistical analysis: 
The model overall appears to be well-constructed and well-though-out. However, no attempt was made to control for item as a random effect (see e.g. Clark 1973). How can we be sure that the oscillations observed are not simply due to the linguistic content of the atypical sequences?
No reproducible materials for the statistical analysis were found in the repository. After running the MATLAB code to generate the spectra, it’s not clear which values were taken and used for the statistical analysis – mean values, max values, something else?
","A series of ANOVAs were used to analyse the data, with post-hoc t-tests. This is fine in principle but in practice no accounting was made for items as random effects, nor were there corrections for multiple comparisons in the ANOVAs.",Random effects of items should have been included or accounted for.,See above.,See above.,"Only data from the NF condition were analysed, which is appropriate.","The raw spectra were transformed into a single value prior to analysis, but it’s not clear how this was done.","Our certainty in this review is relatively low as we are not experts in the particular oscillation analysis methods used in this analysis, and parts of the writeup were unclear (even after we examined the MATLAB code)."
2022-05-30 15:21:42,2022-05-30 15:56:07,IP Address,83.41.133.195,100,2064,True,2022-05-30 15:56:07,R_1EcGP6STvTo6hft,,,,,41.4928,2.0403,anonymous,EN,saron_pictus,neosilurus_omanensis,64,60,62,publishable with major revision.,"Overall, we felt that this analysis was well done, but with some changes that should be made that would strengthen our confidence in the results.","Mixed models were appropriate, ",It seems like this was motivated by theory in an acceptable way.,The variables were appropriate for the research questions.,"It would have been nice to see random slopes used, as this was in theory a confirmatory hypothesis test.","An unknown amount of observations were removed for lying outside two standard deviations from the mean. This is not an appropriate statistical practice. If you wanted to check the influence of outliers, we would advise doing so within the regression model as part of model criticism as suggested by Baayen and Milin (2010).

Many times it seemed like large amounts of data were missing. It is important to acknowledge that missing data is a problem if the data is missing for a reason related to how the data was generated.

",,
2022-06-07 07:48:33,2022-06-07 08:09:04,IP Address,134.99.36.13,100,1231,True,2022-06-07 08:09:05,R_3CJaS4gTxNKAztZ,,,,,51.2076,6.7962,anonymous,EN,aracana_bitatawa,pervagor_adscensionis,70,80,75,publishable with major revision.,"MFCCs are peculiar measure to focus on. Why not Frequency Band Summaries, which are also psycho-acoustic approximations of spectra (not that these are better or worse, but the authors do not motivate their choice at all)? Having said that, the analysis is well-done.",fine.,"There is very little discussion, but given the phonetic analysis and the question asked this is fine.",ok,ok,Not discussed why only NF.,All reasonable.,
2022-06-10 12:40:15,2022-06-10 14:39:55,IP Address,151.197.3.250,100,7179,True,2022-06-10 14:39:55,R_1kG1l5NBnA9jd5u,,,,,39.9476,-75.1474,anonymous,EN,genyonemus_evotis,swiftia_ruber,50,60,55,publishable with major revision.,"The contour plots in figure 1 through 3 look a bit strange, for example, F0 of stressed segments in both conditions in figure 2 appear to be lower than the unstressed segments. This indicates that there might be an error in the measurements. Upon inspecting the TextGrid, it turns out that the syllable boundaries were not well aligned with the syllable structure of the adjectives and nouns: the consonant onsets were included in the previous syllable rather than the current syllable, which should be at least explained in more detail so that the plots can be better interpreted. The results are mostly qualitative, which is fine, but it would be better to still report the statistics and discuss why the difference shown in figure 1 doesn't seem to matter much in speech. ",The statistical analysis method seems to be appropriate.,"The authors did not explain why a Gaussian assumption was used for both the basis expansion and prior, and why 5 points were selected per segment.",The authors did not include speaker/item random effects in their model. This can be especially problematic because their F0 normalization is per utterance based.,The method the authors chose to use seems to be appropriate.,The authors did not exclude potential F0 measurement errors such as F0 irregularities caused by creaky voice.,"It is not clear why normalizing F0 with regard to the median of the F0 contour is sufficient for cross speaker comparison, as the normalization baseline can vary within an individual speaker due to unobserved effects on each utterance. So the resulted unit is per utterance based, which can work but should be conditioned on speaker. It's probably better to choose the median F0 of each speaker as the baseline so that the normalized unit can be compared and interpret across speakers.",
2022-06-10 14:39:59,2022-06-10 17:45:54,IP Address,151.197.3.250,100,11154,True,2022-06-10 17:45:55,R_C7y0Q7r5vcBzfSV,,,,,39.9476,-75.1474,anonymous,EN,genyonemus_evotis,neosilurus_omanensis,70,30,50,publishable with major revision.,"The phonetic analysis has touched on some good points, and the consideration on segmentation and measurements selection were reasonable. However, it is not clear if it is appropriate to measure the F0 of the entire sentence inclusive of all the unvoiced segments/segments that fail the pitch tracker. The F0 measurement algorithm and measures' calculation processes were not explained.
The statistical analysis was conducted with the model misspecified. The significance reporting was also problematic that the authors were using 0.1 as the threshold. A few errors of significance were seen. FDR should be used earlier in the results section rather than a separate section to correct the significance of results.",The choice of mixed effect model was fine for this problem.,"The two model setups appear circular and debatable. The authors designed the two models to test two separate hypotheses in the first place. However, in the following Analysis and Results sections, they changed the effective model depending on whether Model 2 explains more variance than Model 1. It seems that the authors conflated hypothesis testing and model selection. If the authors believe that different focus conditions play a role in predicting the DVs, then ""context"" should always be included in the models, not selecting a different model for each DV based on whether more variance was explained by ""context"", which is circular. 

Moreover, to address the first hypothesis, it does not make sense to include the adjs in all the conditions, because in the NF condition adjectives are not part of the experimental manipulation of typicality, making the stats problematic. In general, context conditions should be analyzed separately under each condition due to experiment design, but the authors mingled it together as an independent variable.","Not subsetting adjs in only AF & ANF conditions is not appropriate. In addition, it would be better to discuss the potential of variable interaction for the 5 selected response variables. ",The structure of the model needs major revision.,"The authors excluded too much observations based on predetermined rules. However, as the authors mentioned, this resulted in too few data points to work with with potentially many outliers, thus not a good practice.","It is questionable to use mean, instead of median, to normalize F0, as F0 distribution is likely not normal. The speech rate measurements should be normalized, as the unit used by the authors might introduce large coefficients which may make the probability estimation unstable.",
2022-06-11 15:22:28,2022-06-11 15:37:06,IP Address,24.85.249.153,100,877,True,2022-06-11 15:37:07,R_TcSh5X0kNTsh13H,,,,,49.2293,-123.1882,anonymous,EN,cromileptes_saxatilis,clione_dorsalis,85,53,65,publishable with major revision.,"While the phonetic analyses seem to have been competently carried out, there are many issues with the statistical analyses that could have affected the results. I also found that there wasn't sufficient justification for the specific model structures, or, indeed some of the key outcome variables (such as F1/F2, which are only mentioned in the context of vowel spaces in the intro, but then suddenly make an appearance in the analyses at the end). Also, far too many analyses were run here to be able to confidently point to one of them and say that this supports / does not support the hypotheses – and some of the significant results in the data (e.g. the typicality effect for F2 on /y/) are likely simply a consequence of running so many separate tests.",Linear mixed effects models are appropriate for the research questions & this type of data.,"While many of the variables were clearly justified, some of them were not (see my comments about F1/F2 above); and no justification is provided for the model structures. It's also not entirely clear at what level the vowel spaces were calculated – within each speaker for each typicality condition? This should be described explicitly.","By and large, the variables are suitable for addressing the main research questions.","There are severe problems with the random effects structures for most of the models here. The word duration analysis does not include any random effects by item, and also does not include random slopes over typicality by speaker, which is problematic & could lead to anti-conservative results. Not knowing exactly what the observations are for the vowel space model, it's hard to say whether the model structure is appropriate here, but it is possible that the same key random slope is also missing here. The F1/F2 analyses also do not include this random slope, which is problematic for the same reasons outlined above.

Also, the large overall number of statistical tests in the report makes it hard to evaluate them in light of the research questions. For instance, the authors find a significant F2 different for the vowel /y/ across two typicality conditions at time point 4 – what should we make of this finding? They seem to essentially dismiss it, but then why was it included in the first place? There are close to 50 statistical tests in the report that speak to the main hypotheses, which is simply too much! Find two significant effects here (as the authors do) is essentially meaningless, given the high probability of false positives.","If there were exclusions, they were not clearly described.","The only transformation worth mentioning here is the vowel space area calculation used by the authors. This transformation, though interesting, really ought to have been described in more detail.",
2022-06-09 21:26:32,2022-06-09 21:37:43,IP Address,184.64.221.169,40,670,False,2022-06-16 21:37:49,R_vjAVqVSSGpSZBBv,,,,,,,anonymous,EN,pseudopleuronectes_assasi,ceratophrys_elephantotus,15,20,10,deeply flawed and unpublishable.,,,,,,,,
