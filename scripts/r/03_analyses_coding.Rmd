---
title: "03 - Analyses coding"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = here::here())
library(tidyverse)
library(ggmosaic)
library(googlesheets4)
library(magrittr)
library(glue)
library(osfr)
library(cli)
library("here")
library("fs")
library("forcats")
library("strex")
library("purrr")
library("broom")
library("broom.mixed")

# Plotting theme
clean_theme <- function(...) {
  list(
    theme_minimal(), 
    theme(
      axis.title.x = element_blank(),
      panel.grid.major = element_line(colour = 'grey90', size = 0.15),
      panel.grid.minor = element_line(colour = 'grey90', size = 0.15),
      strip.text.x = element_text(hjust = 0),
      axis.text.x = element_blank()
    )
  )
}
```

# Read coding sheet

```{r coding}
the_sheet <- "https://docs.google.com/spreadsheets/d/1OOXB-8Uk-fh_urw0Lm4DC0jBueXLIb4Bm-a9--UVXOw/edit?usp=sharing"

coding <- read_sheet(the_sheet) %>%
  mutate(
    outcome = factor(outcome, levels = c("duration", "f0", "formants", "intensity", "harmonics", "SNR", "multivariate", "other")),
    temporal_window = factor(temporal_window, levels = c("segment", "syllable", "word", "phrase", "sentence", "other"))
  ) %>%
  drop_na(model_n)
```

# Teams' analyses

## Download OSF components

First, we get a list of the OSF components in the Teams Analyses component. (It takes a few seconds)

```{r comps}
assigned <- coding %>%
  dplyr::select(team, animal, assigned_to) %>%
  distinct()

comps <- osf_retrieve_node("https://osf.io/n3fyd/") %>%
  osf_ls_nodes(n_max = Inf) %>%
  left_join(y = assigned, by = c("name" = "animal"))
```

Now we get only those components that are assigned to you. Tell me who you are when prompted.

```{r who}
who <- menu(c("Ste", "Joseph", "Timo"), "Who are you?")

whos <- c("sc", "jvc", "tr")
your_comps <- comps %>%
  filter(assigned_to == whos[who])
dir.create(glue("./data/analyses/{whos[who]}"), showWarnings = FALSE, recursive = TRUE)
```

And now we download the components in `data/analyses/` (it will take some time!).

```{r download}
for (comp in 1:nrow(your_comps)) {
  name <- your_comps$name[comp]
  files <- osf_ls_files(your_comps[comp,], n_max = Inf)
  dir <- glue("./data/analyses/{whos[who]}/{name}")
  dir.create(dir, showWarnings = FALSE, recursive = TRUE)
  cli_h1(name)
  osf_download(
    files,
    path = dir,
    recurse = TRUE,
    conflicts = "skip",
    verbose = TRUE, progress = TRUE
  )
}
```

## Refit models

Now that the components have been downloaded, we can refit the models using the scripts in `scripts/r/04-refit/`.

## Upload refitted models to OSF

Once all your models have been refitted, you can upload them to the OSF, in the Cache component, `models/refitted/` folder.

Here's the code that does that for you.

```{r upload-refitted}
cache <- osf_retrieve_node("wds2m")
refitted <- osf_ls_files(osf_ls_files(cache, type = "folder")) %>%
  filter(name == "refitted")
models <- list.files(
  "./data/analyses/models",
  full.names = TRUE
)

osf_upload(
  refitted,
  path = models,
  recurse = TRUE, conflicts = "skip", progress = TRUE, verbose = TRUE
)
```

## Download all refitted models

We download all the refitted models `.rds` files from the OSF.

```{r download-refitted}
cache <- osf_retrieve_node("wds2m")
refitted_rds <- osf_ls_files(cache, "models/refitted", n_max = Inf)

osf_download(
  refitted_rds,
  path = "./data/analyses/models/",
  conflicts = "skip", progress = TRUE, verbose = TRUE
)
```


# Get estimates from refitted models

Now we can extract the relevant estimates from the refitted models.

The following functions extracts the estimates.

```{r clean-up}
clean_up <- function(model) {
  effs <- suppressWarnings(tidy(model, effects = "fixed", parametric = TRUE)) %>% 
  filter(term %in% c("effect_catmedium", "effect_cattypical", "effect_con"))
  if (!("response" %in% colnames(effs))) {
    effs$response <- "none"
  }
  effs <- effs %>%
  select(outcome_mult = response, term, estimate, se = std.error)
  
  return(effs)
}
```

Now we load all the models and apply `clean_up()` to get the estimates.

```{r load-models}
msa_models <- dir_ls(path = here("data/analyses/models"), regexp = ".rds$") %>% 
  as_tibble() %>% 
  transmute(
    path = value,
    mod_name = str_remove(path, here("data/analyses/models/")), 
    mod_name = str_remove(mod_name, ".rds"), 
    model = map(path, ~ readRDS(file = .))
  ) %>% 
  separate(
    mod_name, 
    into = c("word1", "word2", "model_n", "model_outcome", "typicality"), 
    sep = "_", remove = F,
    convert = TRUE
  ) %>% 
  unite(animal, word1, word2, sep = "_") %>% 
  select(animal, model_n:model) %>% 
  mutate(summaries = map(model, clean_up)) %>%
  select(-model) %>%
  unnest(summaries) %>%
  mutate(
    typ_level = case_when(
      term == "effect_cattypical" ~ "typical",
      term == "effect_catmedium" ~ "medium"
    ),
    typicality = ifelse(typicality == "con", "continuous", "categorical"),
    model_id = paste(animal, model_n, sep = "_")
  ) %>%
  select(animal, model_n, model_id, model_outcome, outcome_mult, typicality, typ_level, estimate, se) %>%
  mutate(
    outcome_mult = case_when(
      outcome_mult == "none" ~ NA_character_,
      outcome_mult == "meanf0" ~ "f0",
      outcome_mult == "meanint" ~ "intensity",
      outcome_mult == "duration" ~ "duration",
      outcome_mult == "f0" ~ "f0",
      outcome_mult == "f15" ~ "formants_1",
      outcome_mult == "f25" ~ "formants_2"
    )
  ) %>%
  left_join(y = coding) %>%
  mutate(
    model_id = ifelse(is.na(outcome_mult), model_id, paste(model_id, outcome_mult, sep = "_")),
    model_id = ifelse(is.na(typ_level), model_id, paste(model_id, typ_level, sep = "_"))
  )

saveRDS(msa_models, "./data/analyses/msa_models.rds")
```

Simple pandoc table of the models, estimates, se, etc.

```{r effect-table}
msa_models %>%
  select(model_id, estimate, se) %>%
  knitr::kable(format = "pandoc")
```

# Plotting

Simple forest plot of the estimates and 95% CrIs.

```{r fp-outcome}
msa_models %>%
  filter(animal != "polymetme_brevirostrum") %>%
  ggplot(aes(x = reorder(model_id, estimate), y = estimate, colour = outcome)) + 
  geom_hline(yintercept = 0) +
  geom_segment(
    aes(y = estimate - se * 1.96, yend = estimate + se * 1.96, xend = model_id), 
    alpha = 0.5, size = 1, lineend = "round"
  ) + 
  geom_point(pch = 21, stroke = 2, size = 1) +
  facet_wrap(. ~ typicality, ncol = 1, scales = "free") +
  scale_colour_brewer(palette = "Set1", type = "qual") +
  labs(y = "Estimate (z-scores)") + 
  clean_theme() 
```

```{r fp-outcome-facet}
msa_models %>%
  filter(animal != "polymetme_brevirostrum") %>%
  ggplot(aes(x = reorder(model_id, estimate), y = estimate, colour = outcome)) + 
  geom_hline(yintercept = 0) +
  geom_segment(
    aes(y = estimate - se * 1.96, yend = estimate + se * 1.96, xend = model_id), 
    alpha = 0.5, size = 1, lineend = "round"
  ) + 
  geom_point(pch = 21, stroke = 2, size = 1) +
  facet_grid(outcome ~ typicality, scales = "free") +
  scale_colour_brewer(palette = "Set1", type = "qual") +
  labs(y = "Estimate (z-scores)") + 
  clean_theme()
```

```{r forest-plot-2}
msa_models %>%
  filter(animal != "polymetme_brevirostrum") %>%
  ggplot(aes(x = reorder(model_id, estimate), y = estimate, colour = estimate)) + 
  geom_hline(yintercept = 0) +
  geom_segment(
    aes(y = estimate - se * 1.96, yend = estimate + se * 1.96, xend = model_id), 
    alpha = 0.5, size = 1, lineend = "round"
  ) + 
  geom_point(pch = 21, stroke = 2, size = 1) +
  facet_wrap(. ~ typicality, ncol = 1, scales = "free") +
  scale_colour_gradientn(colours = c("#d95f02", "#dfc27d", "#80cdc1", "#018571"), limits = c(-1, 1)) +
  labs(y = "Estimate (z-scores)") + 
  clean_theme() 
```

```{r}
coding %>%
  ggplot(aes(framework)) +
  geom_bar()
```

```{r}
coding %>%
  ggplot(aes(model)) +
  geom_bar()
```

```{r}
coding %>%
  ggplot(aes(family)) +
  geom_bar()

coding %>%
  ggplot(aes(outcome, fill = family)) +
  geom_bar()
```

```{r}
coding %>%
  drop_na(outcome, temporal_window) %>%
  ggplot() +
  geom_mosaic(aes(x = product(outcome, temporal_window), fill = outcome))
```

```{r}
coding %>%
  drop_na(outcome, temporal_window) %>%
  filter(
    outcome %in% c("duration", "f0", "intensity"),
    temporal_window %in% c("segment", "word", "phrase", "sentence")
  ) %>%
  droplevels() %>%
  ggplot() +
  geom_mosaic(aes(x = product(outcome, temporal_window), fill = outcome))
```

```{r}
coding %>%
  count(operationalisation) %>%
  ggplot(
    aes(reorder(operationalisation, desc(n)), n)
    ) +
  geom_bar(stat = "identity")
```

```{r}
coding %>%
  drop_na(outcome, operationalisation) %>%
  filter(
    outcome %in% c("duration", "f0", "intensity"),
    temporal_window %in% c("segment", "word", "phrase", "sentence")
  ) %>%
  droplevels() %>%
  ggplot() +
  geom_mosaic(aes(x = product(outcome, operationalisation), fill = outcome))
```

```{r}
coding %>%
  select(framework:outcome, operationalisation, temporal_window, typicality_operationalization, random_effects) %>%
  distinct()
```

```{r}
coding %>%
  select(team, n_models) %>%
  distinct() %>%
  drop_na() %>%
  summarise(mean(n_models), median(n_models), sd(n_models), min(n_models), max(n_models))
```

